{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import admg_rkhs_discovery\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/33000.0 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dagma iter t=1 -- mu: 0.1 ------------------------------\n",
      "success:  False\n",
      "\n",
      "Minimize s=1.0 -- lr=0.03\n",
      "\n",
      "mu 0.1\n",
      "\n",
      "Inner iteration 0\n",
      "\th(W(model)): 2.000000031151749e-08\n",
      "\tscore(model): 5.384405338314584\n",
      "\t mle: 14.225183092635179\n",
      "\t mse: 7.627581357622315\n",
      "\tW1: tensor([[0.0001, 0.0001],\n",
      "        [0.0001, 0.0001]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 2.000000031151749e-08\n",
      "\tW2: tensor([[1.0000, 0.0400],\n",
      "        [0.0400, 1.0000]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0618, 0.0721],\n",
      "        [0.0721, 1.0650]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-0.3193,  0.0000],\n",
      "        [-1.8389, -9.9572]])\n",
      "Check y:  tensor([ 1.3817,  5.4328,  2.9905,  1.2662, -1.9645,  4.1842, -1.6192,  2.9269,\n",
      "         1.0065, -2.9408,  5.2526,  0.8029,  1.9536,  1.9734, -1.7924, -2.2382,\n",
      "        -0.5879,  4.4945,  5.4120,  3.5396,  0.6810,  5.1442, -1.0167,  5.3879,\n",
      "        -3.1229,  4.0312, -3.7983,  1.4677,  0.6025, -2.1855, -5.0772,  5.4484,\n",
      "        -1.1525,  1.9652, -0.5601,  3.4216,  3.2627,  3.4016,  1.4913,  4.9713,\n",
      "        -3.4993, -1.6330,  5.2271, -1.5058,  4.6726,  4.7542, -5.0220, -3.4176,\n",
      "        -4.4142, -3.4032,  2.0180, -1.5939,  0.4890, -2.6624, -5.0076, -4.2280,\n",
      "         4.3616, -5.1381, -0.8928, -5.1601, -4.1754, -2.8998,  4.4381, -3.6649,\n",
      "        -4.8651, -3.2873,  4.7474, -2.5213,  4.3704, -2.4927,  0.7257, -0.8325,\n",
      "         0.7194,  3.0517,  5.5680, -0.9911, -4.9062, -3.1767, -4.7308, -3.1356,\n",
      "        -4.3675, -2.1953, -1.6083,  5.1506,  1.9104, -5.0713,  0.6421, -2.4313,\n",
      "         2.1905,  1.8727, -4.3567,  4.6864, -3.4953,  5.4431, -4.8243, -4.6607,\n",
      "         2.5074, -0.5857,  4.5773, -0.3071,  4.8968, -5.0351,  5.5576,  1.0405,\n",
      "        -5.1523,  2.1968,  2.6727,  2.0797, -5.1154,  1.2656, -1.3805,  4.1637,\n",
      "         5.2528, -4.7117,  4.8902, -2.6273,  3.2298,  2.3503,  3.2120,  5.1515,\n",
      "         5.5107,  0.0329,  1.1846,  4.1360, -1.9595,  3.0970, -0.5679, -4.6485,\n",
      "         4.5269, -4.8154,  3.4324, -1.8382, -3.5935, -4.6990,  2.0111,  2.6378,\n",
      "         2.1419,  4.3639,  4.3374, -1.7725,  2.7908, -3.3143, -1.6621,  2.9226,\n",
      "         5.0286,  5.3103, -2.6105,  2.1421,  5.4240,  0.3019, -3.9505,  3.5914,\n",
      "        -4.2542,  3.3624, -3.2775,  4.1235,  5.0089,  1.9852, -2.3682, -1.7420,\n",
      "         5.2242, -1.2186,  5.4892,  3.6392,  0.7454,  3.9226, -0.4283, -3.4886,\n",
      "         5.5368, -4.4461,  0.5796, -1.3555, -4.9092, -0.5550,  5.2253, -5.1198,\n",
      "        -3.8142,  1.9056,  5.3168, -0.8275, -4.3021,  3.5304,  2.2290, -5.1613,\n",
      "         1.7406,  3.3166,  0.9968,  2.6090,  5.5374, -4.4762, -2.5858, -5.0169,\n",
      "        -4.7108,  1.4753,  5.5686, -0.2602, -5.1358, -5.1339, -1.4492, -1.6981,\n",
      "        -4.4788,  5.2087, -3.0757, -4.5977, -0.6770, -1.6906,  4.9266, -1.2147,\n",
      "         1.0242,  2.7872,  0.4524, -5.0761,  4.5921, -5.0856, -0.5964,  5.5489,\n",
      "        -4.3297, -2.9402,  2.5614,  4.5302,  3.7388,  3.4666, -5.0036,  5.1613,\n",
      "        -4.7016,  1.2645,  5.0702, -5.0656,  1.3992,  5.5408, -5.1355, -5.0479,\n",
      "         0.4997, -0.6971, -4.9936, -1.9391, -3.1601, -0.9631, -4.9633,  2.5155,\n",
      "         3.7078, -3.1021,  0.4767, -3.5026,  5.4478, -2.6381,  1.8751, -4.6622,\n",
      "        -3.8361, -0.3243, -3.5874,  1.5769,  5.5141,  5.5727,  2.5863, -2.1340,\n",
      "         1.4814,  2.4464,  1.0463, -4.7874, -5.1624, -2.6124, -0.5151,  1.8664,\n",
      "         4.7392,  5.3362, -4.9186,  2.5043, -1.6033, -0.3888,  0.7042,  3.3591,\n",
      "        -3.9678,  1.0548, -5.1503,  1.3504,  1.5524,  5.1435,  3.7788,  3.4210,\n",
      "        -4.7753,  4.0998,  3.4285, -0.4559, -3.7732, -3.9183,  0.6160, -0.5799,\n",
      "        -0.0739,  4.0195, -3.2906, -3.6312,  4.7241, -4.7685,  0.3076, -5.1218,\n",
      "        -2.5425,  3.7528,  0.8007,  1.0720], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.960047669753471\n",
      "Found h negative -2.0870424211883414 at iter 1\n",
      "success:  False\n",
      "\n",
      "Minimize s=1 -- lr=0.015\n",
      "\n",
      "mu 0.1\n",
      "\n",
      "Inner iteration 0\n",
      "\th(W(model)): 2.000000031151749e-08\n",
      "\tscore(model): 5.384405338314584\n",
      "\t mle: 30.02648109228117\n",
      "\t mse: 15.70624244241158\n",
      "\tW1: tensor([[0.0001, 0.0001],\n",
      "        [0.0001, 0.0001]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 2.000000031151749e-08\n",
      "\tW2: tensor([[1.0000, 0.0400],\n",
      "        [0.0400, 1.0000]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0305, 0.0558],\n",
      "        [0.0558, 1.0318]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-0.3193,  0.0000],\n",
      "        [-1.8389, -9.9572]])\n",
      "Check y:  tensor([ 0.6909,  2.7164,  1.4953,  0.6331, -0.9822,  2.0921, -0.8096,  1.4635,\n",
      "         0.5032, -1.4704,  2.6263,  0.4015,  0.9768,  0.9867, -0.8962, -1.1191,\n",
      "        -0.2939,  2.2472,  2.7060,  1.7698,  0.3405,  2.5721, -0.5084,  2.6939,\n",
      "        -1.5615,  2.0156, -1.8991,  0.7339,  0.3013, -1.0927, -2.5386,  2.7242,\n",
      "        -0.5762,  0.9826, -0.2801,  1.7108,  1.6314,  1.7008,  0.7456,  2.4856,\n",
      "        -1.7496, -0.8165,  2.6136, -0.7529,  2.3363,  2.3771, -2.5110, -1.7088,\n",
      "        -2.2071, -1.7016,  1.0090, -0.7970,  0.2445, -1.3312, -2.5038, -2.1140,\n",
      "         2.1808, -2.5690, -0.4464, -2.5801, -2.0877, -1.4499,  2.2190, -1.8324,\n",
      "        -2.4326, -1.6437,  2.3737, -1.2607,  2.1852, -1.2464,  0.3629, -0.4163,\n",
      "         0.3597,  1.5258,  2.7840, -0.4956, -2.4531, -1.5884, -2.3654, -1.5678,\n",
      "        -2.1838, -1.0976, -0.8042,  2.5753,  0.9552, -2.5356,  0.3211, -1.2156,\n",
      "         1.0953,  0.9363, -2.1783,  2.3432, -1.7477,  2.7216, -2.4121, -2.3303,\n",
      "         1.2537, -0.2929,  2.2887, -0.1535,  2.4484, -2.5176,  2.7788,  0.5202,\n",
      "        -2.5761,  1.0984,  1.3363,  1.0398, -2.5577,  0.6328, -0.6902,  2.0818,\n",
      "         2.6264, -2.3558,  2.4451, -1.3137,  1.6149,  1.1752,  1.6060,  2.5758,\n",
      "         2.7553,  0.0164,  0.5923,  2.0680, -0.9798,  1.5485, -0.2840, -2.3242,\n",
      "         2.2634, -2.4077,  1.7162, -0.9191, -1.7968, -2.3495,  1.0055,  1.3189,\n",
      "         1.0709,  2.1819,  2.1687, -0.8863,  1.3954, -1.6572, -0.8310,  1.4613,\n",
      "         2.5143,  2.6552, -1.3053,  1.0711,  2.7120,  0.1510, -1.9752,  1.7957,\n",
      "        -2.1271,  1.6812, -1.6387,  2.0617,  2.5045,  0.9926, -1.1841, -0.8710,\n",
      "         2.6121, -0.6093,  2.7446,  1.8196,  0.3727,  1.9613, -0.2142, -1.7443,\n",
      "         2.7684, -2.2231,  0.2898, -0.6778, -2.4546, -0.2775,  2.6126, -2.5599,\n",
      "        -1.9071,  0.9528,  2.6584, -0.4137, -2.1511,  1.7652,  1.1145, -2.5806,\n",
      "         0.8703,  1.6583,  0.4984,  1.3045,  2.7687, -2.2381, -1.2929, -2.5085,\n",
      "        -2.3554,  0.7377,  2.7843, -0.1301, -2.5679, -2.5669, -0.7246, -0.8491,\n",
      "        -2.2394,  2.6043, -1.5379, -2.2988, -0.3385, -0.8453,  2.4633, -0.6073,\n",
      "         0.5121,  1.3936,  0.2262, -2.5380,  2.2961, -2.5428, -0.2982,  2.7744,\n",
      "        -2.1648, -1.4701,  1.2807,  2.2651,  1.8694,  1.7333, -2.5018,  2.5807,\n",
      "        -2.3508,  0.6323,  2.5351, -2.5328,  0.6996,  2.7704, -2.5678, -2.5239,\n",
      "         0.2499, -0.3486, -2.4968, -0.9695, -1.5800, -0.4815, -2.4816,  1.2578,\n",
      "         1.8539, -1.5510,  0.2383, -1.7513,  2.7239, -1.3190,  0.9375, -2.3311,\n",
      "        -1.9181, -0.1621, -1.7937,  0.7884,  2.7571,  2.7864,  1.2932, -1.0670,\n",
      "         0.7407,  1.2232,  0.5232, -2.3937, -2.5812, -1.3062, -0.2576,  0.9332,\n",
      "         2.3696,  2.6681, -2.4593,  1.2522, -0.8016, -0.1944,  0.3521,  1.6795,\n",
      "        -1.9839,  0.5274, -2.5752,  0.6752,  0.7762,  2.5717,  1.8894,  1.7105,\n",
      "        -2.3876,  2.0499,  1.7142, -0.2280, -1.8866, -1.9592,  0.3080, -0.2900,\n",
      "        -0.0369,  2.0098, -1.6453, -1.8156,  2.3621, -2.3842,  0.1538, -2.5609,\n",
      "        -1.2713,  1.8764,  0.4004,  0.5360], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.960047669753471\n",
      "Found h negative -1.9935065149998419 at iter 4\n",
      "success:  False\n",
      "\n",
      "Minimize s=1 -- lr=0.0075\n",
      "\n",
      "mu 0.1\n",
      "\n",
      "Inner iteration 0\n",
      "\th(W(model)): 2.000000031151749e-08\n",
      "\tscore(model): 5.384405338314584\n",
      "\t mle: 40.87067992314434\n",
      "\t mse: 21.051516687599356\n",
      "\tW1: tensor([[0.0001, 0.0001],\n",
      "        [0.0001, 0.0001]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 2.000000031151749e-08\n",
      "\tW2: tensor([[1.0000, 0.0400],\n",
      "        [0.0400, 1.0000]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0151, 0.0478],\n",
      "        [0.0478, 1.0157]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-0.3193,  0.0000],\n",
      "        [-1.8389, -9.9572]])\n",
      "Check y:  tensor([ 0.3454,  1.3582,  0.7476,  0.3166, -0.4911,  1.0460, -0.4048,  0.7317,\n",
      "         0.2516, -0.7352,  1.3132,  0.2007,  0.4884,  0.4934, -0.4481, -0.5596,\n",
      "        -0.1470,  1.1236,  1.3530,  0.8849,  0.1703,  1.2860, -0.2542,  1.3470,\n",
      "        -0.7807,  1.0078, -0.9496,  0.3669,  0.1506, -0.5464, -1.2693,  1.3621,\n",
      "        -0.2881,  0.4913, -0.1400,  0.8554,  0.8157,  0.8504,  0.3728,  1.2428,\n",
      "        -0.8748, -0.4083,  1.3068, -0.3765,  1.1682,  1.1885, -1.2555, -0.8544,\n",
      "        -1.1036, -0.8508,  0.5045, -0.3985,  0.1223, -0.6656, -1.2519, -1.0570,\n",
      "         1.0904, -1.2845, -0.2232, -1.2900, -1.0438, -0.7249,  1.1095, -0.9162,\n",
      "        -1.2163, -0.8218,  1.1869, -0.6303,  1.0926, -0.6232,  0.1814, -0.2081,\n",
      "         0.1799,  0.7629,  1.3920, -0.2478, -1.2265, -0.7942, -1.1827, -0.7839,\n",
      "        -1.0919, -0.5488, -0.4021,  1.2877,  0.4776, -1.2678,  0.1605, -0.6078,\n",
      "         0.5476,  0.4682, -1.0892,  1.1716, -0.8738,  1.3608, -1.2061, -1.1652,\n",
      "         0.6269, -0.1464,  1.1443, -0.0768,  1.2242, -1.2588,  1.3894,  0.2601,\n",
      "        -1.2881,  0.5492,  0.6682,  0.5199, -1.2788,  0.3164, -0.3451,  1.0409,\n",
      "         1.3132, -1.1779,  1.2226, -0.6568,  0.8075,  0.5876,  0.8030,  1.2879,\n",
      "         1.3777,  0.0082,  0.2962,  1.0340, -0.4899,  0.7742, -0.1420, -1.1621,\n",
      "         1.1317, -1.2038,  0.8581, -0.4595, -0.8984, -1.1748,  0.5028,  0.6594,\n",
      "         0.5355,  1.0910,  1.0844, -0.4431,  0.6977, -0.8286, -0.4155,  0.7307,\n",
      "         1.2571,  1.3276, -0.6526,  0.5355,  1.3560,  0.0755, -0.9876,  0.8979,\n",
      "        -1.0635,  0.8406, -0.8194,  1.0309,  1.2522,  0.4963, -0.5921, -0.4355,\n",
      "         1.3061, -0.3046,  1.3723,  0.9098,  0.1864,  0.9806, -0.1071, -0.8721,\n",
      "         1.3842, -1.1115,  0.1449, -0.3389, -1.2273, -0.1387,  1.3063, -1.2799,\n",
      "        -0.9535,  0.4764,  1.3292, -0.2069, -1.0755,  0.8826,  0.5572, -1.2903,\n",
      "         0.4351,  0.8292,  0.2492,  0.6523,  1.3843, -1.1191, -0.6465, -1.2542,\n",
      "        -1.1777,  0.3688,  1.3921, -0.0651, -1.2840, -1.2835, -0.3623, -0.4245,\n",
      "        -1.1197,  1.3022, -0.7689, -1.1494, -0.1692, -0.4227,  1.2316, -0.3037,\n",
      "         0.2560,  0.6968,  0.1131, -1.2690,  1.1480, -1.2714, -0.1491,  1.3872,\n",
      "        -1.0824, -0.7351,  0.6403,  1.1325,  0.9347,  0.8666, -1.2509,  1.2903,\n",
      "        -1.1754,  0.3161,  1.2676, -1.2664,  0.3498,  1.3852, -1.2839, -1.2620,\n",
      "         0.1249, -0.1743, -1.2484, -0.4848, -0.7900, -0.2408, -1.2408,  0.6289,\n",
      "         0.9270, -0.7755,  0.1192, -0.8757,  1.3620, -0.6595,  0.4688, -1.1655,\n",
      "        -0.9590, -0.0811, -0.8968,  0.3942,  1.3785,  1.3932,  0.6466, -0.5335,\n",
      "         0.3704,  0.6116,  0.2616, -1.1968, -1.2906, -0.6531, -0.1288,  0.4666,\n",
      "         1.1848,  1.3341, -1.2296,  0.6261, -0.4008, -0.0972,  0.1760,  0.8398,\n",
      "        -0.9919,  0.2637, -1.2876,  0.3376,  0.3881,  1.2859,  0.9447,  0.8553,\n",
      "        -1.1938,  1.0249,  0.8571, -0.1140, -0.9433, -0.9796,  0.1540, -0.1450,\n",
      "        -0.0185,  1.0049, -0.8226, -0.9078,  1.1810, -1.1921,  0.0769, -1.2804,\n",
      "        -0.6356,  0.9382,  0.2002,  0.2680], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.960047669753471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/33000.0 [00:06<15:55:25,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.1\n",
      "\n",
      "Inner iteration 1000\n",
      "\th(W(model)): 0.031184839319278623\n",
      "\tscore(model): 0.35170345381406154\n",
      "\t mle: 3.174616395413385\n",
      "\t mse: 1.6189174066973087\n",
      "\tW1: tensor([[1.0000e-04, 6.4959e+00],\n",
      "        [2.6975e-02, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.031184839319278623\n",
      "\tW2: tensor([[ 1.0539, -0.0014],\n",
      "        [-0.0014,  0.9980]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0539, -0.0014],\n",
      "        [-0.0014,  0.9980]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-0.0017,  0.0000],\n",
      "        [ 0.0026, -0.0042]])\n",
      "Check y:  tensor([ 2.7471,  9.2893,  5.6259,  2.5139, -4.7408,  7.4098, -4.0003,  6.7674,\n",
      "         3.6394, -6.6155,  9.6504,  1.5426,  3.8478,  5.2764, -5.0945, -5.8625,\n",
      "        -2.7882,  8.8907,  9.7495,  7.6550,  3.0544,  9.5636, -2.6359,  9.7377,\n",
      "        -7.2838,  7.1911, -8.2838,  4.4369,  1.1056, -5.1945, -9.8288,  9.7640,\n",
      "        -2.9495,  3.8693, -2.7297,  6.2950,  6.0524,  6.2647,  4.4767,  8.5382,\n",
      "        -7.5424, -4.0307,  8.9316, -4.5798,  8.1045,  8.2214, -9.8715, -7.7291,\n",
      "        -8.8923, -7.3897,  3.9663, -3.9447,  2.6981, -6.5602, -9.8559, -8.8805,\n",
      "         7.6622, -9.9284, -2.3477, -9.9751, -8.8092, -6.9375,  7.7706, -8.0920,\n",
      "        -9.6936, -7.2018,  9.1756, -6.3315,  8.7430, -6.2848,  3.1361, -2.2068,\n",
      "         3.1246,  5.7230,  9.6297, -3.6065, -9.5789, -7.3662, -9.3331, -7.3033,\n",
      "        -8.8268, -5.2142, -4.7659,  8.8104,  3.7678, -9.8197,  1.1927, -6.1839,\n",
      "         4.2778,  5.1119, -8.8116,  8.1242, -7.8443,  9.3094, -9.4636, -9.4446,\n",
      "         4.8302, -2.7837,  8.9865, -2.1781,  8.4284, -9.7652,  9.5853,  3.6993,\n",
      "        -9.9559,  4.2891,  5.1084,  4.0785, -9.9647,  4.0914, -3.4689,  8.4874,\n",
      "         8.9732, -9.3066,  9.3252, -6.0503,  7.2139,  4.5596,  7.1880,  8.8118,\n",
      "         9.4539, -0.1821,  3.9513,  7.3411, -4.7304,  5.7945, -2.7462, -9.2188,\n",
      "         7.8967, -9.4511,  6.3113, -4.4741, -7.9884, -9.2890,  3.9536,  5.0502,\n",
      "         4.1907,  7.6653,  7.6278, -4.3336,  6.5621, -7.2460, -4.0942,  6.7610,\n",
      "         9.4601,  9.0689, -6.4765,  5.5491,  9.2722,  2.3401, -8.4988,  7.7272,\n",
      "        -8.9158,  6.2050, -7.5191,  8.4364,  9.4417,  3.9061, -5.5569, -5.0052,\n",
      "         8.9269, -3.1011,  9.4049,  7.7931,  3.1719,  8.1758, -2.4465, -7.5256,\n",
      "         9.5205, -9.1702,  1.0550, -4.3025, -9.7451, -2.7187,  9.6297, -9.9686,\n",
      "        -8.0262,  5.1659,  9.0800, -3.2813, -8.9800,  6.4586,  4.3462, -9.9908,\n",
      "         4.8941,  6.1352,  1.9558,  5.0020,  9.5222, -8.9790, -5.9729, -9.8660,\n",
      "        -9.5069,  4.4497,  9.6326, -0.8639, -9.9814, -9.9209, -4.4760, -4.1727,\n",
      "        -8.9827,  8.9020, -6.8484, -9.3652, -2.9741, -4.9137,  8.4721, -3.0922,\n",
      "         2.0135,  6.5567,  2.6289, -9.9276,  7.9896, -9.8418, -2.8061,  9.7603,\n",
      "        -8.7735, -6.6145,  4.9218,  8.9322,  6.7671,  7.5525, -9.7188,  9.5781,\n",
      "        -9.4956,  4.0896,  8.6867, -9.9171,  4.3205,  9.5319, -9.9238, -9.8989,\n",
      "         0.8779, -3.0157, -9.8406, -4.6875, -6.9910, -2.5113, -9.6603,  4.8440,\n",
      "         7.8873, -7.2518,  0.8265, -7.8550,  9.3187, -6.0703,  3.7020, -9.4465,\n",
      "        -8.3376, -1.0139, -7.6803,  4.6210,  9.7741,  9.7104,  6.2490, -5.6863,\n",
      "         2.9456,  4.7258,  3.7096, -9.4120, -9.9858, -6.4796, -2.6339,  5.1015,\n",
      "         8.1999,  9.7080, -9.5965,  4.8249, -4.7568, -1.1652,  3.0968,  7.4000,\n",
      "        -8.2539,  3.7246, -9.9905,  4.2370,  4.5797,  9.5630,  6.8257,  7.4881,\n",
      "        -9.3951,  8.4061,  6.3053, -2.5064, -7.9646, -8.4537,  2.9348, -1.6142,\n",
      "        -0.4294,  7.1743, -7.2072, -8.0432,  9.1504, -9.5778,  0.4465, -9.9703,\n",
      "        -6.3661,  7.9484,  3.2721,  3.7547], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9979312466808421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/33000.0 [00:13<28:03:53,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.1\n",
      "\n",
      "Inner iteration 2000\n",
      "\th(W(model)): 0.03178677399749974\n",
      "\tscore(model): 0.34972366357489626\n",
      "\t mle: 3.1497320893133556\n",
      "\t mse: 1.6053495388946741\n",
      "\tW1: tensor([[1.0000e-04, 6.4885e+00],\n",
      "        [2.7261e-02, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.03178677399749974\n",
      "\tW2: tensor([[ 1.0532, -0.0011],\n",
      "        [-0.0011,  0.9990]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0532, -0.0011],\n",
      "        [-0.0011,  0.9990]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-9.6645e-06,  0.0000e+00],\n",
      "        [-3.0140e-05,  2.5132e-05]])\n",
      "Check y:  tensor([ 2.7478,  9.2823,  5.6409,  2.5128, -4.7581,  7.4200, -4.0211,  6.7239,\n",
      "         3.6174, -6.6228,  9.6271,  1.5344,  3.8560,  5.2396, -5.0949, -5.8564,\n",
      "        -2.7854,  8.8554,  9.7297,  7.6119,  3.0387,  9.5382, -2.6600,  9.7173,\n",
      "        -7.2606,  7.2025, -8.2486,  4.4069,  1.0944, -5.2095, -9.8202,  9.7452,\n",
      "        -2.9732,  3.8776, -2.7261,  6.3097,  6.0674,  6.2795,  4.4464,  8.5390,\n",
      "        -7.5463, -4.0513,  8.9284, -4.5828,  8.1093,  8.2252, -9.8390, -7.7003,\n",
      "        -8.8940, -7.3940,  3.9752, -3.9657,  2.6862, -6.5461, -9.8229, -8.8407,\n",
      "         7.6705, -9.9153, -2.3719, -9.9581, -8.7698, -6.9187,  7.7782, -8.0590,\n",
      "        -9.6565, -7.2067,  9.1437, -6.3202,  8.7062, -6.2740,  3.1195, -2.2310,\n",
      "         3.1082,  5.7380,  9.6180, -3.6096, -9.5759, -7.3419, -9.3327, -7.2799,\n",
      "        -8.8286, -5.2290, -4.7681,  8.8085,  3.7754, -9.8114,  1.1821, -6.1743,\n",
      "         4.2884,  5.0762, -8.8134,  8.1288, -7.8140,  9.3022, -9.4620, -9.4046,\n",
      "         4.8432, -2.7808,  8.9523, -2.1664,  8.4302, -9.7585,  9.5744,  3.6767,\n",
      "        -9.9409,  4.2997,  5.1223,  4.0880, -9.9378,  4.0648, -3.4915,  8.4485,\n",
      "         8.9697, -9.3064,  9.2954, -6.0605,  7.1702,  4.5715,  7.1442,  8.8099,\n",
      "         9.4449, -0.2010,  3.9261,  7.3516, -4.7479,  5.8095, -2.7428, -9.2191,\n",
      "         7.9033, -9.4497,  6.3260, -4.4928, -7.9564, -9.2889,  3.9624,  5.0639,\n",
      "         4.2009,  7.6737,  7.6364, -4.3530,  6.5191, -7.2507, -4.1146,  6.7175,\n",
      "         9.4327,  9.0643, -6.4634,  5.5105,  9.2654,  2.3320, -8.4616,  7.6843,\n",
      "        -8.8758,  6.2199, -7.4929,  8.3971,  9.4139,  3.9146, -5.5698, -5.0061,\n",
      "         8.9238, -3.1245,  9.3965,  7.7505,  3.1549,  8.1348, -2.4393, -7.5295,\n",
      "         9.5106, -9.1295,  1.0434, -4.3063, -9.7090, -2.7150,  9.6058, -9.9420,\n",
      "        -8.0291,  5.1298,  9.0753, -3.2827, -8.9397,  6.4730,  4.3572, -9.9708,\n",
      "         4.8601,  6.1501,  1.9507,  5.0156,  9.5123, -8.9804, -5.9836, -9.8334,\n",
      "        -9.4674,  4.4196,  9.6209, -0.8856, -9.9565, -9.9083, -4.4794, -4.1927,\n",
      "        -8.9840,  8.8991, -6.8547, -9.3249, -2.9732, -4.9151,  8.4735, -3.1156,\n",
      "         2.0087,  6.5137,  2.6178, -9.8979,  7.9954, -9.8328, -2.8034,  9.7449,\n",
      "        -8.7754, -6.6218,  4.9351,  8.8974,  6.7805,  7.5092, -9.7133,  9.5530,\n",
      "        -9.4560,  4.0630,  8.6860, -9.8868,  4.2916,  9.5218, -9.9111, -9.8677,\n",
      "         0.8652, -3.0151, -9.8070, -4.7052, -6.9967, -2.5355, -9.6560,  4.8571,\n",
      "         7.8450, -7.2290,  0.8134, -7.8246,  9.3114, -6.0804,  3.7093, -9.4065,\n",
      "        -8.3020, -1.0361, -7.6838,  4.5894,  9.7572,  9.6970,  6.2069, -5.6819,\n",
      "         2.9477,  4.7384,  3.6869, -9.4109, -9.9671, -6.4665, -2.6292,  5.0660,\n",
      "         8.2038,  9.6864, -9.5932,  4.8379, -4.7590, -1.1878,  3.0806,  7.3564,\n",
      "        -8.2565,  3.7017, -9.9676,  4.2090,  4.5485,  9.5376,  6.8389,  7.4447,\n",
      "        -9.3942,  8.3666,  6.3201, -2.5000, -7.9676, -8.4170,  2.9204, -1.6379,\n",
      "        -0.4494,  7.1858, -7.2121, -8.0107,  9.1181, -9.5389,  0.4310, -9.9439,\n",
      "        -6.3544,  7.9064,  3.2541,  3.7315], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9989405668978113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/33000.0 [00:20<36:56:22,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.1\n",
      "\n",
      "Inner iteration 3000\n",
      "\th(W(model)): 0.032395510049452625\n",
      "\tscore(model): 0.34855942718500343\n",
      "\t mle: 3.1327794428742934\n",
      "\t mse: 1.596025960997049\n",
      "\tW1: tensor([[1.0000e-04, 6.4859e+00],\n",
      "        [2.7527e-02, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.032395510049452625\n",
      "\tW2: tensor([[ 1.0524, -0.0011],\n",
      "        [-0.0011,  0.9989]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0524, -0.0011],\n",
      "        [-0.0011,  0.9989]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-1.2057e-05,  0.0000e+00],\n",
      "        [ 9.7781e-07,  8.0649e-07]])\n",
      "Check y:  tensor([ 2.7509,  9.2790,  5.6434,  2.5155, -4.7580,  7.4158, -4.0236,  6.7186,\n",
      "         3.6216, -6.6158,  9.6306,  1.5346,  3.8605,  5.2381, -5.1020, -5.8612,\n",
      "        -2.7872,  8.8541,  9.7335,  7.6066,  3.0442,  9.5411, -2.6655,  9.7211,\n",
      "        -7.2587,  7.1992, -8.2425,  4.4085,  1.0934, -5.2075, -9.8245,  9.7489,\n",
      "        -2.9782,  3.8821, -2.7274,  6.3100,  6.0686,  6.2799,  4.4479,  8.5326,\n",
      "        -7.5386, -4.0537,  8.9230, -4.5906,  8.1031,  8.2188, -9.8372, -7.6963,\n",
      "        -8.8920, -7.3861,  3.9797, -3.9683,  2.6919, -6.5478, -9.8209, -8.8334,\n",
      "         7.6655, -9.9194, -2.3777, -9.9616, -8.7625, -6.9185,  7.7728, -8.0534,\n",
      "        -9.6523, -7.1989,  9.1441, -6.3230,  8.7042, -6.2770,  3.1249, -2.2369,\n",
      "         3.1135,  5.7403,  9.6184, -3.6160, -9.5791, -7.3396, -9.3342, -7.2778,\n",
      "        -8.8262, -5.2270, -4.7758,  8.8026,  3.7799, -9.8157,  1.1814, -6.1777,\n",
      "         4.2930,  5.0753, -8.8109,  8.1226, -7.8095,  9.2991, -9.4645, -9.3986,\n",
      "         4.8474, -2.7825,  8.9515, -2.1623,  8.4238, -9.7627,  9.5742,  3.6808,\n",
      "        -9.9447,  4.3043,  5.1260,  4.0926, -9.9382,  4.0676, -3.4954,  8.4453,\n",
      "         8.9644, -9.3076,  9.2968, -6.0552,  7.1646,  4.5759,  7.1386,  8.8040,\n",
      "         9.4431, -0.2050,  3.9294,  7.3477, -4.7477,  5.8116, -2.7443, -9.2197,\n",
      "         7.8975, -9.4521,  6.3263, -4.4937, -7.9513, -9.2901,  3.9669,  5.0678,\n",
      "         4.2054,  7.6686,  7.6315, -4.3543,  6.5140, -7.2429, -4.1168,  6.7122,\n",
      "         9.4349,  9.0596, -6.4655,  5.5080,  9.2620,  2.3373, -8.4549,  7.6791,\n",
      "        -8.8685,  6.2205, -7.4898,  8.3937,  9.4160,  3.9191, -5.5664, -5.0135,\n",
      "         8.9184, -3.1293,  9.3943,  7.7454,  3.1602,  8.1305, -2.4380, -7.5217,\n",
      "         9.5096, -9.1224,  1.0424, -4.3141, -9.7053, -2.7163,  9.6091, -9.9426,\n",
      "        -8.0224,  5.1287,  9.0706, -3.2877, -8.9325,  6.4726,  4.3617, -9.9735,\n",
      "         4.8600,  6.1510,  1.9520,  5.0195,  9.5113, -8.9791, -5.9786, -9.8315,\n",
      "        -9.4617,  4.4212,  9.6213, -0.8908, -9.9576, -9.9124, -4.4872, -4.1946,\n",
      "        -8.9828,  8.8936, -6.8473, -9.3184, -2.9763, -4.9226,  8.4671, -3.1204,\n",
      "         2.0102,  6.5087,  2.6234, -9.8973,  7.9894, -9.8371, -2.8053,  9.7476,\n",
      "        -8.7726, -6.6149,  4.9392,  8.8963,  6.7789,  7.5037, -9.7173,  9.5560,\n",
      "        -9.4503,  4.0658,  8.6798, -9.8860,  4.2936,  9.5209, -9.9152, -9.8664,\n",
      "         0.8636, -3.0186, -9.8047, -4.7052, -6.9891, -2.5411, -9.6597,  4.8612,\n",
      "         7.8401, -7.2273,  0.8118, -7.8201,  9.3083, -6.0750,  3.7137, -9.4005,\n",
      "        -8.2956, -1.0415, -7.6763,  4.5903,  9.7605,  9.6986,  6.2025, -5.6873,\n",
      "         2.9511,  4.7427,  3.6909, -9.4130, -9.9702, -6.4686, -2.6297,  5.0651,\n",
      "         8.1975,  9.6901, -9.5966,  4.8421, -4.7667, -1.1934,  3.0860,  7.3508,\n",
      "        -8.2507,  3.7057, -9.9694,  4.2113,  4.5495,  9.5405,  6.8370,  7.4392,\n",
      "        -9.3962,  8.3631,  6.3203, -2.4994, -7.9608, -8.4103,  2.9260, -1.6438,\n",
      "        -0.4539,  7.1826, -7.2043, -8.0053,  9.1184, -9.5337,  0.4284, -9.9445,\n",
      "        -6.3570,  7.9016,  3.2592,  3.7354], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.998926390166191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/33000.0 [00:27<45:36:51,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.1\n",
      "\n",
      "Inner iteration 4000\n",
      "\th(W(model)): 0.032778449320728154\n",
      "\tscore(model): 0.34775884718382827\n",
      "\t mle: 3.121452818249948\n",
      "\t mse: 1.5898066136410025\n",
      "\tW1: tensor([[1.0000e-04, 6.4848e+00],\n",
      "        [2.7692e-02, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.032778449320728154\n",
      "\tW2: tensor([[ 1.0519, -0.0011],\n",
      "        [-0.0011,  0.9989]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0519, -0.0011],\n",
      "        [-0.0011,  0.9989]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-1.2321e-05,  0.0000e+00],\n",
      "        [ 6.5528e-07,  3.3542e-07]])\n",
      "Check y:  tensor([ 2.7537,  9.2781,  5.6444,  2.5181, -4.7586,  7.4121, -4.0258,  6.7154,\n",
      "         3.6247, -6.6117,  9.6327,  1.5358,  3.8638,  5.2386, -5.1058, -5.8635,\n",
      "        -2.7886,  8.8519,  9.7364,  7.6024,  3.0466,  9.5426, -2.6692,  9.7239,\n",
      "        -7.2573,  7.1960, -8.2387,  4.4109,  1.0939, -5.2070, -9.8270,  9.7519,\n",
      "        -2.9818,  3.8854, -2.7287,  6.3092,  6.0685,  6.2792,  4.4502,  8.5286,\n",
      "        -7.5336, -4.0559,  8.9202, -4.5949,  8.0987,  8.2144, -9.8365, -7.6937,\n",
      "        -8.8902, -7.3811,  3.9830, -3.9707,  2.6931, -6.5484, -9.8200, -8.8292,\n",
      "         7.6614, -9.9219, -2.3815, -9.9638, -8.7583, -6.9181,  7.7686, -8.0500,\n",
      "        -9.6501, -7.1940,  9.1432, -6.3242,  8.7015, -6.2783,  3.1274, -2.2407,\n",
      "         3.1161,  5.7410,  9.6201, -3.6198, -9.5807, -7.3379, -9.3345, -7.2764,\n",
      "        -8.8240, -5.2264, -4.7800,  8.7993,  3.7832, -9.8182,  1.1820, -6.1793,\n",
      "         4.2961,  5.0762, -8.8087,  8.1182, -7.8066,  9.2983, -9.4654, -9.3953,\n",
      "         4.8499, -2.7840,  8.9498, -2.1608,  8.4196, -9.7650,  9.5755,  3.6839,\n",
      "        -9.9470,  4.3074,  5.1281,  4.0958, -9.9388,  4.0704, -3.4985,  8.4420,\n",
      "         8.9618, -9.3078,  9.2967, -6.0524,  7.1607,  4.5788,  7.1348,  8.8008,\n",
      "         9.4434, -0.2069,  3.9324,  7.3442, -4.7484,  5.8121, -2.7456, -9.2195,\n",
      "         7.8932, -9.4530,  6.3254, -4.4949, -7.9481, -9.2902,  3.9702,  5.0699,\n",
      "         4.2086,  7.6645,  7.6274, -4.3559,  6.5113, -7.2379, -4.1188,  6.7090,\n",
      "         9.4357,  9.0574, -6.4663,  5.5078,  9.2610,  2.3368, -8.4509,  7.6749,\n",
      "        -8.8643,  6.2200, -7.4877,  8.3902,  9.4166,  3.9224, -5.5649, -5.0174,\n",
      "         8.9155, -3.1328,  9.3942,  7.7412,  3.1629,  8.1266, -2.4380, -7.5167,\n",
      "         9.5103, -9.1185,  1.0427, -4.3184, -9.7035, -2.7175,  9.6111, -9.9433,\n",
      "        -8.0178,  5.1295,  9.0684, -3.2908, -8.9283,  6.4714,  4.3648, -9.9753,\n",
      "         4.8615,  6.1507,  1.9539,  5.0218,  9.5121, -8.9777, -5.9760, -9.8307,\n",
      "        -9.4586,  4.4235,  9.6231, -0.8936, -9.9587, -9.9149, -4.4915, -4.1966,\n",
      "        -8.9813,  8.8906, -6.8428, -9.3149, -2.9785, -4.9267,  8.4630, -3.1239,\n",
      "         2.0121,  6.5059,  2.6244, -9.8973,  7.9850, -9.8396, -2.8069,  9.7505,\n",
      "        -8.7703, -6.6108,  4.9415,  8.8943,  6.7768,  7.4996, -9.7194,  9.5576,\n",
      "        -9.4471,  4.0687,  8.6762, -9.8858,  4.2962,  9.5218, -9.9177, -9.8660,\n",
      "         0.8637, -3.0209, -9.8037, -4.7060, -6.9844, -2.5449, -9.6616,  4.8637,\n",
      "         7.8359, -7.2259,  0.8117, -7.8172,  9.3076, -6.0722,  3.7170, -9.3972,\n",
      "        -8.2918, -1.0445, -7.6713,  4.5923,  9.7636,  9.7010,  6.2004, -5.6901,\n",
      "         2.9542,  4.7453,  3.6940, -9.4137, -9.9722, -6.4694, -2.6305,  5.0660,\n",
      "         8.1931,  9.6927, -9.5982,  4.8446, -4.7709, -1.1966,  3.0885,  7.3468,\n",
      "        -8.2466,  3.7088, -9.9708,  4.2140,  4.5517,  9.5420,  6.8348,  7.4351,\n",
      "        -9.3968,  8.3596,  6.3195, -2.4996, -7.9561, -8.4063,  2.9281, -1.6473,\n",
      "        -0.4561,  7.1794, -7.1993, -8.0020,  9.1174, -9.5310,  0.4277, -9.9453,\n",
      "        -6.3581,  7.8974,  3.2620,  3.7385], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9989171004675834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/33000.0 [00:35<52:21:17,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.1\n",
      "\n",
      "Inner iteration 4999\n",
      "\th(W(model)): 0.03304607095355738\n",
      "\tscore(model): 0.3471877432419427\n",
      "\t mle: 3.1134228228255996\n",
      "\t mse: 1.5853992267245842\n",
      "\tW1: tensor([[1.0000e-04, 6.4839e+00],\n",
      "        [2.7806e-02, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.03304607095355738\n",
      "\tW2: tensor([[ 1.0516, -0.0011],\n",
      "        [-0.0011,  0.9989]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0516, -0.0011],\n",
      "        [-0.0011,  0.9989]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-1.2393e-05,  0.0000e+00],\n",
      "        [ 6.3639e-07,  2.8165e-07]])\n",
      "Check y:  tensor([ 2.7558,  9.2777,  5.6447,  2.5200, -4.7592,  7.4095, -4.0273,  6.7134,\n",
      "         3.6269, -6.6093,  9.6339,  1.5369,  3.8659,  5.2392, -5.1078, -5.8647,\n",
      "        -2.7900,  8.8501,  9.7382,  7.5995,  3.0481,  9.5433, -2.6715,  9.7256,\n",
      "        -7.2563,  7.1937, -8.2366,  4.4128,  1.0945, -5.2069, -9.8283,  9.7538,\n",
      "        -2.9840,  3.8876, -2.7299,  6.3084,  6.0682,  6.2785,  4.4520,  8.5260,\n",
      "        -7.5305, -4.0573,  8.9185, -4.5972,  8.0957,  8.2115, -9.8361, -7.6921,\n",
      "        -8.8888, -7.3781,  3.9851, -3.9722,  2.6937, -6.5485, -9.8195, -8.8268,\n",
      "         7.6585, -9.9232, -2.3838, -9.9649, -8.7560, -6.9176,  7.7656, -8.0481,\n",
      "        -9.6489, -7.1911,  9.1423, -6.3247,  8.6994, -6.2789,  3.1291, -2.2429,\n",
      "         3.1177,  5.7413,  9.6215, -3.6219, -9.5814, -7.3369, -9.3345, -7.2754,\n",
      "        -8.8226, -5.2263, -4.7821,  8.7973,  3.7854, -9.8195,  1.1827, -6.1800,\n",
      "         4.2980,  5.0772, -8.8071,  8.1152, -7.8050,  9.2980, -9.4658, -9.3934,\n",
      "         4.8513, -2.7853,  8.9482, -2.1610,  8.4168, -9.7662,  9.5766,  3.6861,\n",
      "        -9.9483,  4.3093,  5.1292,  4.0979, -9.9392,  4.0726, -3.5004,  8.4394,\n",
      "         8.9602, -9.3077,  9.2963, -6.0509,  7.1581,  4.5805,  7.1323,  8.7987,\n",
      "         9.4438, -0.2077,  3.9346,  7.3417, -4.7490,  5.8122, -2.7468, -9.2191,\n",
      "         7.8902, -9.4533,  6.3246, -4.4959, -7.9463, -9.2900,  3.9723,  5.0711,\n",
      "         4.2106,  7.6616,  7.6246, -4.3570,  6.5096, -7.2349, -4.1202,  6.7070,\n",
      "         9.4359,  9.0562, -6.4666,  5.5079,  9.2605,  2.3359, -8.4486,  7.6720,\n",
      "        -8.8620,  6.2194, -7.4865,  8.3876,  9.4168,  3.9246, -5.5642, -5.0194,\n",
      "         8.9139, -3.1349,  9.3944,  7.7383,  3.1645,  8.1238, -2.4387, -7.5136,\n",
      "         9.5111, -9.1163,  1.0433, -4.3207, -9.7025, -2.7187,  9.6121, -9.9437,\n",
      "        -8.0149,  5.1303,  9.0672, -3.2927, -8.9260,  6.4703,  4.3667, -9.9763,\n",
      "         4.8628,  6.1502,  1.9553,  5.0230,  9.5129, -8.9766, -5.9745, -9.8303,\n",
      "        -9.4569,  4.4254,  9.6244, -0.8952, -9.9592, -9.9162, -4.4938, -4.1978,\n",
      "        -8.9803,  8.8889, -6.8401, -9.3129, -2.9801, -4.9287,  8.4603, -3.1260,\n",
      "         2.0137,  6.5042,  2.6247, -9.8973,  7.9820, -9.8409, -2.8083,  9.7526,\n",
      "        -8.7686, -6.6084,  4.9429,  8.8926,  6.7752,  7.4968, -9.7205,  9.5584,\n",
      "        -9.4454,  4.0708,  8.6739, -9.8857,  4.2982,  9.5226, -9.9190, -9.8658,\n",
      "         0.8640, -3.0225, -9.8031, -4.7066, -6.9816, -2.5472, -9.6626,  4.8652,\n",
      "         7.8330, -7.2250,  0.8120, -7.8155,  9.3074, -6.0706,  3.7192, -9.3953,\n",
      "        -8.2896, -1.0462, -7.6682,  4.5940,  9.7656,  9.7028,  6.1993, -5.6914,\n",
      "         2.9563,  4.7469,  3.6962, -9.4140, -9.9733, -6.4696, -2.6316,  5.0670,\n",
      "         8.1902,  9.6942, -9.5990,  4.8461, -4.7731, -1.1983,  3.0901,  7.3440,\n",
      "        -8.2439,  3.7110, -9.9715,  4.2161,  4.5534,  9.5427,  6.8330,  7.4323,\n",
      "        -9.3970,  8.3569,  6.3187, -2.5005, -7.9531, -8.4041,  2.9293, -1.6494,\n",
      "        -0.4572,  7.1771, -7.1964, -8.0001,  9.1163, -9.5294,  0.4275, -9.9456,\n",
      "        -6.3585,  7.8945,  3.2638,  3.7407], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9989117769794507\n",
      "\n",
      "Dagma iter t=2 -- mu: 0.010000000000000002 ------------------------------\n",
      "success:  False\n",
      "\n",
      "Minimize s=1.0 -- lr=0.0075\n",
      "\n",
      "mu 0.010000000000000002\n",
      "\n",
      "Inner iteration 0\n",
      "\th(W(model)): 0.03304632585827871\n",
      "\tscore(model): 0.06686031860402612\n",
      "\t mle: 4.504377601599301\n",
      "\t mse: 2.2931868712645382\n",
      "\tW1: tensor([[1.0000e-04, 6.4839e+00],\n",
      "        [2.7806e-02, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.03304632585827871\n",
      "\tW2: tensor([[ 1.0516, -0.0011],\n",
      "        [-0.0011,  0.9989]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0359, 0.0065],\n",
      "        [0.0065, 1.0141]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[ 0.1954,  0.0000],\n",
      "        [-0.0041, -0.0038]])\n",
      "Check y:  tensor([ 2.5283,  7.9778,  4.9638,  2.3254, -4.0451,  6.4053, -3.4056,  6.3268,\n",
      "         3.7662, -5.6520,  8.4847,  1.4748,  3.4759,  5.1273, -5.0981, -5.7435,\n",
      "        -3.0414,  7.9686,  8.5253,  7.0259,  3.2626,  8.4350, -2.2159,  8.5228,\n",
      "        -6.8935,  6.2298, -7.6680,  4.4365,  1.0897, -4.4352, -8.5748,  8.5252,\n",
      "        -2.4905,  3.4942, -2.9864,  5.5088,  5.3121,  5.4843,  4.4696,  7.3235,\n",
      "        -6.4511, -3.4319,  7.6582, -4.6555,  6.9660,  7.0616, -8.7827, -7.2421,\n",
      "        -7.6544, -6.3185,  3.5768, -3.3574,  2.9492, -6.3149, -8.7747, -8.1134,\n",
      "         6.6080, -8.6928, -1.9628, -8.7597, -8.0610, -6.6184,  6.6954, -7.5219,\n",
      "        -8.6792, -6.1562,  8.1749, -6.1292,  7.8592, -6.0910,  3.3336, -1.8390,\n",
      "         3.3237,  5.0434,  8.3123, -3.7939, -8.3120, -6.9584, -8.0700, -6.9089,\n",
      "        -7.5940, -4.4521, -4.8165,  7.5537,  3.4076, -8.5647,  1.1666, -6.0084,\n",
      "         3.8410,  4.9928, -7.5800,  6.9820, -7.3314,  7.9965, -8.1972, -8.5149,\n",
      "         4.3051, -3.0371,  8.0388, -2.4605,  7.2321, -8.5052,  8.2652,  3.8172,\n",
      "        -8.7300,  3.8505,  4.5368,  3.6722, -8.8194,  4.1481, -2.9439,  7.6671,\n",
      "         7.6945, -8.0444,  8.2793, -5.1682,  6.6800,  4.0785,  6.6596,  7.5549,\n",
      "         8.1335, -0.0495,  4.0303,  6.3501, -4.0363,  5.1018, -3.0019, -7.9604,\n",
      "         6.7973, -8.1849,  5.5221, -3.8153, -7.4424, -8.0275,  3.5660,  4.4884,\n",
      "         3.7673,  6.6105,  6.5803, -3.6940,  6.1635, -6.1942, -3.4869,  6.3217,\n",
      "         8.3697,  7.7787, -6.2471,  5.3490,  7.9620,  2.6283, -7.8302,  7.0821,\n",
      "        -8.1392,  5.4360, -7.0784,  7.6284,  8.3576,  3.5256, -4.7459, -5.0219,\n",
      "         7.6542, -2.6231,  8.0864,  7.1335,  3.3647,  7.4292, -2.7184, -6.4364,\n",
      "         8.1992, -8.3228,  1.0451, -4.4134, -8.7111, -2.9761,  8.4734, -8.8199,\n",
      "        -6.8745,  5.0370,  7.7885, -3.4982, -8.1859,  5.6410,  3.8988, -8.7936,\n",
      "         4.8143,  5.3793,  1.8378,  4.4484,  8.2009, -7.7348, -5.1020, -8.7799,\n",
      "        -8.5572,  4.4472,  8.3154, -0.6533, -8.8194, -8.6832, -4.5652, -3.5548,\n",
      "        -7.7382,  7.6325, -5.8519, -8.4602, -3.2149, -4.9436,  7.2684, -2.6153,\n",
      "         1.8883,  6.1591,  2.8877, -8.8085,  6.8725, -8.5894, -3.0581,  8.4739,\n",
      "        -7.5451, -5.6512,  4.3816,  7.9992,  5.8895,  6.9458, -8.4559,  8.4437,\n",
      "        -8.5495,  4.1466,  7.4484, -8.8042,  4.3396,  8.2106, -8.6869, -8.7961,\n",
      "         0.8887, -3.2535, -8.7664, -3.9993, -5.9745, -2.1065, -8.3950,  4.3167,\n",
      "         7.2066, -6.8682,  0.8433, -7.3396,  8.0051, -5.1853,  3.3514, -8.5161,\n",
      "        -7.7088, -0.7861, -6.5711,  4.5891,  8.5062,  8.4045,  5.9132, -5.5969,\n",
      "         2.7004,  4.2179,  3.8259, -8.1466, -8.7800, -6.2496, -2.8962,  4.9844,\n",
      "         7.0439,  8.5123, -8.3298,  4.3008, -4.8086, -0.9199,  3.2995,  6.8263,\n",
      "        -7.0762,  3.8386, -8.8132,  4.2700,  4.5550,  8.4346,  5.9366,  6.8954,\n",
      "        -8.1301,  7.6054,  5.5172, -2.7754, -6.8202, -7.7963,  3.1580, -1.3167,\n",
      "        -0.2685,  6.2163, -6.1608, -7.4845,  8.1570, -8.6044,  0.5072, -8.8200,\n",
      "        -6.1573,  7.2540,  3.4514,  3.8642], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9989117736033535\n",
      "Found h negative -1.8038524430750227 at iter 2\n",
      "success:  False\n",
      "\n",
      "Minimize s=1 -- lr=0.00375\n",
      "\n",
      "mu 0.010000000000000002\n",
      "\n",
      "Inner iteration 0\n",
      "\th(W(model)): 0.03304632585827871\n",
      "\tscore(model): 0.06686031860402612\n",
      "\t mle: 3.628963916260275\n",
      "\t mse: 1.846800527558697\n",
      "\tW1: tensor([[1.0000e-04, 6.4839e+00],\n",
      "        [2.7806e-02, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.03304632585827871\n",
      "\tW2: tensor([[ 1.0516, -0.0011],\n",
      "        [-0.0011,  0.9989]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0437, 0.0027],\n",
      "        [0.0027, 1.0065]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[ 0.1954,  0.0000],\n",
      "        [-0.0041, -0.0038]])\n",
      "Check y:  tensor([ 2.6420,  8.6278,  5.3043,  2.4227, -4.4022,  6.9074, -3.7164,  6.5201,\n",
      "         3.6966, -6.1307,  9.0593,  1.5059,  3.6709,  5.1832, -5.1029, -5.8041,\n",
      "        -2.9157,  8.4094,  9.1317,  7.3127,  3.1553,  8.9891, -2.4437,  9.1242,\n",
      "        -7.0749,  6.7117, -7.9523,  4.4246,  1.0921, -4.8210, -9.2015,  9.1395,\n",
      "        -2.7373,  3.6909, -2.8582,  5.9086,  5.6901,  5.8814,  4.4608,  7.9248,\n",
      "        -6.9908, -3.7446,  8.2883, -4.6263,  7.5308,  7.6365, -9.3094, -7.4671,\n",
      "        -8.2716, -6.8483,  3.7810, -3.6648,  2.8214, -6.4317, -9.2971, -8.4701,\n",
      "         7.1333, -9.3080, -2.1733, -9.3623, -8.4085, -6.7680,  7.2305, -7.7850,\n",
      "        -9.1641, -6.6736,  8.6586, -6.2269,  8.2793, -6.1850,  3.2314, -2.0409,\n",
      "         3.2207,  5.3923,  8.9669, -3.7079, -8.9467, -7.1476, -8.7023, -7.0921,\n",
      "        -8.2083, -4.8392, -4.7993,  8.1755,  3.5965, -9.1921,  1.1746, -6.0942,\n",
      "         4.0695,  5.0350, -8.1936,  7.5486, -7.5682,  8.6472, -8.8315, -8.9541,\n",
      "         4.5782, -2.9112,  8.4935, -2.3107,  7.8245, -9.1357,  8.9209,  3.7516,\n",
      "        -9.3391,  4.0799,  4.8330,  3.8850, -9.3793,  4.1103, -3.2222,  8.0532,\n",
      "         8.3274, -8.6761,  8.7878, -5.6095,  6.9191,  4.3295,  6.8959,  8.1768,\n",
      "         8.7887, -0.1286,  3.9825,  6.8459, -4.3926,  5.4570, -2.8744, -8.5897,\n",
      "         7.3438, -8.8191,  5.9233, -4.1556, -7.6943, -8.6588,  3.7692,  4.7798,\n",
      "         3.9890,  7.1361,  7.1025, -4.0255,  6.3365, -6.7146, -3.8036,  6.5143,\n",
      "         8.9028,  8.4174, -6.3568,  5.4285,  8.6113,  2.4821, -8.1394,  7.3771,\n",
      "        -8.5006,  5.8277, -7.2824,  8.0080,  8.8872,  3.7251, -5.1550, -5.0206,\n",
      "         8.2840, -2.8790,  8.7404,  7.4359,  3.2646,  7.7765, -2.5785, -6.9750,\n",
      "         8.8551, -8.7195,  1.0442, -4.3671, -9.2068, -2.8474,  9.0428, -9.3818,\n",
      "        -7.4447,  5.0837,  8.4279, -3.3955, -8.5560,  6.0557,  4.1327, -9.3849,\n",
      "         4.8385,  5.7648,  1.8965,  4.7357,  8.8569, -8.3557, -5.5383, -9.3051,\n",
      "        -9.0070,  4.4363,  8.9699, -0.7742, -9.3893, -9.2997, -4.5295, -3.8763,\n",
      "        -8.3592,  8.2607, -6.3460, -8.8865, -3.0975, -4.9361,  7.8644, -2.8707,\n",
      "         1.9510,  6.3317,  2.7562, -9.3529,  7.4273, -9.2152, -2.9332,  9.1132,\n",
      "        -8.1569, -6.1298,  4.6622,  8.4459,  6.3323,  7.2213, -9.0882,  9.0010,\n",
      "        -8.9975,  4.1087,  8.0611, -9.3450,  4.3189,  8.8666, -9.3030, -9.3309,\n",
      "         0.8764, -3.1380, -9.2848, -4.3529, -6.4781, -2.3269, -9.0288,  4.5909,\n",
      "         7.5198, -7.0466,  0.8276, -7.5776,  8.6563, -5.6279,  3.5353, -8.9557,\n",
      "        -7.9992, -0.9161, -7.1197,  4.5916,  9.1359,  9.0536,  6.0562, -5.6442,\n",
      "         2.8283,  4.4824,  3.7611, -8.7803, -9.3766, -6.3596, -2.7639,  5.0257,\n",
      "         7.6171,  9.1033, -8.9644,  4.5734, -4.7908, -1.0591,  3.1948,  7.0852,\n",
      "        -7.6601,  3.7748, -9.3923,  4.2431,  4.5542,  8.9887,  6.3848,  7.1638,\n",
      "        -8.7636,  7.9811,  5.9180, -2.6379, -7.3867, -8.1002,  3.0436, -1.4830,\n",
      "        -0.3629,  6.6967, -6.6786, -7.7423,  8.6366, -9.0669,  0.4673, -9.3828,\n",
      "        -6.2579,  7.5742,  3.3576,  3.8024], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9989117736033535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/33000.0 [00:42<36:00:17,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.010000000000000002\n",
      "\n",
      "Inner iteration 1000\n",
      "\th(W(model)): 0.003042193621690892\n",
      "\tscore(model): 0.0408940004942533\n",
      "\t mle: 3.775998668013667\n",
      "\t mse: 1.8959479383758928\n",
      "\tW1: tensor([[1.0000e-04, 6.4722e+00],\n",
      "        [8.5155e-03, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.003042193621690892\n",
      "\tW2: tensor([[ 1.0089e+00, -7.1827e-05],\n",
      "        [-7.1827e-05,  9.9995e-01]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0089e+00, -7.1193e-05],\n",
      "        [-7.1193e-05,  9.9994e-01]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[ 3.8173e-05,  0.0000e+00],\n",
      "        [-1.3383e-05,  1.7597e-04]])\n",
      "Check y:  tensor([  2.8067,   9.2699,   5.6777,   2.5682,  -4.8379,   7.3919,  -4.1084,\n",
      "          6.6752,   3.6128,  -6.6444,   9.7192,   1.5691,   3.9217,   5.1777,\n",
      "         -5.0426,  -5.8036,  -2.8173,   8.9128,   9.8157,   7.5978,   3.0730,\n",
      "          9.6297,  -2.7388,   9.8050,  -7.2378,   7.1822,  -8.2662,   4.3648,\n",
      "          1.1173,  -5.2801,  -9.8299,   9.8278,  -3.0562,   3.9433,  -2.7619,\n",
      "          6.3237,   6.0903,   6.2946,   4.4029,   8.4929,  -7.5282,  -4.1385,\n",
      "          8.8928,  -4.5383,   8.0639,   8.1786,  -9.9133,  -7.6939,  -8.8471,\n",
      "         -7.3821,   4.0406,  -4.0532,   2.7485,  -6.5034,  -9.8977,  -8.8862,\n",
      "          7.6346,  -9.9430,  -2.4458,  -9.9992,  -8.8119,  -6.8852,   7.7394,\n",
      "         -8.0679,  -9.7321,  -7.2029,   9.2183,  -6.2731,   8.7545,  -6.2262,\n",
      "          3.1478,  -2.3022,   3.1373,   5.7719,   9.6483,  -3.5967,  -9.5577,\n",
      "         -7.3219,  -9.2985,  -7.2577,  -8.7812,  -5.2992,  -4.7201,   8.7682,\n",
      "          3.8413,  -9.8197,   1.2074,  -6.1249,   4.3519,   5.0166,  -8.7659,\n",
      "          8.0832,  -7.8123,   9.2916,  -9.4353,  -9.4740,   4.8993,  -2.8130,\n",
      "          9.0156,  -2.2430,   8.3833,  -9.7595,   9.5972,   3.6687,  -9.9756,\n",
      "          4.3631,   5.1728,   4.1529, -10.0041,   4.0367,  -3.5787,   8.4809,\n",
      "          8.9360,  -9.2708,   9.3780,  -6.1047,   7.1366,   4.6318,   7.1097,\n",
      "          8.7697,   9.4495,  -0.2171,   3.9047,   7.3260,  -4.8278,   5.8411,\n",
      "         -2.7775,  -9.1799,   7.8615,  -9.4221,   6.3394,  -4.5764,  -7.9608,\n",
      "         -9.2526,   4.0278,   5.1157,   4.2650,   7.6377,   7.6015,  -4.4380,\n",
      "          6.4650,  -7.2450,  -4.2015,   6.6686,   9.5212,   9.0358,  -6.4190,\n",
      "          5.4464,   9.2515,   2.4255,  -8.4891,   7.6738,  -8.9229,   6.2372,\n",
      "         -7.4784,   8.4263,   9.5016,   3.9802,  -5.6306,  -4.9548,   8.8880,\n",
      "         -3.2092,   9.3956,   7.7433,   3.1806,   8.1486,  -2.4950,  -7.5120,\n",
      "          9.5238,  -9.1881,   1.0649,  -4.2684,  -9.7850,  -2.7516,   9.6980,\n",
      "        -10.0076,  -7.9935,   5.0694,   9.0474,  -3.2856,  -8.9899,   6.4808,\n",
      "          4.4200, -10.0209,   4.8047,   6.1700,   1.9952,   5.0684,   9.5257,\n",
      "         -8.9347,  -6.0306,  -9.9079,  -9.5388,   4.3771,   9.6517,  -0.9225,\n",
      "        -10.0188,  -9.9343,  -4.4371,  -4.2791,  -8.9384,   8.8622,  -6.8663,\n",
      "         -9.3914,  -2.9934,  -4.8649,   8.4268,  -3.2002,   2.0545,   6.4595,\n",
      "          2.6859,  -9.9689,   7.9518,  -9.8444,  -2.8342,   9.8078,  -8.7277,\n",
      "         -6.6435,   4.9895,   8.9574,   6.7764,   7.4902,  -9.7087,   9.6447,\n",
      "         -9.5271,   4.0350,   8.6424,  -9.9587,   4.2539,   9.5366,  -9.9377,\n",
      "         -9.9407,   0.8815,  -3.0329,  -9.8823,  -4.7858,  -7.0021,  -2.6123,\n",
      "         -9.6453,   4.9129,   7.8428,  -7.2051,   0.8283,  -7.8234,   9.3016,\n",
      "         -6.1238,   3.7751,  -9.4760,  -8.3220,  -1.0774,  -7.6603,   4.5412,\n",
      "          9.8299,   9.7441,   6.1468,  -5.6281,   3.0090,   4.7963,   3.6783,\n",
      "         -9.3810, -10.0133,  -6.4221,  -2.6715,   5.0065,   8.1574,   9.7766,\n",
      "         -9.5766,   4.8941,  -4.7112,  -1.2334,   3.1118,   7.3305,  -8.2147,\n",
      "          3.6923, -10.0253,   4.1746,   4.5016,   9.6291,   6.8325,   7.4227,\n",
      "         -9.3633,   8.3940,   6.3337,  -2.5514,  -7.9340,  -8.4423,   2.9637,\n",
      "         -1.6955,  -0.4731,   7.1661,  -7.2080,  -8.0175,   9.1913,  -9.6123,\n",
      "          0.4344, -10.0091,  -6.3079,   7.9074,   3.2728,   3.7204],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9999511443663645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 12/33000.0 [00:49<41:12:38,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.010000000000000002\n",
      "\n",
      "Inner iteration 2000\n",
      "\th(W(model)): 0.0020117820942555653\n",
      "\tscore(model): 0.040045470331335514\n",
      "\t mle: 3.7939846048040007\n",
      "\t mse: 1.9051562224749687\n",
      "\tW1: tensor([[1.0000e-04, 6.5529e+00],\n",
      "        [6.8412e-03, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.0020117820942555653\n",
      "\tW2: tensor([[ 1.0090e+00, -1.0507e-05],\n",
      "        [-1.0507e-05,  9.9986e-01]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0090e+00, -1.0593e-05],\n",
      "        [-1.0593e-05,  9.9986e-01]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-5.5912e-06,  0.0000e+00],\n",
      "        [ 2.5311e-08, -3.6514e-06]])\n",
      "Check y:  tensor([  2.7471,   9.3070,   5.6607,   2.5099,  -4.7793,   7.4407,  -4.0474,\n",
      "          6.7490,   3.5675,  -6.6298,   9.6687,   1.5222,   3.8653,   5.2385,\n",
      "         -5.0800,  -5.8556,  -2.7094,   8.8979,   9.7692,   7.6467,   2.9649,\n",
      "          9.5806,  -2.6919,   9.7572,  -7.2779,   7.2236,  -8.2735,   4.3839,\n",
      "          1.0781,  -5.2270,  -9.8493,   9.7840,  -3.0044,   3.8871,  -2.6482,\n",
      "          6.3309,   6.0884,   6.3007,   4.4246,   8.5593,  -7.5506,  -4.0775,\n",
      "          8.9502,  -4.5567,   8.1293,   8.2452,  -9.8717,  -7.7214,  -8.9073,\n",
      "         -7.3983,   3.9854,  -3.9924,   2.5958,  -6.5554,  -9.8555,  -8.8687,\n",
      "          7.6910,  -9.9465,  -2.4042,  -9.9903,  -8.7974,  -6.9325,   7.7985,\n",
      "         -8.0826,  -9.6882,  -7.2114,   9.1868,  -6.3265,   8.7482,  -6.2796,\n",
      "          3.0493,  -2.2634,   3.0374,   5.7582,   9.6485,  -3.5583,  -9.6002,\n",
      "         -7.3600,  -9.3527,  -7.2974,  -8.8411,  -5.2464,  -4.7462,   8.8296,\n",
      "          3.7841,  -9.8404,   1.1666,  -6.1784,   4.3010,   5.0713,  -8.8256,\n",
      "          8.1488,  -7.8360,   9.3272,  -9.4843,  -9.4352,   4.8595,  -2.7046,\n",
      "          8.9950,  -2.0704,   8.4504,  -9.7864,   9.6038,   3.6291,  -9.9726,\n",
      "          4.3125,   5.1401,   4.0992,  -9.9708,   4.0309,  -3.5207,   8.4893,\n",
      "          8.9917,  -9.3259,   9.3386,  -6.0712,   7.2006,   4.5861,   7.1744,\n",
      "          8.8311,   9.4719,  -0.2270,   3.8875,   7.3725,  -4.7691,   5.8299,\n",
      "         -2.6654,  -9.2373,   7.9234,  -9.4717,   6.3473,  -4.5160,  -7.9794,\n",
      "         -9.3082,   3.9725,   5.0814,   4.2129,   7.6941,   7.6569,  -4.3771,\n",
      "          6.5414,  -7.2552,  -4.1404,   6.7425,   9.4755,   9.0870,  -6.4717,\n",
      "          5.5153,   9.2900,   2.2236,  -8.4877,   7.7198,  -8.9039,   6.2410,\n",
      "         -7.5123,   8.4376,   9.4568,   3.9244,  -5.5844,  -4.9894,   8.9456,\n",
      "         -3.1553,   9.4228,   7.7865,   3.0862,   8.1737,  -2.3521,  -7.5338,\n",
      "          9.5387,  -9.1588,   1.0268,  -4.2735,  -9.7410,  -2.6368,   9.6476,\n",
      "         -9.9751,  -8.0346,   5.1262,   9.0980,  -3.2220,  -8.9682,   6.4943,\n",
      "          4.3703, -10.0035,   4.8498,   6.1712,   1.9424,   5.0328,   9.5405,\n",
      "         -8.9949,  -5.9948,  -9.8660,  -9.4982,   4.3970,   9.6514,  -0.9152,\n",
      "         -9.9895,  -9.9393,  -4.4508,  -4.2180,  -8.9986,   8.9207,  -6.8605,\n",
      "         -9.3550,  -2.9030,  -4.8965,   8.4937,  -3.1464,   2.0010,   6.5359,\n",
      "          2.5240,  -9.9308,   8.0154,  -9.8622,  -2.7280,   9.7802,  -8.7872,\n",
      "         -6.6288,   4.9519,   8.9400,   6.8019,   7.5431,  -9.7403,   9.5953,\n",
      "         -9.4868,   4.0290,   8.7067,  -9.9197,   4.2651,   9.5501,  -9.9421,\n",
      "         -9.9005,   0.8470,  -2.9463,  -9.8395,  -4.7267,  -7.0020,  -2.5676,\n",
      "         -9.6819,   4.8734,   7.8818,  -7.2460,   0.7948,  -7.8467,   9.3365,\n",
      "         -6.0909,   3.7174,  -9.4371,  -8.3271,  -1.0663,  -7.6883,   4.5717,\n",
      "          9.7941,   9.7298,   6.2245,  -5.6781,   2.9489,   4.7541,   3.6396,\n",
      "         -9.4323,  -9.9996,  -6.4748,  -2.5482,   5.0608,   8.2239,   9.7271,\n",
      "         -9.6179,   4.8542,  -4.7369,  -1.2186,   3.0087,   7.3888,  -8.2633,\n",
      "          3.6550, -10.0005,   4.1798,   4.5296,   9.5800,   6.8602,   7.4780,\n",
      "         -9.4153,   8.4069,   6.3413,  -2.4149,  -7.9729,  -8.4428,   2.8412,\n",
      "         -1.6698,  -0.4769,   7.2069,  -7.2167,  -8.0340,   9.1612,  -9.5701,\n",
      "          0.4094,  -9.9769,  -6.3611,   7.9436,   3.1896,   3.6859],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9998605650628865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 13/33000.0 [00:56<45:48:08,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.010000000000000002\n",
      "\n",
      "Inner iteration 3000\n",
      "\th(W(model)): 0.001446601756305288\n",
      "\tscore(model): 0.039644713048523225\n",
      "\t mle: 3.8102397491285998\n",
      "\t mse: 1.9134591126963718\n",
      "\tW1: tensor([[1.0000e-04, 6.6033e+00],\n",
      "        [5.7577e-03, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.001446601756305288\n",
      "\tW2: tensor([[ 1.0091e+00, -1.1021e-05],\n",
      "        [-1.1021e-05,  9.9985e-01]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0091e+00, -1.1022e-05],\n",
      "        [-1.1022e-05,  9.9985e-01]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-3.5782e-07,  0.0000e+00],\n",
      "        [-6.4101e-10,  2.4328e-08]])\n",
      "Check y:  tensor([  2.7308,   9.3272,   5.6625,   2.4935,  -4.7738,   7.4640,  -4.0412,\n",
      "          6.7851,   3.5398,  -6.6356,   9.6625,   1.5067,   3.8523,   5.2631,\n",
      "         -5.0922,  -5.8765,  -2.6566,   8.9052,   9.7638,   7.6759,   2.9073,\n",
      "          9.5751,  -2.6886,   9.7515,  -7.3005,   7.2444,  -8.2878,   4.3873,\n",
      "          1.0639,  -5.2230,  -9.8637,   9.7793,  -3.0000,   3.8742,  -2.5931,\n",
      "          6.3407,   6.0952,   6.3101,   4.4292,   8.5883,  -7.5660,  -4.0712,\n",
      "          8.9765,  -4.5595,   8.1579,   8.2742,  -9.8703,  -7.7410,  -8.9324,\n",
      "         -7.4120,   3.9731,  -3.9862,   2.5171,  -6.5794,  -9.8540,  -8.8757,\n",
      "          7.7166,  -9.9566,  -2.4021,  -9.9972,  -8.8054,  -6.9563,   7.8250,\n",
      "         -8.0990,  -9.6867,  -7.2231,   9.1882,  -6.3500,   8.7586,  -6.3030,\n",
      "          2.9962,  -2.2619,   2.9837,   5.7611,   9.6572,  -3.5355,  -9.6207,\n",
      "         -7.3821,  -9.3763,  -7.3198,  -8.8661,  -5.2425,  -4.7528,   8.8572,\n",
      "          3.7707,  -9.8550,   1.1521,  -6.2013,   4.2906,   5.0927,  -8.8507,\n",
      "          8.1775,  -7.8547,   9.3468,  -9.5065,  -9.4356,   4.8532,  -2.6517,\n",
      "          9.0003,  -1.9903,   8.4796,  -9.8027,   9.6145,   3.6041,  -9.9810,\n",
      "          4.3020,   5.1364,   4.0874,  -9.9714,   4.0221,  -3.5150,   8.5048,\n",
      "          9.0175,  -9.3497,   9.3369,  -6.0722,   7.2344,   4.5777,   7.2084,\n",
      "          8.8586,   9.4874,  -0.2358,   3.8732,   7.3950,  -4.7636,   5.8336,\n",
      "         -2.6110,  -9.2617,   7.9509,  -9.4941,   6.3573,  -4.5100,  -7.9968,\n",
      "         -9.3321,   3.9601,   5.0772,   4.2018,   7.7198,   7.6822,  -4.3710,\n",
      "          6.5778,  -7.2675,  -4.1341,   6.7787,   9.4715,   9.1115,  -6.4955,\n",
      "          5.5444,   9.3105,   2.1215,  -8.4995,   7.7480,  -8.9106,   6.2497,\n",
      "         -7.5335,   8.4541,   9.4531,   3.9117,  -5.5822,  -5.0002,   8.9720,\n",
      "         -3.1504,   9.4398,   7.8139,   3.0351,   8.1950,  -2.2846,  -7.5489,\n",
      "          9.5519,  -9.1622,   1.0127,  -4.2701,  -9.7393,  -2.5812,   9.6415,\n",
      "         -9.9758,  -8.0548,   5.1486,   9.1223,  -3.1882,  -8.9740,   6.5062,\n",
      "          4.3603, -10.0081,   4.8661,   6.1790,   1.9262,   5.0282,   9.5536,\n",
      "         -9.0200,  -5.9953,  -9.8646,  -9.4980,   4.4008,   9.6600,  -0.9204,\n",
      "         -9.9911,  -9.9498,  -4.4514,  -4.2118,  -9.0237,   8.9474,  -6.8686,\n",
      "         -9.3563,  -2.8578,  -4.9057,   8.5229,  -3.1416,   1.9847,   6.5723,\n",
      "          2.4409,  -9.9303,   8.0435,  -9.8761,  -2.6760,   9.7803,  -8.8121,\n",
      "         -6.6347,   4.9465,   8.9464,   6.8176,   7.5735,  -9.7578,   9.5896,\n",
      "         -9.4867,   4.0202,   8.7351,  -9.9189,   4.2646,   9.5630,  -9.9525,\n",
      "         -9.8994,   0.8335,  -2.9027,  -9.8380,  -4.7211,  -7.0115,  -2.5648,\n",
      "         -9.7008,   4.8673,   7.9078,  -7.2687,   0.7816,  -7.8653,   9.3559,\n",
      "         -6.0921,   3.7037,  -9.4375,  -8.3408,  -1.0708,  -7.7050,   4.5807,\n",
      "          9.7918,   9.7340,   6.2601,  -5.6976,   2.9329,   4.7469,   3.6151,\n",
      "         -9.4551, -10.0052,  -6.4986,  -2.4889,   5.0819,   8.2528,   9.7209,\n",
      "         -9.6380,   4.8479,  -4.7433,  -1.2222,   2.9534,   7.4209,  -8.2854,\n",
      "          3.6311, -10.0033,   4.1764,   4.5374,   9.5745,   6.8767,   7.5091,\n",
      "         -9.4383,   8.4240,   6.3512,  -2.3500,  -7.9924,  -8.4551,   2.7767,\n",
      "         -1.6711,  -0.4843,   7.2275,  -7.2285,  -8.0509,   9.1631,  -9.5693,\n",
      "          0.3977,  -9.9778,  -6.3847,   7.9687,   3.1438,   3.6633],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9998460079344221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 14/33000.0 [01:02<49:38:11,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.010000000000000002\n",
      "\n",
      "Inner iteration 4000\n",
      "\th(W(model)): 0.0011260566164761343\n",
      "\tscore(model): 0.039440480588772205\n",
      "\t mle: 3.821746508147184\n",
      "\t mse: 1.9193296992237585\n",
      "\tW1: tensor([[1.0000e-04, 6.6312e+00],\n",
      "        [5.0590e-03, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.0011260566164761343\n",
      "\tW2: tensor([[ 1.0091e+00, -1.2410e-05],\n",
      "        [-1.2410e-05,  9.9984e-01]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0091e+00, -1.2411e-05],\n",
      "        [-1.2411e-05,  9.9984e-01]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-2.7604e-07,  0.0000e+00],\n",
      "        [ 6.9025e-10,  1.0311e-08]])\n",
      "Check y:  tensor([  2.7261,   9.3388,   5.6636,   2.4886,  -4.7750,   7.4731,  -4.0424,\n",
      "          6.8030,   3.5256,  -6.6388,   9.6625,   1.5017,   3.8487,   5.2766,\n",
      "         -5.0970,  -5.8854,  -2.6301,   8.9090,   9.7649,   7.6898,   2.8760,\n",
      "          9.5750,  -2.6905,   9.7523,  -7.3103,   7.2525,  -8.2947,   4.3900,\n",
      "          1.0591,  -5.2244,  -9.8717,   9.7808,  -3.0017,   3.8707,  -2.5653,\n",
      "          6.3446,   6.0979,   6.3138,   4.4326,   8.6014,  -7.5715,  -4.0724,\n",
      "          8.9896,  -4.5601,   8.1699,   8.2866,  -9.8734,  -7.7498,  -8.9416,\n",
      "         -7.4172,   3.9697,  -3.9874,   2.4734,  -6.5896,  -9.8570,  -8.8804,\n",
      "          7.7269,  -9.9635,  -2.4042, -10.0032,  -8.8104,  -6.9665,   7.8358,\n",
      "         -8.1066,  -9.6894,  -7.2277,   9.1898,  -6.3600,   8.7637,  -6.3129,\n",
      "          2.9675,  -2.2641,   2.9547,   5.7626,   9.6650,  -3.5239,  -9.6299,\n",
      "         -7.3917,  -9.3859,  -7.3296,  -8.8752,  -5.2439,  -4.7551,   8.8704,\n",
      "          3.7670,  -9.8631,   1.1472,  -6.2111,   4.2878,   5.1045,  -8.8597,\n",
      "          8.1896,  -7.8631,   9.3583,  -9.5159,  -9.4385,   4.8518,  -2.6251,\n",
      "          9.0034,  -1.9498,   8.4925,  -9.8112,   9.6231,   3.5914,  -9.9875,\n",
      "          4.2993,   5.1358,   4.0843,  -9.9754,   4.0184,  -3.5164,   8.5121,\n",
      "          9.0305,  -9.3593,   9.3376,  -6.0745,   7.2507,   4.5755,   7.2248,\n",
      "          8.8718,   9.4977,  -0.2398,   3.8665,   7.4038,  -4.7648,   5.8353,\n",
      "         -2.5836,  -9.2712,   7.9622,  -9.5036,   6.3612,  -4.5111,  -8.0048,\n",
      "         -9.3417,   3.9567,   5.0764,   4.1989,   7.7300,   7.6923,  -4.3721,\n",
      "          6.5960,  -7.2722,  -4.1353,   6.7965,   9.4716,   9.1242,  -6.5057,\n",
      "          5.5599,   9.3222,   2.0636,  -8.5057,   7.7614,  -8.9151,   6.2531,\n",
      "         -7.5428,   8.4618,   9.4532,   3.9082,  -5.5838,  -5.0044,   8.9851,\n",
      "         -3.1520,   9.4506,   7.8268,   3.0076,   8.2049,  -2.2506,  -7.5544,\n",
      "          9.5614,  -9.1659,   1.0079,  -4.2678,  -9.7420,  -2.5532,   9.6414,\n",
      "         -9.9798,  -8.0617,   5.1610,   9.1350,  -3.1712,  -8.9783,   6.5108,\n",
      "          4.3577, -10.0135,   4.8755,   6.1821,   1.9212,   5.0272,   9.5631,\n",
      "         -9.0294,  -5.9974,  -9.8676,  -9.5008,   4.4037,   9.6677,  -0.9239,\n",
      "         -9.9954,  -9.9568,  -4.4510,  -4.2129,  -9.0331,   8.9605,  -6.8724,\n",
      "         -9.3594,  -2.8350,  -4.9092,   8.5359,  -3.1432,   1.9797,   6.5905,\n",
      "          2.3946,  -9.9338,   8.0551,  -9.8839,  -2.6498,   9.7844,  -8.8211,\n",
      "         -6.6379,   4.9453,   8.9499,   6.8236,   7.5880,  -9.7665,   9.5895,\n",
      "         -9.4895,   4.0164,   8.7484,  -9.9223,   4.2652,   9.5723,  -9.9595,\n",
      "         -9.9026,   0.8288,  -2.8807,  -9.8409,  -4.7223,  -7.0156,  -2.5668,\n",
      "         -9.7097,   4.8659,   7.9200,  -7.2786,   0.7768,  -7.8737,   9.3673,\n",
      "         -6.0944,   3.6999,  -9.4404,  -8.3476,  -1.0741,  -7.7110,   4.5864,\n",
      "          9.7947,   9.7400,   6.2783,  -5.7058,   2.9283,   4.7452,   3.6027,\n",
      "         -9.4646, -10.0109,  -6.5088,  -2.4591,   5.0937,   8.2651,   9.7213,\n",
      "         -9.6472,   4.8464,  -4.7455,  -1.2254,   2.9235,   7.4363,  -8.2930,\n",
      "          3.6191, -10.0080,   4.1756,   4.5425,   9.5744,   6.8830,   7.5240,\n",
      "         -9.4478,   8.4320,   6.3551,  -2.3174,  -7.9992,  -8.4614,   2.7414,\n",
      "         -1.6739,  -0.4882,   7.2355,  -7.2331,  -8.0587,   9.1649,  -9.5720,\n",
      "          0.3931,  -9.9818,  -6.3948,   7.9804,   3.1194,   3.6520],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.999838927128191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/33000.0 [01:09<52:37:42,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.010000000000000002\n",
      "\n",
      "Inner iteration 4999\n",
      "\th(W(model)): 0.0009342087735109139\n",
      "\tscore(model): 0.03933155857280481\n",
      "\t mle: 3.8299529020468137\n",
      "\t mse: 1.9235161647550958\n",
      "\tW1: tensor([[1.0000e-04, 6.6491e+00],\n",
      "        [4.5957e-03, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.0009342087735109139\n",
      "\tW2: tensor([[ 1.0092e+00, -1.3150e-05],\n",
      "        [-1.3150e-05,  9.9983e-01]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0092e+00, -1.3150e-05],\n",
      "        [-1.3150e-05,  9.9983e-01]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-2.5533e-07,  0.0000e+00],\n",
      "        [ 6.7087e-10,  7.5408e-09]])\n",
      "Check y:  tensor([  2.7251,   9.3469,   5.6638,   2.4876,  -4.7773,   7.4766,  -4.0449,\n",
      "          6.8135,   3.5179,  -6.6405,   9.6631,   1.5005,   3.8480,   5.2863,\n",
      "         -5.1008,  -5.8909,  -2.6146,   8.9098,   9.7669,   7.6966,   2.8562,\n",
      "          9.5750,  -2.6931,   9.7540,  -7.3152,   7.2554,  -8.2978,   4.3935,\n",
      "          1.0577,  -5.2265,  -9.8771,   9.7833,  -3.0043,   3.8700,  -2.5489,\n",
      "          6.3456,   6.0987,   6.3148,   4.4365,   8.6084,  -7.5734,  -4.0749,\n",
      "          8.9975,  -4.5615,   8.1755,   8.2926,  -9.8763,  -7.7540,  -8.9454,\n",
      "         -7.4189,   3.9690,  -3.9899,   2.4445,  -6.5953,  -9.8599,  -8.8825,\n",
      "          7.7311,  -9.9687,  -2.4067, -10.0081,  -8.8125,  -6.9718,   7.8404,\n",
      "         -8.1100,  -9.6916,  -7.2294,   9.1897,  -6.3657,   8.7650,  -6.3186,\n",
      "          2.9497,  -2.2666,   2.9366,   5.7629,   9.6717,  -3.5180,  -9.6352,\n",
      "         -7.3965,  -9.3907,  -7.3344,  -8.8789,  -5.2460,  -4.7575,   8.8781,\n",
      "          3.7663,  -9.8685,   1.1459,  -6.2168,   4.2872,   5.1134,  -8.8634,\n",
      "          8.1953,  -7.8670,   9.3664,  -9.5210,  -9.4403,   4.8514,  -2.6095,\n",
      "          9.0038,  -1.9245,   8.4991,  -9.8166,   9.6301,   3.5847,  -9.9925,\n",
      "          4.2987,   5.1356,   4.0836,  -9.9790,   4.0177,  -3.5190,   8.5147,\n",
      "          9.0385,  -9.3640,   9.3373,  -6.0763,   7.2596,   4.5750,   7.2338,\n",
      "          8.8795,   9.5054,  -0.2416,   3.8638,   7.4071,  -4.7671,   5.8357,\n",
      "         -2.5674,  -9.2758,   7.9671,  -9.5086,   6.3623,  -4.5135,  -8.0084,\n",
      "         -9.3464,   3.9560,   5.0761,   4.1982,   7.7343,   7.6965,  -4.3745,\n",
      "          6.6069,  -7.2739,  -4.1378,   6.8070,   9.4714,   9.1323,  -6.5114,\n",
      "          5.5707,   9.3303,   2.0241,  -8.5083,   7.7679,  -8.9171,   6.2541,\n",
      "         -7.5473,   8.4646,   9.4530,   3.9075,  -5.5858,  -5.0078,   8.9929,\n",
      "         -3.1546,   9.4584,   7.8329,   2.9905,   8.2091,  -2.2298,  -7.5563,\n",
      "          9.5688,  -9.1677,   1.0065,  -4.2675,  -9.7444,  -2.5366,   9.6419,\n",
      "         -9.9836,  -8.0640,   5.1702,   9.1431,  -3.1619,  -8.9803,   6.5121,\n",
      "          4.3571, -10.0180,   4.8830,   6.1830,   1.9201,   5.0269,   9.5705,\n",
      "         -9.0334,  -5.9993,  -9.8705,  -9.5027,   4.4073,   9.6744,  -0.9260,\n",
      "         -9.9994,  -9.9620,  -4.4518,  -4.2154,  -9.0371,   8.9684,  -6.8740,\n",
      "         -9.3611,  -2.8220,  -4.9123,   8.5427,  -3.1458,   1.9786,   6.6015,\n",
      "          2.3638,  -9.9371,   8.0603,  -9.8893,  -2.6345,   9.7889,  -8.8247,\n",
      "         -6.6396,   4.9450,   8.9505,   6.8256,   7.5954,  -9.7719,   9.5896,\n",
      "         -9.4914,   4.0157,   8.7557,  -9.9255,   4.2674,   9.5796,  -9.9647,\n",
      "         -9.9057,   0.8274,  -2.8682,  -9.8437,  -4.7246,  -7.0173,  -2.5693,\n",
      "         -9.7151,   4.8656,   7.9257,  -7.2835,   0.7754,  -7.8776,   9.3754,\n",
      "         -6.0962,   3.6991,  -9.4422,  -8.3505,  -1.0762,  -7.7129,   4.5916,\n",
      "          9.7983,   9.7457,   6.2897,  -5.7110,   2.9274,   4.7448,   3.5962,\n",
      "         -9.4696, -10.0156,  -6.5145,  -2.4413,   5.1025,   8.2711,   9.7225,\n",
      "         -9.6525,   4.8461,  -4.7479,  -1.2276,   2.9047,   7.4444,  -8.2957,\n",
      "          3.6128, -10.0122,   4.1768,   4.5474,   9.5745,   6.8850,   7.5317,\n",
      "         -9.4527,   8.4350,   6.3562,  -2.2976,  -8.0015,  -8.4642,   2.7187,\n",
      "         -1.6762,  -0.4901,   7.2384,  -7.2348,  -8.0622,   9.1649,  -9.5740,\n",
      "          0.3916,  -9.9856,  -6.4005,   7.9858,   3.1045,   3.6463],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9998343159706098\n",
      "\n",
      "Dagma iter t=3 -- mu: 0.0010000000000000002 ------------------------------\n",
      "success:  False\n",
      "\n",
      "Minimize s=1.0 -- lr=0.00375\n",
      "\n",
      "mu 0.0010000000000000002\n",
      "\n",
      "Inner iteration 0\n",
      "\th(W(model)): 0.000934040543076442\n",
      "\tscore(model): 0.004849753900192198\n",
      "\t mle: 4.385836558241526\n",
      "\t mse: 2.196772857774783\n",
      "\tW1: tensor([[1.0000e-04, 6.6491e+00],\n",
      "        [4.5953e-03, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.000934040543076442\n",
      "\tW2: tensor([[ 1.0092e+00, -1.3150e-05],\n",
      "        [-1.3150e-05,  9.9983e-01]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0016, 0.0037],\n",
      "        [0.0037, 1.0074]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[ 3.3374e-02,  0.0000e+00],\n",
      "        [-4.7549e-05, -5.9631e-04]])\n",
      "Check y:  tensor([ 2.6163,  8.6988,  5.3298,  2.3951, -4.4195,  6.9806, -3.7330,  6.6143,\n",
      "         3.5843, -6.1616,  9.0841,  1.4735,  3.6586,  5.2256, -5.0958, -5.8301,\n",
      "        -2.7402,  8.4628,  9.1569,  7.4035,  2.9608,  9.0160, -2.4636,  9.1489,\n",
      "        -7.1336,  6.7797, -8.0134,  4.4014,  1.0591, -4.8401, -9.2504,  9.1658,\n",
      "        -2.7560,  3.6789, -2.6771,  5.9524,  5.7272,  5.9243,  4.4413,  8.0116,\n",
      "        -7.0336, -3.7612,  8.3707, -4.5906,  7.6160,  7.7227, -9.3496, -7.5289,\n",
      "        -8.3283, -6.8891,  3.7705, -3.6814,  2.5699, -6.4784, -9.3374, -8.5257,\n",
      "         7.2118, -9.3535, -2.1945, -9.4055, -8.4649, -6.8221,  7.3110, -7.8468,\n",
      "        -9.2067, -6.7119,  8.7002, -6.2678,  8.3387, -6.2246,  3.0492, -2.0628,\n",
      "         3.0368,  5.4204,  9.0168, -3.6039, -9.0006, -7.2071, -8.7585, -7.1510,\n",
      "        -8.2647, -4.8583, -4.7745,  8.2600,  3.5829, -9.2412,  1.1417, -6.1309,\n",
      "         4.0645,  5.0667, -8.2499,  7.6340, -7.6301,  8.7174, -8.8868, -9.0010,\n",
      "         4.5845, -2.7353,  8.5430, -2.0741,  7.9115, -9.1862,  8.9745,  3.6470,\n",
      "        -9.3834,  4.0752,  4.8456,  3.8765, -9.4192,  4.0518, -3.2395,  8.1221,\n",
      "         8.4088, -8.7325,  8.8232, -5.6346,  7.0145,  4.3300,  6.9914,  8.2613,\n",
      "         8.8513, -0.1596,  3.9082,  6.9175, -4.4100,  5.4870, -2.6948, -8.6465,\n",
      "         7.4263, -8.8745,  5.9676, -4.1724, -7.7564, -8.7153,  3.7585,  4.7910,\n",
      "         3.9824,  7.2147,  7.1803, -4.0422,  6.4282, -6.7535, -3.8201,  6.6085,\n",
      "         8.9331,  8.4964, -6.4015,  5.4863,  8.6831,  2.1683, -8.1990,  7.4667,\n",
      "        -8.5556,  5.8689, -7.3431,  8.0786,  8.9181,  3.7137, -5.1762, -5.0089,\n",
      "         8.3665, -2.8973,  8.8057,  7.5242,  3.0878,  7.8554, -2.3696, -7.0176,\n",
      "         8.9135, -8.7709,  1.0112, -4.3138, -9.2486, -2.6652,  9.0680, -9.4217,\n",
      "        -7.4938,  5.1190,  8.5065, -3.2645, -8.6102,  6.1040,  4.1290, -9.4267,\n",
      "         4.8545,  5.8041,  1.8656,  4.7458,  8.9151, -8.4126, -5.5626, -9.3453,\n",
      "        -9.0528,  4.4142,  9.0196, -0.8025, -9.4295, -9.3455, -4.4874, -3.8929,\n",
      "        -8.4161,  8.3436, -6.3798, -8.9347, -2.9393, -4.9196,  7.9514, -2.8890,\n",
      "         1.9203,  6.4233,  2.4930, -9.3927,  7.5111, -9.2637, -2.7594,  9.1477,\n",
      "        -8.2130, -6.1608,  4.6705,  8.4976,  6.3892,  7.3137, -9.1397,  9.0274,\n",
      "        -9.0434,  4.0500,  8.1471, -9.3848,  4.2843,  8.9242, -9.3487, -9.3709,\n",
      "         0.8433, -2.9836, -9.3253, -4.3702, -6.5136, -2.3473, -9.0814,  4.5975,\n",
      "         7.6061, -7.1050,  0.7947, -7.6395,  8.7260, -5.6532,  3.5208, -9.0025,\n",
      "        -8.0600, -0.9437, -7.1644,  4.5851,  9.1661,  9.0955,  6.1412, -5.6636,\n",
      "         2.8044,  4.4864,  3.6578, -8.8360, -9.4190, -6.4043, -2.5735,  5.0567,\n",
      "         7.7031,  9.1276, -9.0180,  4.5796, -4.7655, -1.0860,  3.0067,  7.1793,\n",
      "        -7.7118,  3.6734, -9.4330,  4.2000,  4.5441,  9.0155,  6.4433,  7.2570,\n",
      "        -8.8194,  8.0528,  5.9620, -2.4350, -7.4350, -8.1602,  2.8306, -1.5077,\n",
      "        -0.3929,  6.7643, -6.7169, -7.8043,  8.6793, -9.1115,  0.4348, -9.4228,\n",
      "        -6.2998,  7.6592,  3.1954,  3.7047], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9998343115839716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/33000.0 [01:16<43:34:56,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.0010000000000000002\n",
      "\n",
      "Inner iteration 1000\n",
      "\th(W(model)): 0.0003666476217154546\n",
      "\tscore(model): 0.004382219684721824\n",
      "\t mle: 4.013067406302835\n",
      "\t mse: 2.007532528608322\n",
      "\tW1: tensor([[1.0000e-04, 6.2747e+00],\n",
      "        [3.0512e-03, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.0003666476217154546\n",
      "\tW2: tensor([[ 1.0010e+00, -1.8417e-05],\n",
      "        [-1.8417e-05,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0010e+00, -1.3498e-05],\n",
      "        [-1.3498e-05,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[1.1501e-04, 0.0000e+00],\n",
      "        [2.9800e-05, 8.1641e-05]])\n",
      "Check y:  tensor([  2.6528,   9.4861,   5.5100,   2.4253,  -4.5977,   7.3816,  -3.8740,\n",
      "          6.4199,   3.8703,  -6.4812,   9.6810,   1.4810,   3.7322,   5.1219,\n",
      "         -5.0554,  -5.7044,  -3.2644,   8.6637,   9.8539,   7.2891,   3.4511,\n",
      "          9.5487,  -2.5529,   9.8302,  -7.0033,   7.1450,  -8.0137,   4.4619,\n",
      "          1.0574,  -5.0454, -10.0052,   9.8869,  -2.8556,   3.7534,  -3.2210,\n",
      "          6.1979,   5.9469,   6.1665,   4.4923,   8.6370,  -7.4598,  -3.9035,\n",
      "          9.0840,  -4.6375,   8.1480,   8.2792,  -9.9050,  -7.4417,  -8.9613,\n",
      "         -7.2956,   3.8491,  -3.8199,   3.1988,  -6.3245,  -9.8822,  -8.6676,\n",
      "          7.6573, -10.0985,  -2.2748, -10.1310,  -8.5870,  -6.6735,   7.7768,\n",
      "         -7.8124,  -9.6567,  -7.0954,   9.0196,  -6.1178,   8.4865,  -6.0760,\n",
      "          3.5092,  -2.1390,   3.5010,   5.6090,   9.8436,  -3.8785,  -9.7388,\n",
      "         -7.0831,  -9.4633,  -7.0221,  -8.8867,  -5.0649,  -4.7871,   8.9463,\n",
      "          3.6534,  -9.9961,   1.1418,  -5.9861,   4.1573,   4.9890,  -8.8694,\n",
      "          8.1700,  -7.5580,   9.5083,  -9.6104,  -9.3364,   4.7073,  -3.2610,\n",
      "          8.7812,  -2.8144,   8.5126,  -9.9400,   9.8006,   3.9138, -10.1198,\n",
      "          4.1685,   4.9863,   3.9600, -10.0548,   4.2020,  -3.3581,   8.1893,\n",
      "          9.1313,  -9.4332,   9.2156,  -5.9026,   6.8469,   4.4373,   6.8215,\n",
      "          8.9480,   9.6650,  -0.1872,   4.0983,   7.3070,  -4.5876,   5.6820,\n",
      "         -3.2332,  -9.3334,   7.9164,  -9.5964,   6.2149,  -4.3363,  -7.7052,\n",
      "         -9.4132,   3.8366,   4.9278,   4.0711,   7.6608,   7.6196,  -4.1989,\n",
      "          6.2301,  -7.1423,  -3.9654,   6.4139,   9.4001,   9.2396,  -6.2484,\n",
      "          5.3462,   9.4672,   2.9451,  -8.2442,   7.3637,  -8.7078,   6.1046,\n",
      "         -7.2328,   8.1313,   9.3744,   3.7897,  -5.4060,  -4.9819,   9.0788,\n",
      "         -3.0022,   9.6125,   7.4323,   3.5346,   7.8412,  -3.0120,  -7.4416,\n",
      "          9.7349,  -9.0034,   1.0084,  -4.4174,  -9.7262,  -3.2129,   9.6484,\n",
      "        -10.0620,  -7.9877,   5.0324,   9.2520,  -3.6324,  -8.7814,   6.3684,\n",
      "          4.2252, -10.1311,   4.8158,   6.0324,   1.8822,   4.8794,   9.7367,\n",
      "         -9.0601,  -5.8242,  -9.8970,  -9.4146,   4.4716,   9.8463,  -0.8448,\n",
      "        -10.0882, -10.0922,  -4.5548,  -4.0419,  -9.0643,   9.0504,  -6.7234,\n",
      "         -9.2383,  -3.4025,  -4.9071,   8.5621,  -2.9935,   1.9382,   6.2251,\n",
      "          3.1499,  -9.9915,   8.0197, -10.0182,  -3.2776,   9.9417,  -8.8261,\n",
      "         -6.4802,   4.7990,   8.7144,   6.6927,   7.1845,  -9.8911,   9.5701,\n",
      "         -9.4004,   4.2007,   8.8057,  -9.9748,   4.3736,   9.7466, -10.0947,\n",
      "         -9.9464,   0.8370,  -3.4335,  -9.8599,  -4.5455,  -6.8728,  -2.4326,\n",
      "         -9.8281,   4.7211,   7.5312,  -6.9724,   0.7873,  -7.5689,   9.5185,\n",
      "         -5.9228,   3.5886,  -9.3388,  -8.0709,  -0.9894,  -7.6089,   4.6030,\n",
      "          9.9332,   9.9137,   5.9478,  -5.5526,   2.8467,   4.6030,   3.9213,\n",
      "         -9.5524, -10.1336,  -6.2512,  -3.1502,   4.9807,   8.2550,   9.7760,\n",
      "         -9.7583,   4.7020,  -4.7798,  -1.1352,   3.4812,   7.0308,  -8.2405,\n",
      "          3.9322, -10.1122,   4.3108,   4.5712,   9.5478,   6.7548,   7.1193,\n",
      "         -9.5334,   8.0971,   6.2087,  -3.0561,  -7.9198,  -8.1954,   3.3663,\n",
      "         -1.5679,  -0.4258,   7.1270,  -7.1011,  -7.7618,   8.9872,  -9.5049,\n",
      "          0.4198, -10.0653,  -6.1488,   7.5959,   3.6061,   3.9541],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  1.000042059518132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 18/33000.0 [01:23<48:02:41,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.0010000000000000002\n",
      "\n",
      "Inner iteration 2000\n",
      "\th(W(model)): 0.0002540625773317373\n",
      "\tscore(model): 0.004218836263021114\n",
      "\t mle: 3.9624846118093733\n",
      "\t mse: 1.9822218217349286\n",
      "\tW1: tensor([[1.0000e-04, 6.4727e+00],\n",
      "        [2.4623e-03, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.0002540625773317373\n",
      "\tW2: tensor([[ 1.0010e+00, -6.5637e-07],\n",
      "        [-6.5637e-07,  9.9999e-01]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0010e+00, -6.5355e-07],\n",
      "        [-6.5355e-07,  9.9999e-01]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[ 4.3194e-07,  0.0000e+00],\n",
      "        [ 6.0878e-07, -1.3653e-06]])\n",
      "Check y:  tensor([  2.8067,   9.2852,   5.6645,   2.5691,  -4.8294,   7.3801,  -4.1020,\n",
      "          6.6661,   3.6131,  -6.6268,   9.7253,   1.5726,   3.9168,   5.1791,\n",
      "         -5.0180,  -5.7765,  -2.8164,   8.9016,   9.8277,   7.5836,   3.0659,\n",
      "          9.6323,  -2.7338,   9.8160,  -7.2148,   7.1691,  -8.2531,   4.3685,\n",
      "          1.1216,  -5.2698,  -9.8311,   9.8414,  -3.0511,   3.9383,  -2.7619,\n",
      "          6.3090,   6.0759,   6.2799,   4.4066,   8.4944,  -7.5063,  -4.1320,\n",
      "          8.9015,  -4.5170,   8.0589,   8.1752,  -9.9249,  -7.6746,  -8.8285,\n",
      "         -7.3608,   4.0351,  -4.0469,   2.7342,  -6.4768,  -9.9091,  -8.8817,\n",
      "          7.6248,  -9.9485,  -2.4409, -10.0074,  -8.8064,  -6.8602,   7.7305,\n",
      "         -8.0525,  -9.7412,  -7.1824,   9.2111,  -6.2461,   8.7418,  -6.1991,\n",
      "          3.1420,  -2.2973,   3.1313,   5.7584,   9.6680,  -3.5850,  -9.5512,\n",
      "         -7.2995,  -9.2864,  -7.2348,  -8.7620,  -5.2888,  -4.6975,   8.7746,\n",
      "          3.8368,  -9.8206,   1.2116,  -6.0977,   4.3448,   5.0188,  -8.7465,\n",
      "          8.0785,  -7.7942,   9.3073,  -9.4259,  -9.4791,   4.8895,  -2.8122,\n",
      "          9.0055,  -2.2513,   8.3830,  -9.7584,   9.6166,   3.6695,  -9.9825,\n",
      "          4.3560,   5.1617,   4.1469, -10.0159,   4.0397,  -3.5731,   8.4666,\n",
      "          8.9454,  -9.2583,   9.3737,  -6.0902,   7.1246,   4.6234,   7.0978,\n",
      "          8.7761,   9.4675,  -0.2118,   3.9071,   7.3137,  -4.8194,   5.8274,\n",
      "         -2.7772,  -9.1658,   7.8540,  -9.4125,   6.3247,  -4.5688,  -7.9442,\n",
      "         -9.2397,   4.0224,   5.1049,   4.2584,   7.6278,   7.5913,  -4.4308,\n",
      "          6.4575,  -7.2242,  -4.1948,   6.6596,   9.5204,   9.0471,  -6.3922,\n",
      "          5.4463,   9.2665,   2.4017,  -8.4790,   7.6593,  -8.9191,   6.2226,\n",
      "         -7.4572,   8.4119,   9.5004,   3.9750,  -5.6187,  -4.9307,   8.8966,\n",
      "         -3.2040,   9.4128,   7.7287,   3.1754,   8.1335,  -2.4992,  -7.4902,\n",
      "          9.5426,  -9.1884,   1.0693,  -4.2494,  -9.7949,  -2.7517,   9.7031,\n",
      "        -10.0194,  -7.9709,   5.0713,   9.0589,  -3.2779,  -8.9870,   6.4660,\n",
      "          4.4126, -10.0307,   4.8077,   6.1555,   1.9978,   5.0578,   9.5446,\n",
      "         -8.9172,  -6.0165,  -9.9193,  -9.5449,   4.3807,   9.6714,  -0.9172,\n",
      "        -10.0302,  -9.9393,  -4.4167,  -4.2723,  -8.9209,   8.8704,  -6.8474,\n",
      "         -9.3951,  -2.9899,  -4.8413,   8.4273,  -3.1950,   2.0570,   6.4521,\n",
      "          2.6700,  -9.9808,   7.9454,  -9.8461,  -2.8330,   9.8259,  -8.7081,\n",
      "         -6.6259,   4.9793,   8.9466,   6.7618,   7.4764,  -9.7062,   9.6479,\n",
      "         -9.5330,   4.0380,   8.6465,  -9.9705,   4.2574,   9.5556,  -9.9429,\n",
      "         -9.9524,   0.8862,  -3.0288,  -9.8935,  -4.7775,  -6.9825,  -2.6073,\n",
      "         -9.6410,   4.9031,   7.8279,  -7.1819,   0.8330,  -7.8054,   9.3175,\n",
      "         -6.1092,   3.7710,  -9.4810,  -8.3096,  -1.0722,  -7.6380,   4.5448,\n",
      "          9.8463,   9.7636,   6.1417,  -5.6013,   3.0083,   4.7870,   3.6792,\n",
      "         -9.3705, -10.0224,  -6.3954,  -2.6728,   5.0088,   8.1538,   9.7857,\n",
      "         -9.5705,   4.8844,  -4.6886,  -1.2282,   3.1054,   7.3175,  -8.1924,\n",
      "          3.6932, -10.0362,   4.1780,   4.5052,   9.6317,   6.8180,   7.4092,\n",
      "         -9.3525,   8.3795,   6.3190,  -2.5546,  -7.9114,  -8.4316,   2.9544,\n",
      "         -1.6905,  -0.4678,   7.1529,  -7.1874,  -8.0015,   9.1836,  -9.6196,\n",
      "          0.4395, -10.0209,  -6.2809,   7.8925,   3.2690,   3.7216],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9999903953142687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 19/33000.0 [01:30<51:54:45,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.0010000000000000002\n",
      "\n",
      "Inner iteration 3000\n",
      "\th(W(model)): 0.00015270643006370932\n",
      "\tscore(model): 0.004120037307688381\n",
      "\t mle: 3.9650189687531285\n",
      "\t mse: 1.983498392604798\n",
      "\tW1: tensor([[1.0000e-04, 6.5421e+00],\n",
      "        [1.8887e-03, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.00015270643006370932\n",
      "\tW2: tensor([[ 1.0010e+00, -1.3499e-06],\n",
      "        [-1.3499e-06,  9.9999e-01]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0010e+00, -1.3499e-06],\n",
      "        [-1.3499e-06,  9.9999e-01]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[ 3.5160e-09,  0.0000e+00],\n",
      "        [ 3.4854e-09, -4.0482e-09]])\n",
      "Check y:  tensor([  2.7864,   9.3131,   5.6728,   2.5481,  -4.8299,   7.4153,  -4.1015,\n",
      "          6.7150,   3.5635,  -6.6400,   9.7326,   1.5510,   3.9032,   5.2006,\n",
      "         -5.0221,  -5.7971,  -2.7313,   8.9296,   9.8332,   7.6319,   2.9810,\n",
      "          9.6419,  -2.7367,   9.8216,  -7.2484,   7.2016,  -8.2830,   4.3588,\n",
      "          1.1007,  -5.2720,  -9.8515,   9.8469,  -3.0528,   3.9249,  -2.6738,\n",
      "          6.3280,   6.0910,   6.2984,   4.3987,   8.5344,  -7.5298,  -4.1315,\n",
      "          8.9372,  -4.5063,   8.0994,   8.2159,  -9.9345,  -7.7078,  -8.8611,\n",
      "         -7.3826,   4.0225,  -4.0465,   2.6258,  -6.5066,  -9.9189,  -8.9050,\n",
      "          7.6626,  -9.9651,  -2.4450, -10.0213,  -8.8306,  -6.8926,   7.7693,\n",
      "         -8.0838,  -9.7527,  -7.2021,   9.2316,  -6.2735,   8.7734,  -6.2259,\n",
      "          3.0624,  -2.3021,   3.0510,   5.7682,   9.6837,  -3.5382,  -9.5778,\n",
      "         -7.3332,  -9.3166,  -7.2685,  -8.7946,  -5.2911,  -4.6925,   8.8121,\n",
      "          3.8225,  -9.8413,   1.1905,  -6.1232,   4.3353,   5.0351,  -8.7791,\n",
      "          8.1190,  -7.8269,   9.3346,  -9.4544,  -9.4941,   4.8864,  -2.7269,\n",
      "          9.0311,  -2.1336,   8.4235,  -9.7808,   9.6343,   3.6232,  -9.9977,\n",
      "          4.3466,   5.1624,   4.1353, -10.0258,   4.0139,  -3.5733,   8.5036,\n",
      "          8.9805,  -9.2887,   9.3901,  -6.0981,   7.1746,   4.6170,   7.1479,\n",
      "          8.8136,   9.4902,  -0.2277,   3.8743,   7.3481,  -4.8198,   5.8383,\n",
      "         -2.6900,  -9.1970,   7.8936,  -9.4412,   6.3439,  -4.5686,  -7.9763,\n",
      "         -9.2703,   4.0097,   5.1047,   4.2480,   7.6657,   7.6288,  -4.4305,\n",
      "          6.5047,  -7.2444,  -4.1944,   6.7084,   9.5329,   9.0803,  -6.4212,\n",
      "          5.4755,   9.2949,   2.2682,  -8.5068,   7.7070,  -8.9419,   6.2401,\n",
      "         -7.4908,   8.4498,   9.5134,   3.9619,  -5.6229,  -4.9324,   8.9324,\n",
      "         -3.2052,   9.4372,   7.7758,   3.0980,   8.1759,  -2.3962,  -7.5135,\n",
      "          9.5629,  -9.2076,   1.0485,  -4.2295,  -9.8057,  -2.6631,   9.7110,\n",
      "        -10.0293,  -7.9993,   5.0894,   9.0919,  -3.2167,  -9.0090,   6.4876,\n",
      "          4.4038, -10.0429,   4.8165,   6.1719,   1.9760,   5.0570,   9.5648,\n",
      "         -8.9495,  -6.0238,  -9.9290,  -9.5590,   4.3716,   9.6869,  -0.9295,\n",
      "        -10.0405,  -9.9563,  -4.4026,  -4.2719,  -8.9533,   8.9066,  -6.8632,\n",
      "         -9.4113,  -2.9141,  -4.8406,   8.4676,  -3.1962,   2.0352,   6.4992,\n",
      "          2.5568,  -9.9903,   7.9854,  -9.8661,  -2.7489,   9.8341,  -8.7406,\n",
      "         -6.6391,   4.9774,   8.9736,   6.7883,   7.5254,  -9.7298,   9.6571,\n",
      "         -9.5473,   4.0121,   8.6853,  -9.9800,   4.2425,   9.5754,  -9.9598,\n",
      "         -9.9620,   0.8659,  -2.9550,  -9.9033,  -4.7778,  -6.9998,  -2.6108,\n",
      "         -9.6659,   4.9002,   7.8741,  -7.2155,   0.8128,  -7.8380,   9.3446,\n",
      "         -6.1173,   3.7561,  -9.4961,  -8.3390,  -1.0836,  -7.6630,   4.5429,\n",
      "          9.8529,   9.7751,   6.1851,  -5.6187,   2.9888,   4.7826,   3.6335,\n",
      "         -9.3997, -10.0354,  -6.4243,  -2.5798,   5.0247,   8.1945,   9.7918,\n",
      "         -9.5968,   4.8812,  -4.6833,  -1.2388,   3.0232,   7.3671,  -8.2226,\n",
      "          3.6484, -10.0472,   4.1593,   4.5017,   9.6413,   6.8454,   7.4585,\n",
      "         -9.3819,   8.4180,   6.3381,  -2.4549,  -7.9392,  -8.4599,   2.8618,\n",
      "         -1.6985,  -0.4825,   7.1852,  -7.2072,  -8.0332,   9.2049,  -9.6327,\n",
      "          0.4207, -10.0308,  -6.3087,   7.9379,   3.1979,   3.6784],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9999872943910231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/33000.0 [01:37<55:03:03,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.0010000000000000002\n",
      "\n",
      "Inner iteration 4000\n",
      "\th(W(model)): 0.00013668068325101146\n",
      "\tscore(model): 0.004107290975621082\n",
      "\t mle: 3.9684793595173034\n",
      "\t mse: 1.9852366200722742\n",
      "\tW1: tensor([[1.0000e-04, 6.5978e+00],\n",
      "        [1.7718e-03, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 0.00013668068325101146\n",
      "\tW2: tensor([[ 1.0010e+00, -7.5419e-06],\n",
      "        [-7.5419e-06,  9.9999e-01]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0010e+00, -7.4790e-06],\n",
      "        [-7.4790e-06,  9.9999e-01]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[ 3.0069e-07,  0.0000e+00],\n",
      "        [-8.2985e-07, -2.1084e-08]])\n",
      "Check y:  tensor([  2.7660,   9.3314,   5.6869,   2.5268,  -4.8371,   7.4596,  -4.1049,\n",
      "          6.7767,   3.5487,  -6.6706,   9.7053,   1.5287,   3.8908,   5.2523,\n",
      "         -5.0548,  -5.8390,  -2.6798,   8.9332,   9.8052,   7.6785,   2.9281,\n",
      "          9.6173,  -2.7402,   9.7934,  -7.2852,   7.2433,  -8.3013,   4.3838,\n",
      "          1.0793,  -5.2831,  -9.8697,   9.8196,  -3.0556,   3.9127,  -2.6190,\n",
      "          6.3547,   6.1131,   6.3246,   4.4253,   8.5776,  -7.5752,  -4.1350,\n",
      "          8.9708,  -4.5276,   8.1468,   8.2628,  -9.9195,  -7.7376,  -8.9131,\n",
      "         -7.4257,   4.0114,  -4.0497,   2.5461,  -6.5495,  -9.9037,  -8.9084,\n",
      "          7.7091,  -9.9735,  -2.4495, -10.0227,  -8.8359,  -6.9332,   7.8164,\n",
      "         -8.1064,  -9.7379,  -7.2422,   9.2229,  -6.3168,   8.7832,  -6.2693,\n",
      "          3.0152,  -2.3071,   3.0030,   5.7841,   9.6785,  -3.5264,  -9.6115,\n",
      "         -7.3689,  -9.3597,  -7.3050,  -8.8472,  -5.3024,  -4.7184,   8.8493,\n",
      "          3.8093,  -9.8603,   1.1689,  -6.1665,   4.3279,   5.0828,  -8.8319,\n",
      "          8.1663,  -7.8546,   9.3518,  -9.4931,  -9.4836,   4.8869,  -2.6751,\n",
      "          9.0306,  -2.0456,   8.4683,  -9.8038,   9.6329,   3.6119, -10.0024,\n",
      "          4.3394,   5.1674,   4.1255, -10.0143,   4.0234,  -3.5757,   8.5236,\n",
      "          9.0126,  -9.3327,   9.3749,  -6.1198,   7.2306,   4.6134,   7.2043,\n",
      "          8.8508,   9.4986,  -0.2436,   3.8767,   7.3916,  -4.8270,   5.8556,\n",
      "         -2.6362,  -9.2433,   7.9411,  -9.4804,   6.3710,  -4.5741,  -8.0011,\n",
      "         -9.3148,   3.9985,   5.1088,   4.2395,   7.7122,   7.6751,  -4.4352,\n",
      "          6.5678,  -7.2853,  -4.1981,   6.7702,   9.5122,   9.1088,  -6.4643,\n",
      "          5.5325,   9.3141,   2.1591,  -8.5200,   7.7518,  -8.9444,   6.2652,\n",
      "         -7.5242,   8.4717,   9.4934,   3.9502,  -5.6380,  -4.9634,   8.9661,\n",
      "         -3.2077,   9.4488,   7.8188,   3.0533,   8.2071,  -2.3250,  -7.5587,\n",
      "          9.5666,  -9.2036,   1.0273,  -4.2429,  -9.7905,  -2.6077,   9.6843,\n",
      "        -10.0182,  -8.0505,   5.1384,   9.1200,  -3.1904,  -9.0098,   6.5174,\n",
      "          4.3973, -10.0396,   4.8579,   6.1956,   1.9536,   5.0602,   9.5683,\n",
      "         -9.0004,  -6.0444,  -9.9139,  -9.5472,   4.3972,   9.6815,  -0.9415,\n",
      "        -10.0311,  -9.9657,  -4.4211,  -4.2759,  -9.0041,   8.9411,  -6.8975,\n",
      "         -9.4026,  -2.8726,  -4.8697,   8.5118,  -3.1988,   2.0129,   6.5623,\n",
      "          2.4716,  -9.9767,   8.0330,  -9.8833,  -2.6983,   9.8138,  -8.7936,\n",
      "         -6.6696,   4.9794,   8.9754,   6.8235,   7.5745,  -9.7558,   9.6320,\n",
      "         -9.5357,   4.0215,   8.7257,  -9.9660,   4.2626,   9.5782,  -9.9688,\n",
      "         -9.9475,   0.8452,  -2.9156,  -9.8880,  -4.7847,  -7.0365,  -2.6146,\n",
      "         -9.6954,   4.9009,   7.9144,  -7.2527,   0.7923,  -7.8655,   9.3612,\n",
      "         -6.1393,   3.7423,  -9.4855,  -8.3561,  -1.0947,  -7.7103,   4.5751,\n",
      "          9.8288,   9.7618,   6.2485,  -5.6593,   2.9693,   4.7815,   3.6227,\n",
      "         -9.4403, -10.0341,  -6.4675,  -2.5196,   5.0721,   8.2414,   9.7635,\n",
      "         -9.6296,   4.8816,  -4.7090,  -1.2490,   2.9733,   7.4196,  -8.2756,\n",
      "          3.6385, -10.0400,   4.1756,   4.5323,   9.6167,   6.8816,   7.5091,\n",
      "         -9.4231,   8.4410,   6.3650,  -2.3872,  -7.9898,  -8.4741,   2.8002,\n",
      "         -1.7062,  -0.4970,   7.2267,  -7.2474,  -8.0568,   9.1972,  -9.6195,\n",
      "          0.4017, -10.0199,  -6.3520,   7.9764,   3.1599,   3.6702],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9999849911266995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/33000.0 [01:43<56:55:44,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.0010000000000000002\n",
      "\n",
      "Inner iteration 4999\n",
      "\th(W(model)): 8.320605370126799e-05\n",
      "\tscore(model): 0.0040574788103778705\n",
      "\t mle: 3.9719324297136276\n",
      "\t mse: 1.9869694243787763\n",
      "\tW1: tensor([[1.0000e-04, 6.6523e+00],\n",
      "        [1.3710e-03, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 8.320605370126799e-05\n",
      "\tW2: tensor([[ 1.0010e+00, -5.9621e-06],\n",
      "        [-5.9621e-06,  9.9998e-01]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0010e+00, -5.5767e-06],\n",
      "        [-5.5767e-06,  9.9998e-01]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[3.7161e-08, 0.0000e+00],\n",
      "        [2.1448e-07, 1.2434e-08]])\n",
      "Check y:  tensor([  2.7364,   9.3520,   5.6815,   2.4976,  -4.8141,   7.4883,  -4.0800,\n",
      "          6.8204,   3.5186,  -6.6707,   9.6815,   1.5045,   3.8639,   5.2852,\n",
      "         -5.0794,  -5.8724,  -2.6226,   8.9304,   9.7827,   7.7101,   2.8619,\n",
      "          9.5946,  -2.7210,   9.7704,  -7.3131,   7.2682,  -8.3115,   4.3914,\n",
      "          1.0586,  -5.2633,  -9.8812,   9.7983,  -3.0342,   3.8859,  -2.5586,\n",
      "          6.3620,   6.1156,   6.3312,   4.4344,   8.6145,  -7.5936,  -4.1101,\n",
      "          9.0024,  -4.5414,   8.1836,   8.3001,  -9.9003,  -7.7588,  -8.9481,\n",
      "         -7.4410,   3.9852,  -4.0248,   2.4544,  -6.5835,  -9.8843,  -8.9048,\n",
      "          7.7416,  -9.9766,  -2.4327, -10.0194,  -8.8339,  -6.9648,   7.8502,\n",
      "         -8.1207,  -9.7184,  -7.2538,   9.2108,  -6.3514,   8.7852,  -6.3038,\n",
      "          2.9544,  -2.2916,   2.9415,   5.7804,   9.6795,  -3.5081,  -9.6355,\n",
      "         -7.3957,  -9.3905,  -7.3327,  -8.8822,  -5.2827,  -4.7366,   8.8832,\n",
      "          3.7819,  -9.8724,   1.1475,  -6.2010,   4.3042,   5.1119,  -8.8669,\n",
      "          8.2033,  -7.8738,   9.3715,  -9.5208,  -9.4675,   4.8692,  -2.6176,\n",
      "          9.0247,  -1.9523,   8.5057,  -9.8192,   9.6373,   3.5851, -10.0022,\n",
      "          4.3157,   5.1535,   4.1001,  -9.9989,   4.0163,  -3.5518,   8.5336,\n",
      "          9.0433,  -9.3639,   9.3582,  -6.1103,   7.2698,   4.5925,   7.2439,\n",
      "          8.8847,   9.5113,  -0.2507,   3.8630,   7.4192,  -4.8038,   5.8532,\n",
      "         -2.5766,  -9.2760,   7.9763,  -9.5084,   6.3786,  -4.5499,  -8.0174,\n",
      "         -9.3463,   3.9722,   5.0941,   4.2150,   7.7447,   7.7071,  -4.4106,\n",
      "          6.6124,  -7.2977,  -4.1732,   6.8139,   9.4917,   9.1371,  -6.4986,\n",
      "          5.5705,   9.3354,   2.0396,  -8.5253,   7.7819,  -8.9399,   6.2706,\n",
      "         -7.5488,   8.4833,   9.4734,   3.9235,  -5.6219,  -4.9865,   8.9979,\n",
      "         -3.1855,   9.4641,   7.8474,   2.9949,   8.2262,  -2.2483,  -7.5767,\n",
      "          9.5753,  -9.1932,   1.0070,  -4.2491,  -9.7707,  -2.5466,   9.6606,\n",
      "        -10.0031,  -8.0778,   5.1688,   9.1479,  -3.1580,  -9.0038,   6.5279,\n",
      "          4.3742, -10.0320,   4.8811,   6.1997,   1.9268,   5.0448,   9.5770,\n",
      "         -9.0353,  -6.0337,  -9.8947,  -9.5300,   4.4053,   9.6823,  -0.9405,\n",
      "        -10.0176,  -9.9695,  -4.4322,  -4.2510,  -9.0389,   8.9734,  -6.9021,\n",
      "         -9.3880,  -2.8251,  -4.8910,   8.5490,  -3.1766,   1.9857,   6.6070,\n",
      "          2.3747,  -9.9591,   8.0690,  -9.8938,  -2.6421,   9.8005,  -8.8286,\n",
      "         -6.6697,   4.9629,   8.9713,   6.8403,   7.6081,  -9.7738,   9.6090,\n",
      "         -9.5187,   4.0144,   8.7613,  -9.9480,   4.2656,   9.5863,  -9.9723,\n",
      "         -9.9289,   0.8266,  -2.8703,  -9.8684,  -4.7613,  -7.0439,  -2.5964,\n",
      "         -9.7161,   4.8834,   7.9408,  -7.2810,   0.7742,  -7.8844,   9.3806,\n",
      "         -6.1301,   3.7145,  -9.4694,  -8.3651,  -1.0920,  -7.7313,   4.5895,\n",
      "          9.8114,   9.7553,   6.2932,  -5.6915,   2.9396,   4.7625,   3.5965,\n",
      "         -9.4693, -10.0284,  -6.5017,  -2.4538,   5.1009,   8.2787,   9.7398,\n",
      "         -9.6529,   4.8639,  -4.7270,  -1.2445,   2.9099,   7.4560,  -8.3062,\n",
      "          3.6131, -10.0287,   4.1751,   4.5452,   9.5940,   6.8995,   7.5439,\n",
      "         -9.4525,   8.4535,   6.3725,  -2.3141,  -8.0160,  -8.4805,   2.7257,\n",
      "         -1.6967,  -0.5011,   7.2513,  -7.2591,  -8.0721,   9.1860,  -9.6013,\n",
      "          0.3875, -10.0050,  -6.3865,   8.0014,   3.1080,   3.6464],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9999836311791546\n",
      "\n",
      "Dagma iter t=4 -- mu: 0.00010000000000000003 ------------------------------\n",
      "success:  False\n",
      "\n",
      "Minimize s=1.0 -- lr=0.00375\n",
      "\n",
      "mu 0.00010000000000000003\n",
      "\n",
      "Inner iteration 0\n",
      "\th(W(model)): 5.901285723330929e-05\n",
      "\tscore(model): 0.0004573429217419433\n",
      "\t mle: 4.188915206275809\n",
      "\t mse: 2.089836828203723\n",
      "\tW1: tensor([[1.0000e-04, 6.6521e+00],\n",
      "        [1.1546e-03, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 5.901285723330929e-05\n",
      "\tW2: tensor([[ 1.0010e+00, -5.5767e-06],\n",
      "        [-5.5767e-06,  9.9998e-01]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[0.9935, 0.0037],\n",
      "        [0.0037, 1.0075]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[ 3.6065e-03,  0.0000e+00],\n",
      "        [-2.0030e-05, -5.8800e-05]])\n",
      "Check y:  tensor([ 2.6377,  8.7017,  5.3543,  2.4155, -4.4403,  6.9963, -3.7523,  6.5892,\n",
      "         3.5493, -6.1770,  9.0888,  1.4889,  3.6834,  5.1891, -5.0735, -5.8123,\n",
      "        -2.7440,  8.4618,  9.1615,  7.3882,  2.9316,  9.0204, -2.4765,  9.1536,\n",
      "        -7.1352,  6.7969, -8.0330,  4.3633,  1.0719, -4.8609, -9.2561,  9.1703,\n",
      "        -2.7706,  3.7038, -2.6825,  5.9745,  5.7503,  5.9466,  4.4032,  8.0188,\n",
      "        -7.0411, -3.7805,  8.3753, -4.5685,  7.6265,  7.7323, -9.3809, -7.5384,\n",
      "        -8.3243, -6.8981,  3.7956, -3.7005,  2.5460, -6.4686, -9.3692, -8.5551,\n",
      "         7.2256, -9.3647, -2.2055, -9.4212, -8.4933, -6.8179,  7.3241, -7.8630,\n",
      "        -9.2412, -6.7226,  8.7019, -6.2550,  8.3361, -6.2112,  3.0190, -2.0729,\n",
      "         3.0068,  5.4446,  9.0195, -3.5907, -8.9996, -7.2102, -8.7548, -7.1530,\n",
      "        -8.2610, -4.8791, -4.7521,  8.2653,  3.6076, -9.2465,  1.1550, -6.1163,\n",
      "         4.0900,  5.0295, -8.2463,  7.6443, -7.6418,  8.7203, -8.8842, -9.0360,\n",
      "         4.6101, -2.7393,  8.5430, -2.0974,  7.9195, -9.1896,  8.9771,  3.6116,\n",
      "        -9.3969,  4.1006,  4.8710,  3.9017, -9.4455,  4.0144, -3.2567,  8.1167,\n",
      "         8.4131, -8.7286,  8.8262, -5.6532,  6.9941,  4.3556,  6.9708,  8.2666,\n",
      "         8.8538, -0.1555,  3.8714,  6.9337, -4.4307,  5.5110, -2.6999, -8.6423,\n",
      "         7.4384, -8.8718,  5.9896, -4.1929, -7.7706, -8.7113,  3.7835,  4.8165,\n",
      "         4.0077,  7.2285,  7.1944, -4.0623,  6.4009, -6.7638, -3.8397,  6.5833,\n",
      "         8.9370,  8.5002, -6.3906,  5.4511,  8.6861,  2.1511, -8.2224,  7.4522,\n",
      "        -8.5856,  5.8915, -7.3489,  8.0726,  8.9219,  3.7386, -5.1964, -4.9865,\n",
      "         8.3711, -2.9127,  8.8084,  7.5106,  3.0572,  7.8463, -2.3835, -7.0253,\n",
      "         8.9160, -8.8039,  1.0236, -4.2931, -9.2826, -2.6710,  9.0726, -9.4477,\n",
      "        -7.4965,  5.0820,  8.5103, -3.2569, -8.6410,  6.1254,  4.1545, -9.4458,\n",
      "         4.8166,  5.8269,  1.8833,  4.7713,  8.9176, -8.4084, -5.5816, -9.3768,\n",
      "        -9.0879,  4.3761,  9.0223, -0.8033, -9.4538, -9.3561, -4.4657, -3.9127,\n",
      "        -8.4119,  8.3484, -6.3935, -8.9693, -2.9384, -4.8970,  7.9590, -2.9043,\n",
      "         1.9383,  6.3960,  2.4703, -9.4216,  7.5225, -9.2700, -2.7627,  9.1513,\n",
      "        -8.2095, -6.1762,  4.6961,  8.4970,  6.4090,  7.2972, -9.1418,  9.0320,\n",
      "        -9.0786,  4.0126,  8.1532, -9.4143,  4.2464,  8.9267, -9.3595, -9.4012,\n",
      "         0.8547, -2.9817, -9.3575, -4.3909, -6.5261, -2.3594, -9.0820,  4.6231,\n",
      "         7.5936, -7.1060,  0.8056, -7.6514,  8.7288, -5.6717,  3.5453, -9.0375,\n",
      "        -8.0806, -0.9456, -7.1705,  4.5470,  9.1701,  9.0985,  6.1111, -5.6443,\n",
      "         2.8267,  4.5120,  3.6223, -8.8329, -9.4366, -6.3934, -2.5817,  5.0194,\n",
      "         7.7128,  9.1323, -9.0174,  4.6052, -4.7431, -1.0889,  2.9770,  7.1611,\n",
      "        -7.7123,  3.6378, -9.4553,  4.1622,  4.5059,  9.0200,  6.4627,  7.2398,\n",
      "        -8.8162,  8.0464,  5.9841, -2.4470, -7.4383, -8.1828,  2.8030, -1.5139,\n",
      "        -0.3906,  6.7816, -6.7276, -7.8195,  8.6808, -9.1466,  0.4432, -9.4486,\n",
      "        -6.2874,  7.6474,  3.1637,  3.6690], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9999836354738528\n",
      "Found h negative -1.421778252137754 at iter 2\n",
      "success:  False\n",
      "\n",
      "Minimize s=1 -- lr=0.001875\n",
      "\n",
      "mu 0.00010000000000000003\n",
      "\n",
      "Inner iteration 0\n",
      "\th(W(model)): 5.901285723330929e-05\n",
      "\tscore(model): 0.0004573429217419433\n",
      "\t mle: 4.03633720579153\n",
      "\t mse: 2.0157749655569486\n",
      "\tW1: tensor([[1.0000e-04, 6.6521e+00],\n",
      "        [1.1546e-03, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 5.901285723330929e-05\n",
      "\tW2: tensor([[ 1.0010e+00, -5.5767e-06],\n",
      "        [-5.5767e-06,  9.9998e-01]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[0.9973, 0.0019],\n",
      "        [0.0019, 1.0037]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[ 3.6065e-03,  0.0000e+00],\n",
      "        [-2.0030e-05, -5.8800e-05]])\n",
      "Check y:  tensor([ 2.6871,  9.0269,  5.5179,  2.4566, -4.6272,  7.2423, -3.9161,  6.7048,\n",
      "         3.5340, -6.4239,  9.3851,  1.4967,  3.7736,  5.2371, -5.0765, -5.8424,\n",
      "        -2.6833,  8.6961,  9.4721,  7.5492,  2.8968,  9.3075, -2.5988,  9.4620,\n",
      "        -7.2242,  7.0326, -8.1723,  4.3774,  1.0653, -5.0621, -9.5687,  9.4843,\n",
      "        -2.9024,  3.7948, -2.6206,  6.1683,  5.9329,  6.1389,  4.4188,  8.3167,\n",
      "        -7.3174, -3.9453,  8.6888, -4.5549,  7.9051,  8.0162, -9.6406, -7.6486,\n",
      "        -8.6362, -7.1696,  3.8904, -3.8626,  2.5002, -6.5260, -9.6267, -8.7299,\n",
      "         7.4836, -9.6706, -2.3191, -9.7203, -8.6636, -6.8914,  7.5871, -7.9919,\n",
      "        -9.4798, -6.9882,  8.9564, -6.3032,  8.5606, -6.2575,  2.9867, -2.1823,\n",
      "         2.9741,  5.6125,  9.3495, -3.5494, -9.3175, -7.3029, -9.0727, -7.2428,\n",
      "        -8.5716, -5.0809, -4.7443,  8.5743,  3.6947, -9.5595,  1.1513, -6.1586,\n",
      "         4.1971,  5.0707, -8.5566,  7.9238, -7.7578,  9.0459, -9.2025, -9.2517,\n",
      "         4.7397, -2.6784,  8.7838, -2.0249,  8.2126, -9.5044,  9.3072,  3.5984,\n",
      "        -9.6995,  4.2082,  5.0123,  4.0009, -9.7222,  4.0154, -3.4042,  8.3252,\n",
      "         8.7282, -9.0463,  9.0922, -5.8818,  7.1320,  4.4741,  7.1073,  8.5756,\n",
      "         9.1826, -0.2031,  3.8672,  7.1764, -4.6173,  5.6821, -2.6382, -8.9591,\n",
      "         7.7073, -9.1901,  6.1841, -4.3714, -7.8940, -9.0288,  3.8779,  4.9553,\n",
      "         4.1114,  7.4866,  7.4508, -4.2365,  6.5067, -7.0308, -4.0064,  6.6986,\n",
      "         9.2143,  8.8187, -6.4446,  5.5108,  9.0107,  2.0954, -8.3739,  7.6171,\n",
      "        -8.7627,  6.0810, -7.4488,  8.2780,  9.1977,  3.8311, -5.4092, -4.9865,\n",
      "         8.6845, -3.0491,  9.1362,  7.6790,  3.0261,  8.0363, -2.3159, -7.3010,\n",
      "         9.2457, -8.9986,  1.0153, -4.2711, -9.5266, -2.6088,  9.3666, -9.7254,\n",
      "        -7.7871,  5.1254,  8.8291, -3.2074, -8.8224,  6.3267,  4.2644, -9.7389,\n",
      "         4.8489,  6.0133,  1.9051,  4.9081,  9.2473, -8.7218, -5.8076, -9.6357,\n",
      "        -9.3090,  4.3907,  9.3523, -0.8719, -9.7357, -9.6628, -4.4490, -4.0818,\n",
      "        -8.7254,  8.6609, -6.6478, -9.1787, -2.8818, -4.8940,  8.2540, -3.0404,\n",
      "         1.9620,  6.5015,  2.4225, -9.6903,  7.7958, -9.5819, -2.7024,  9.4759,\n",
      "        -8.5191, -6.4230,  4.8295,  8.7342,  6.6246,  7.4527, -9.4578,  9.3205,\n",
      "        -9.2986,  4.0135,  8.4572, -9.6811,  4.2560,  9.2565, -9.6659, -9.6650,\n",
      "         0.8406, -2.9260, -9.6130, -4.5761, -6.7850, -2.4779, -9.3991,  4.7532,\n",
      "         7.7672, -7.1935,  0.7899, -7.7679,  9.0547, -5.9009,  3.6299, -9.2535,\n",
      "        -8.2228, -1.0188, -7.4509,  4.5682,  9.4908,  9.4269,  6.2022, -5.6679,\n",
      "         2.8832,  4.6373,  3.6094, -9.1511, -9.7325, -6.4476, -2.5178,  5.0602,\n",
      "         7.9958,  9.4361, -9.3351,  4.7345, -4.7350, -1.1667,  2.9435,  7.3085,\n",
      "        -8.0093,  3.6254, -9.7420,  4.1686,  4.5256,  9.3070,  6.6811,  7.3919,\n",
      "        -9.1343,  8.2500,  6.1783, -2.3806, -7.7272, -8.3317,  2.7643, -1.6053,\n",
      "        -0.4459,  7.0164, -6.9934, -7.9458,  8.9334, -9.3739,  0.4154, -9.7268,\n",
      "        -6.3370,  7.8244,  3.1359,  3.6577], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9999836354738528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 24/33000.0 [01:50<37:17:40,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.00010000000000000003\n",
      "\n",
      "Inner iteration 1000\n",
      "\th(W(model)): 3.0816549192014264e-05\n",
      "\tscore(model): 0.0005366899194113582\n",
      "\t mle: 5.050984343683095\n",
      "\t mse: 2.5256422624336916\n",
      "\tW1: tensor([[1.0000e-04, 5.1872e+00],\n",
      "        [1.0698e-03, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 3.0816549192014264e-05\n",
      "\tW2: tensor([[1.0001e+00, 2.4055e-05],\n",
      "        [2.4055e-05, 1.0001e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0001e+00, 2.3202e-05],\n",
      "        [2.3202e-05, 1.0001e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[3.7206e-05, 0.0000e+00],\n",
      "        [3.7277e-05, 1.4592e-05]])\n",
      "Check y:  tensor([ 3.2171,  7.8199,  5.7004,  3.0000, -4.1316,  6.9366, -3.3988,  6.6826,\n",
      "         4.8313, -5.9487,  7.8760,  2.0800,  4.2154,  5.9034, -5.6795, -6.1667,\n",
      "        -4.0488,  7.5817,  7.9216,  7.0825,  4.3717,  7.8405, -2.0394,  7.9154,\n",
      "        -7.0277,  6.8031, -7.6197,  5.3878,  1.6590, -4.5777, -8.6446,  7.9302,\n",
      "        -2.3523,  4.2344, -4.0027,  6.2008,  6.0239,  6.1790,  5.4138,  7.5268,\n",
      "        -6.8084, -3.4289,  7.6910, -5.3406,  7.3202,  7.3785, -8.6136, -7.2915,\n",
      "        -7.9669, -6.6694,  4.3199, -3.3436,  4.0659, -6.5943, -8.6022, -7.9766,\n",
      "         7.0831, -8.7008, -1.7518, -8.7216, -7.9335, -6.8213,  7.1437, -7.5061,\n",
      "        -8.4888, -6.4969,  7.6907, -6.4554,  7.5246, -6.4269,  4.4389, -1.6112,\n",
      "         4.4295,  5.7754,  7.9204, -4.6643, -8.4816, -7.0766, -8.3059, -7.0393,\n",
      "        -7.9144, -4.5969, -5.4645,  7.6428,  4.1445, -8.6391,  1.7432, -6.3651,\n",
      "         4.5913,  5.8073, -7.9021,  7.3302, -7.3596,  7.8265, -8.4006, -8.3258,\n",
      "         5.0598, -4.0452,  7.6185, -3.5521,  7.4770, -8.6052,  7.9090,  4.8757,\n",
      "        -8.7140,  4.6011,  5.2887,  4.4182, -8.6880,  5.1556, -2.8702,  7.4246,\n",
      "         7.7070, -8.2863,  7.7478, -5.4092,  6.8889,  4.8325,  6.8772,  7.6434,\n",
      "         7.8718,  0.4002,  5.0577,  6.8952, -4.1215,  5.8301, -4.0157, -8.2206,\n",
      "         7.2121, -8.3917,  6.2125, -3.8684, -7.4448, -8.2733,  4.3087,  5.2413,\n",
      "         4.5160,  7.0849,  7.0636, -3.7293,  6.5841, -6.5376, -3.4920,  6.6796,\n",
      "         7.7998,  7.7429, -6.5436,  6.0578,  7.8142,  3.7357, -7.7475,  7.1133,\n",
      "        -7.9979,  6.1358, -7.1672,  7.4043,  7.7927,  4.2669, -4.9316, -5.6215,\n",
      "         7.6892, -2.5036,  7.8569,  7.1412,  4.4680,  7.2997, -3.7753, -6.7931,\n",
      "         7.8913, -8.1536,  1.6100, -5.1531, -8.5238, -3.9940,  7.8674, -8.6915,\n",
      "        -7.2395,  5.8391,  7.7469, -4.4256, -8.0370,  6.3170,  4.6503, -8.7237,\n",
      "         5.6765,  6.0849,  2.4743,  5.2018,  7.8918, -8.0356, -5.3347, -8.6096,\n",
      "        -8.3658,  5.3962,  7.9211, -0.2742, -8.7042, -8.6970, -5.2709, -3.5698,\n",
      "        -8.0384,  7.6794, -6.1681, -8.2754, -4.1932, -5.5617,  7.4970, -2.4947,\n",
      "         2.5290,  6.5815,  4.0040, -8.6567,  7.2611, -8.6524, -4.0628,  7.9450,\n",
      "        -7.8713, -5.9478,  5.1357,  7.5976,  6.5288,  7.0383, -8.5755,  7.8463,\n",
      "        -8.3585,  5.1544,  7.5914, -8.6484,  5.3110,  7.8945, -8.6985, -8.6343,\n",
      "         1.4383, -4.2251, -8.5910, -4.0791, -6.3014, -1.9151, -8.5369,  5.0713,\n",
      "         7.1808, -7.0087,  1.3883, -7.3659,  7.8295, -5.4285,  4.0860, -8.3270,\n",
      "        -7.6516, -0.4231, -6.9327,  5.5065,  7.9425,  7.9384,  6.4287, -6.0566,\n",
      "         3.4004,  4.9726,  4.8833, -8.3636, -8.7241, -6.5455, -3.9266,  5.8012,\n",
      "         7.3679,  7.9012, -8.4937,  5.0554, -5.4584, -0.5733,  4.4067,  6.9717,\n",
      "        -7.4370,  4.8943, -8.7156,  5.2551,  5.4802,  7.8403,  6.5679,  7.0103,\n",
      "        -8.3513,  7.3923,  6.2083, -3.8241, -7.1855, -7.7206,  4.2714, -1.0203,\n",
      "         0.1561,  6.7927, -6.5019, -7.4772,  7.6811, -8.4118,  1.0176, -8.6931,\n",
      "        -6.4765,  7.2063,  4.5485,  4.9164], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  1.0000466539758133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 25/33000.0 [01:57<42:32:12,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.00010000000000000003\n",
      "\n",
      "Inner iteration 2000\n",
      "\th(W(model)): 2.1660669452749914e-05\n",
      "\tscore(model): 0.0004324236759876773\n",
      "\t mle: 4.106107119109049\n",
      "\t mse: 2.053156825609253\n",
      "\tW1: tensor([[1.0000e-04, 6.1888e+00],\n",
      "        [7.5167e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 2.1660669452749914e-05\n",
      "\tW2: tensor([[ 1.0001e+00, -8.0652e-06],\n",
      "        [-8.0652e-06,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0001e+00, -8.0745e-06],\n",
      "        [-8.0745e-06,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[ 3.7384e-07,  0.0000e+00],\n",
      "        [-1.4566e-07, -6.8308e-08]])\n",
      "Check y:  tensor([ 2.8146,  9.1783,  5.7944,  2.5714, -4.9249,  7.5603, -4.1669,  6.7750,\n",
      "         4.1199, -6.8352,  9.2338,  1.5590,  3.9610,  5.5490, -5.4043, -6.0213,\n",
      "        -3.5036,  8.5213,  9.3593,  7.4944,  3.5730,  9.1408, -2.7666,  9.3415,\n",
      "        -7.1742,  7.3511, -8.0179,  4.8314,  1.1040, -5.3888, -9.7894,  9.3848,\n",
      "        -3.0888,  3.9834, -3.4532,  6.4701,  6.2265,  6.4398,  4.8661,  8.5831,\n",
      "        -7.7659, -4.1980,  8.9074, -4.9891,  8.2032,  8.3076, -9.5766, -7.5447,\n",
      "        -9.0561, -7.6138,  4.0842, -4.1099,  3.2269, -6.5835, -9.5561, -8.5503,\n",
      "         7.7980, -9.8312, -2.4701, -9.8321, -8.4849, -6.8901,  7.8988, -7.8525,\n",
      "        -9.3607, -7.4261,  8.7722, -6.3987,  8.3946, -6.3610,  3.6509, -2.3251,\n",
      "         3.6400,  5.8932,  9.3952, -4.1928, -9.6267, -7.2422, -9.4355, -7.1903,\n",
      "        -8.9971, -5.4089, -5.1395,  8.8100,  3.8778, -9.7845,  1.1947, -6.2797,\n",
      "         4.4075,  5.4104, -8.9832,  8.2209, -7.6417,  9.1926, -9.5395, -9.0942,\n",
      "         4.9787, -3.4996,  8.6046, -2.9709,  8.4888, -9.7530,  9.3713,  4.1746,\n",
      "        -9.8352,  4.4192,  5.2650,  4.2007, -9.7193,  4.5273, -3.6221,  8.1790,\n",
      "         8.9404, -9.4138,  8.9090, -6.2615,  7.1367,  4.6992,  7.1157,  8.8111,\n",
      "         9.2909, -0.2336,  4.4023,  7.4948, -4.9143,  5.9657, -3.4674, -9.3407,\n",
      "         8.0149, -9.5298,  6.4864, -4.6521, -7.7639, -9.3993,  4.0710,  5.2052,\n",
      "         4.3172,  7.8009,  7.7658, -4.5083,  6.6084, -7.4702, -4.2631,  6.7698,\n",
      "         9.0373,  9.0148, -6.5158,  5.7768,  9.1661,  2.8675, -8.2063,  7.5532,\n",
      "        -8.5828,  6.3800, -7.3690,  8.1363,  9.0194,  4.0216, -5.7587, -5.3324,\n",
      "         8.9038, -3.2446,  9.2585,  7.6069,  3.6848,  7.9203, -3.2077, -7.7491,\n",
      "         9.3330, -8.8225,  1.0513, -4.7640, -9.4198, -3.4438,  9.2108, -9.7268,\n",
      "        -8.2415,  5.4559,  9.0232, -3.9216, -8.6425,  6.6333,  4.4784, -9.8148,\n",
      "         5.2255,  6.3098,  1.9896,  5.1557,  9.3341, -9.1334, -6.1827, -9.5694,\n",
      "        -9.1586,  4.8426,  9.3967, -0.9395, -9.7552, -9.8292, -4.9050, -4.3435,\n",
      "        -9.1366,  8.8839, -7.0706, -9.0138, -3.6623, -5.2587,  8.5265, -3.2354,\n",
      "         2.0497,  6.6040,  3.1584, -9.6567,  8.0995, -9.7962, -3.5189,  9.4378,\n",
      "        -8.9486, -6.8343,  5.0731,  8.5573,  6.9384,  7.4112, -9.7238,  9.1558,\n",
      "        -9.1468,  4.5257,  8.7081, -9.6408,  4.7296,  9.3400, -9.8300, -9.6144,\n",
      "         0.8671, -3.6976, -9.5362, -4.8704, -7.2144, -2.6384, -9.6846,  4.9929,\n",
      "         7.6837, -7.1478,  0.8137, -7.6507,  9.1992, -6.2818,  3.8094, -9.0961,\n",
      "        -8.0648, -1.0946, -7.9024,  4.9912,  9.4244,  9.4306,  6.3533, -5.8797,\n",
      "         3.0215,  4.8710,  4.1840, -9.4990, -9.8245, -6.5183, -3.3706,  5.4016,\n",
      "         8.2885,  9.3018, -9.6395,  4.9733, -5.1321, -1.2509,  3.6135,  7.2874,\n",
      "        -8.4614,  4.1976, -9.7843,  4.6563,  4.9555,  9.1402,  6.9960,  7.3589,\n",
      "        -9.4856,  8.1111,  6.4805, -3.2600, -8.1816, -8.1665,  3.4580, -1.7145,\n",
      "        -0.4898,  7.3349, -7.4314, -7.8107,  8.7496, -9.2334,  0.4187, -9.7302,\n",
      "        -6.4266,  7.7337,  3.7794,  4.2249], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  1.0000037786810443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 26/33000.0 [02:04<47:09:23,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.00010000000000000003\n",
      "\n",
      "Inner iteration 3000\n",
      "\th(W(model)): 2.0001838988203957e-05\n",
      "\tscore(model): 0.0004221224443754624\n",
      "\t mle: 4.019781596609758\n",
      "\t mse: 2.0099927932221773\n",
      "\tW1: tensor([[1.0000e-04, 6.3925e+00],\n",
      "        [6.9927e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 2.0001838988203957e-05\n",
      "\tW2: tensor([[ 1.0001e+00, -3.0575e-06],\n",
      "        [-3.0575e-06,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0001e+00, -3.0546e-06],\n",
      "        [-3.0546e-06,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-8.6047e-10,  0.0000e+00],\n",
      "        [ 8.8414e-11, -1.4442e-11]])\n",
      "Check y:  tensor([  2.6963,   9.3592,   5.6365,   2.4615,  -4.7206,   7.4856,  -3.9826,\n",
      "          6.7112,   3.7555,  -6.6292,   9.5402,   1.4888,   3.8112,   5.3208,\n",
      "         -5.1791,  -5.8589,  -3.1418,   8.7335,   9.6710,   7.5417,   3.1756,\n",
      "          9.4386,  -2.6352,   9.6533,  -7.1438,   7.2593,  -8.0887,   4.5264,\n",
      "          1.0536,  -5.1766,  -9.9246,   9.6955,  -2.9439,   3.8331,  -3.0893,\n",
      "          6.3297,   6.0782,   6.2983,   4.5644,   8.6358,  -7.5993,  -4.0127,\n",
      "          9.0222,  -4.7259,   8.1986,   8.3173,  -9.7893,  -7.5588,  -9.0210,\n",
      "         -7.4383,   3.9319,  -3.9274,   2.8147,  -6.4837,  -9.7684,  -8.6818,\n",
      "          7.7458,  -9.9951,  -2.3517, -10.0146,  -8.6093,  -6.8260,   7.8573,\n",
      "         -7.9036,  -9.5651,  -7.2409,   9.0223,  -6.2779,   8.5869,  -6.2359,\n",
      "          3.2575,  -2.2133,   3.2460,   5.7370,   9.6516,  -3.8688,  -9.7057,\n",
      "         -7.2200,  -9.4687,  -7.1618,  -8.9531,  -5.1965,  -4.8897,   8.9045,\n",
      "          3.7298,  -9.9173,   1.1403,  -6.1455,   4.2500,   5.1661,  -8.9372,\n",
      "          8.2186,  -7.6675,   9.3776,  -9.5962,  -9.2793,   4.8161,  -3.1377,\n",
      "          8.8296,  -2.5912,   8.5259,  -9.8725,   9.6166,   3.8141, -10.0091,\n",
      "          4.2615,   5.1024,   4.0464,  -9.9288,   4.1948,  -3.4563,   8.3367,\n",
      "          9.0623,  -9.4424,   9.1783,  -6.0465,   7.1278,   4.5384,   7.1036,\n",
      "          8.9059,   9.5062,  -0.2214,   4.0594,   7.4145,  -4.7103,   5.8109,\n",
      "         -3.1041,  -9.3547,   7.9866,  -9.5842,   6.3467,  -4.4541,  -7.8044,\n",
      "         -9.4249,   3.9190,   5.0424,   4.1610,   7.7491,   7.7104,  -4.3140,\n",
      "          6.5202,  -7.2872,  -4.0758,   6.7052,   9.3233,   9.1537,  -6.4082,\n",
      "          5.5762,   9.3436,   2.4453,  -8.2991,   7.6099,  -8.7179,   6.2364,\n",
      "         -7.3621,   8.2872,   9.3031,   3.8706,  -5.5433,  -5.1004,   9.0178,\n",
      "         -3.0934,   9.4632,   7.6722,   3.2932,   8.0362,  -2.8346,  -7.5815,\n",
      "          9.5632,  -8.9825,   1.0033,  -4.4820,  -9.6274,  -3.0795,   9.5153,\n",
      "         -9.9358,  -8.1105,   5.2169,   9.1642,  -3.5809,  -8.7839,   6.4995,\n",
      "          4.3200, -10.0083,   4.9607,   6.1640,   1.9017,   4.9928,   9.5647,\n",
      "         -9.1105,  -5.9673,  -9.7819,  -9.3490,   4.5386,   9.6538,  -0.8931,\n",
      "         -9.9614,  -9.9906,  -4.6346,  -4.1538,  -9.1143,   8.9936,  -6.8714,\n",
      "         -9.1920,  -3.3078,  -5.0197,   8.5697,  -3.0846,   1.9594,   6.5152,\n",
      "          2.7439,  -9.8690,   8.0815,  -9.9347,  -3.1578,   9.7335,  -8.8976,\n",
      "         -6.6282,   4.9103,   8.7750,   6.8197,   7.4453,  -9.8326,   9.4551,\n",
      "         -9.3363,   4.1930,   8.7830,  -9.8534,   4.4150,   9.5727,  -9.9924,\n",
      "         -9.8272,   0.8275,  -3.3449,  -9.7482,  -4.6673,  -7.0202,  -2.5126,\n",
      "         -9.7805,   4.8304,   7.7614,  -7.1143,   0.7764,  -7.6776,   9.3860,\n",
      "         -6.0670,   3.6629,  -9.2814,  -8.1411,  -1.0407,  -7.7447,   4.7018,\n",
      "          9.7289,   9.7091,   6.2288,  -5.7023,   2.8964,   4.7089,   3.8242,\n",
      "         -9.5462, -10.0133,  -6.4110,  -3.0034,   5.1563,   8.2955,   9.6124,\n",
      "         -9.7220,   4.8107,  -4.8816,  -1.1895,   3.2181,   7.3020,  -8.3513,\n",
      "          3.8388,  -9.9861,   4.3350,   4.6626,   9.4379,   6.8805,   7.3848,\n",
      "         -9.5297,   8.2579,   6.3405,  -2.8887,  -8.0454,  -8.2547,   3.0552,\n",
      "         -1.6309,  -0.4652,   7.2419,  -7.2466,  -7.8568,   8.9963,  -9.4295,\n",
      "          0.3998,  -9.9389,  -6.3089,   7.8194,   3.3931,   3.8682],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.999999988623326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 27/33000.0 [02:11<51:06:32,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.00010000000000000003\n",
      "\n",
      "Inner iteration 4000\n",
      "\th(W(model)): 1.7083353168967363e-05\n",
      "\tscore(model): 0.0004177656950107891\n",
      "\t mle: 4.0054013878947865\n",
      "\t mse: 2.0028026503048677\n",
      "\tW1: tensor([[1.0000e-04, 6.4804e+00],\n",
      "        [6.3743e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 1.7083353168967363e-05\n",
      "\tW2: tensor([[ 1.0001e+00, -1.3296e-06],\n",
      "        [-1.3296e-06,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0001e+00, -1.3289e-06],\n",
      "        [-1.3289e-06,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-2.6796e-11,  0.0000e+00],\n",
      "        [-1.2516e-10,  7.2812e-11]])\n",
      "Check y:  tensor([  2.6695,   9.4031,   5.6022,   2.4362,  -4.6751,   7.4679,  -3.9440,\n",
      "          6.7058,   3.6408,  -6.5743,   9.6312,   1.4709,   3.7786,   5.2593,\n",
      "         -5.0877,  -5.7999,  -2.9682,   8.8068,   9.7601,   7.5705,   3.0457,\n",
      "          9.5290,  -2.6111,   9.7430,  -7.1466,   7.2380,  -8.1328,   4.4360,\n",
      "          1.0395,  -5.1275,  -9.9635,   9.7834,  -2.9164,   3.8004,  -2.9141,\n",
      "          6.2987,   6.0456,   6.2670,   4.4754,   8.6467,  -7.5491,  -3.9738,\n",
      "          9.0485,  -4.6138,   8.1962,   8.3182,  -9.8717,  -7.5804,  -9.0019,\n",
      "         -7.3867,   3.8988,  -3.8894,   2.6771,  -6.4550,  -9.8512,  -8.7476,\n",
      "          7.7329, -10.0464,  -2.3308, -10.0748,  -8.6727,  -6.8138,   7.8467,\n",
      "         -7.9401,  -9.6493,  -7.1880,   9.1043,  -6.2393,   8.6554,  -6.1953,\n",
      "          3.1295,  -2.1938,   3.1178,   5.7029,   9.7179,  -3.7207,  -9.7231,\n",
      "         -7.2262,  -9.4705,  -7.1654,  -8.9315,  -5.1472,  -4.7850,   8.9257,\n",
      "          3.6975,  -9.9553,   1.1254,  -6.1005,   4.2159,   5.0988,  -8.9151,\n",
      "          8.2168,  -7.6939,   9.4226,  -9.6058,  -9.3604,   4.7810,  -2.9639,\n",
      "          8.9060,  -2.4026,   8.5332,  -9.9050,   9.6794,   3.7011, -10.0651,\n",
      "          4.2274,   5.0672,   4.0129, -10.0056,   4.0934,  -3.4233,   8.3963,\n",
      "          9.0905,  -9.4426,   9.2642,  -5.9925,   7.1396,   4.5037,   7.1144,\n",
      "          8.9272,   9.5598,  -0.2234,   3.9537,   7.3956,  -4.6648,   5.7772,\n",
      "         -2.9293,  -9.3502,   7.9789,  -9.5930,   6.3157,  -4.4110,  -7.8367,\n",
      "         -9.4242,   3.8859,   5.0072,   4.1271,   7.7362,   7.6968,  -4.2722,\n",
      "          6.5068,  -7.2345,  -4.0363,   6.6995,   9.4121,   9.1863,  -6.3759,\n",
      "          5.5247,   9.3865,   2.3014,  -8.3514,   7.6414,  -8.7848,   6.2047,\n",
      "         -7.3748,   8.3450,   9.3917,   3.8377,  -5.4917,  -5.0054,   9.0438,\n",
      "         -3.0642,   9.5138,   7.7062,   3.1662,   8.0845,  -2.6521,  -7.5311,\n",
      "          9.6213,  -9.0570,   0.9897,  -4.3592,  -9.7116,  -2.9040,   9.6063,\n",
      "        -10.0121,  -8.0673,   5.1515,   9.1973,  -3.4220,  -8.8529,   6.4697,\n",
      "          4.2857, -10.0744,   4.8857,   6.1319,   1.8805,   4.9577,   9.6229,\n",
      "         -9.0950,  -5.9136,  -9.8645,  -9.4312,   4.4487,   9.7204,  -0.8881,\n",
      "        -10.0355, -10.0408,  -4.5185,  -4.1135,  -9.0989,   9.0186,  -6.8169,\n",
      "         -9.2714,  -3.1395,  -4.9210,   8.5784,  -3.0555,   1.9378,   6.5016,\n",
      "          2.6050,  -9.9490,   8.0761,  -9.9751,  -2.9846,   9.8138,  -8.8741,\n",
      "         -6.5734,   4.8752,   8.8497,   6.7928,   7.4701,  -9.8610,   9.5457,\n",
      "         -9.4183,   4.0916,   8.7994,  -9.9340,   4.3209,   9.6316, -10.0431,\n",
      "         -9.9087,   0.8154,  -3.1778,  -9.8313,  -4.6223,  -6.9662,  -2.4899,\n",
      "         -9.8041,   4.7952,   7.7990,  -7.1156,   0.7648,  -7.7045,   9.4315,\n",
      "         -6.0130,   3.6308,  -9.3625,  -8.1872,  -1.0341,  -7.6962,   4.6176,\n",
      "          9.8130,   9.7828,   6.2035,  -5.6359,   2.8684,   4.6739,   3.7115,\n",
      "         -9.5525, -10.0768,  -6.3788,  -2.8256,   5.0886,   8.2957,   9.7030,\n",
      "         -9.7407,   4.7756,  -4.7766,  -1.1813,   3.0892,   7.3210,  -8.3128,\n",
      "          3.7265, -10.0572,   4.2382,   4.5769,   9.5284,   6.8543,   7.4071,\n",
      "         -9.5351,   8.3146,   6.3095,  -2.7076,  -8.0011,  -8.3053,   2.9225,\n",
      "         -1.6179,  -0.4647,   7.2204,  -7.1936,  -7.8913,   9.0776,  -9.5127,\n",
      "          0.3917, -10.0150,  -6.2718,   7.8593,   3.2685,   3.7568],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.999999290635716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 28/33000.0 [02:18<54:04:26,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 0.00010000000000000003\n",
      "\n",
      "Inner iteration 4999\n",
      "\th(W(model)): 1.3706759262710477e-05\n",
      "\tscore(model): 0.0004138564860067197\n",
      "\t mle: 4.000068473135923\n",
      "\t mse: 2.000136286419208\n",
      "\tW1: tensor([[1.0000e-04, 6.5216e+00],\n",
      "        [5.6728e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 1.3706759262710477e-05\n",
      "\tW2: tensor([[ 1.0001e+00, -9.1262e-07],\n",
      "        [-9.1262e-07,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0001e+00, -9.1236e-07],\n",
      "        [-9.1236e-07,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-3.0145e-11,  0.0000e+00],\n",
      "        [-2.6903e-11,  3.5018e-11]])\n",
      "Check y:  tensor([  2.6731,   9.4042,   5.6121,   2.4387,  -4.6918,   7.4725,  -3.9635,\n",
      "          6.7211,   3.6042,  -6.5758,   9.6545,   1.4684,   3.7864,   5.2519,\n",
      "         -5.0610,  -5.7931,  -2.8795,   8.8380,   9.7789,   7.5958,   2.9987,\n",
      "          9.5545,  -2.6313,   9.7625,  -7.1714,   7.2436,  -8.1726,   4.4138,\n",
      "          1.0346,  -5.1416,  -9.9572,   9.8008,  -2.9369,   3.8083,  -2.8239,\n",
      "          6.3074,   6.0549,   6.2759,   4.4539,   8.6467,  -7.5399,  -3.9932,\n",
      "          9.0482,  -4.5732,   8.1977,   8.3192,  -9.9001,  -7.6130,  -8.9818,\n",
      "         -7.3792,   3.9070,  -3.9090,   2.6240,  -6.4648,  -9.8805,  -8.7913,\n",
      "          7.7364, -10.0468,  -2.3506, -10.0808,  -8.7162,  -6.8318,   7.8497,\n",
      "         -7.9778,  -9.6850,  -7.1827,   9.1344,  -6.2438,   8.6865,  -6.1988,\n",
      "          3.0839,  -2.2133,   3.0720,   5.7128,   9.7239,  -3.6535,  -9.7085,\n",
      "         -7.2526,  -9.4520,  -7.1906,  -8.9114,  -5.1611,  -4.7494,   8.9254,\n",
      "          3.7051,  -9.9486,   1.1210,  -6.1016,   4.2248,   5.0885,  -8.8950,\n",
      "          8.2182,  -7.7282,   9.4238,  -9.5890,  -9.4013,   4.7909,  -2.8751,\n",
      "          8.9370,  -2.2993,   8.5335,  -9.8960,   9.6844,   3.6656, -10.0683,\n",
      "          4.2364,   5.0773,   4.0214, -10.0260,   4.0650,  -3.4437,   8.4270,\n",
      "          9.0903,  -9.4240,   9.2932,  -5.9998,   7.1603,   4.5132,   7.1348,\n",
      "          8.9268,   9.5626,  -0.2352,   3.9228,   7.4005,  -4.6816,   5.7869,\n",
      "         -2.8395,  -9.3309,   7.9813,  -9.5760,   6.3244,  -4.4289,  -7.8730,\n",
      "         -9.4054,   3.8941,   5.0173,   4.1359,   7.7396,   7.7004,  -4.2906,\n",
      "          6.5194,  -7.2288,  -4.0556,   6.7148,   9.4394,   9.1863,  -6.3838,\n",
      "          5.5218,   9.3875,   2.2426,  -8.3932,   7.6673,  -8.8286,   6.2137,\n",
      "         -7.4039,   8.3755,   9.4192,   3.8457,  -5.5032,  -4.9763,   9.0435,\n",
      "         -3.0847,   9.5160,   7.7327,   3.1212,   8.1137,  -2.5550,  -7.5221,\n",
      "          9.6250,  -9.1004,   0.9845,  -4.3110,  -9.7457,  -2.8135,   9.6301,\n",
      "        -10.0319,  -8.0528,   5.1421,   9.1973,  -3.3461,  -8.8967,   6.4780,\n",
      "          4.2948, -10.0848,   4.8717,   6.1410,   1.8802,   4.9677,   9.6266,\n",
      "         -9.0748,  -5.9215,  -9.8932,  -9.4711,   4.4267,   9.7265,  -0.9031,\n",
      "        -10.0530, -10.0405,  -4.4750,  -4.1325,  -9.0787,   9.0183,  -6.8157,\n",
      "         -9.3133,  -3.0556,  -4.8895,   8.5786,  -3.0760,   1.9377,   6.5141,\n",
      "          2.5507,  -9.9734,   8.0781,  -9.9695,  -2.8964,   9.8257,  -8.8541,\n",
      "         -6.5748,   4.8851,   8.8808,   6.8001,   7.4944,  -9.8502,   9.5709,\n",
      "         -9.4585,   4.0632,   8.7991,  -9.9593,   4.2966,   9.6356, -10.0430,\n",
      "         -9.9353,   0.8092,  -3.0949,  -9.8614,  -4.6392,  -6.9634,  -2.5100,\n",
      "         -9.7915,   4.8051,   7.8262,  -7.1399,   0.7584,  -7.7389,   9.4329,\n",
      "         -6.0200,   3.6382,  -9.4034,  -8.2276,  -1.0498,  -7.6854,   4.5987,\n",
      "          9.8273,   9.7916,   6.2115,  -5.6246,   2.8729,   4.6837,   3.6761,\n",
      "         -9.5350, -10.0853,  -6.3868,  -2.7330,   5.0782,   8.2969,   9.7241,\n",
      "         -9.7265,   4.7855,  -4.7408,  -1.1976,   3.0429,   7.3438,  -8.2961,\n",
      "          3.6914, -10.0717,   4.2124,   4.5573,   9.5538,   6.8614,   7.4308,\n",
      "         -9.5173,   8.3450,   6.3182,  -2.6120,  -7.9871,  -8.3468,   2.8734,\n",
      "         -1.6358,  -0.4777,   7.2260,  -7.1883,  -7.9284,   9.1079,  -9.5513,\n",
      "          0.3832, -10.0345,  -6.2772,   7.8870,   3.2253,   3.7222],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9999989803048325\n",
      "\n",
      "Dagma iter t=5 -- mu: 1.0000000000000004e-05 ------------------------------\n",
      "success:  False\n",
      "\n",
      "Minimize s=1.0 -- lr=0.001875\n",
      "\n",
      "mu 1.0000000000000004e-05\n",
      "\n",
      "Inner iteration 0\n",
      "\th(W(model)): 1.3702967697870605e-05\n",
      "\tscore(model): 5.37270764845055e-05\n",
      "\t mle: 4.230936285243642\n",
      "\t mse: 2.1118549532032884\n",
      "\tW1: tensor([[1.0000e-04, 6.5216e+00],\n",
      "        [5.6720e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 1.3702967697870605e-05\n",
      "\tW2: tensor([[ 1.0001e+00, -9.1236e-07],\n",
      "        [-9.1236e-07,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[0.9964, 0.0019],\n",
      "        [0.0019, 1.0037]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[ 3.6364e-04,  0.0000e+00],\n",
      "        [-3.2847e-06, -3.6426e-06]])\n",
      "Check y:  tensor([ 2.6203,  9.0833,  5.4462,  2.3941, -4.5112,  7.2258, -3.8056,  6.6245,\n",
      "         3.6374, -6.3356,  9.3701,  1.4568,  3.6931,  5.2230, -5.0593, -5.7641,\n",
      "        -2.9414,  8.6194,  9.4788,  7.4531,  3.0505,  9.2801, -2.5145,  9.4650,\n",
      "        -7.0832,  7.0070, -8.0339,  4.4185,  1.0372, -4.9468, -9.6479,  9.4969,\n",
      "        -2.8107,  3.7142, -2.8871,  6.1119,  5.8702,  6.0817,  4.4571,  8.3504,\n",
      "        -7.2702, -3.8344,  8.7373, -4.5881,  7.9196,  8.0360, -9.6415, -7.5034,\n",
      "        -8.6752, -7.1143,  3.8092, -3.7528,  2.6860, -6.4083, -9.6241, -8.6169,\n",
      "         7.4781, -9.7434, -2.2423, -9.7840, -8.5464, -6.7591,  7.5865, -7.8495,\n",
      "        -9.4473, -6.9237,  8.8947, -6.1966,  8.4782, -6.1534,  3.1333, -2.1092,\n",
      "         3.1217,  5.5426,  9.4004, -3.6961, -9.3945, -7.1606, -9.1388, -7.1015,\n",
      "        -8.6062, -4.9657, -4.7584,  8.6187,  3.6148, -9.6389,  1.1208, -6.0602,\n",
      "         4.1148,  5.0665, -8.5902,  7.9392, -7.6128,  9.1025, -9.2750, -9.1862,\n",
      "         4.6586, -2.9372,  8.7116, -2.3729,  8.2416, -9.5845,  9.3604,  3.6968,\n",
      "        -9.7681,  4.1259,  4.9334,  3.9192, -9.7508,  4.0824, -3.3018,  8.2353,\n",
      "         8.7780, -9.1109,  9.0413, -5.7778,  7.0412,  4.3919,  7.0170,  8.6201,\n",
      "         9.2390, -0.1920,  3.9452,  7.1570, -4.5013,  5.6136, -2.9024, -9.0188,\n",
      "         7.7124, -9.2620,  6.1282, -4.2565, -7.7502, -9.0925,  3.7967,  4.8759,\n",
      "         4.0293,  7.4812,  7.4437, -4.1226,  6.4328, -6.9684, -3.8948,  6.6185,\n",
      "         9.1754,  8.8711, -6.3307,  5.4814,  9.0670,  2.3138, -8.2423,  7.5206,\n",
      "        -8.6519,  6.0222, -7.3046,  8.1870,  9.1570,  3.7502, -5.2970, -4.9775,\n",
      "         8.7328, -2.9540,  9.1930,  7.5823,  3.1694,  7.9413, -2.6238, -7.2529,\n",
      "         9.3010, -8.9063,  0.9888, -4.3342, -9.5025, -2.8769,  9.3483, -9.7557,\n",
      "        -7.7684,  5.1179,  8.8818, -3.3969, -8.7158,  6.2750,  4.1820, -9.7937,\n",
      "         4.8585,  5.9526,  1.8548,  4.8283,  9.3026, -8.7665, -5.7021, -9.6354,\n",
      "        -9.2508,  4.4309,  9.4030, -0.8392, -9.7728, -9.7365, -4.4931, -3.9694,\n",
      "        -8.7704,  8.7084, -6.5681, -9.1046, -3.1135, -4.8937,  8.2850, -2.9455,\n",
      "         1.9104,  6.4277,  2.6146, -9.7059,  7.8051, -9.6607, -2.9579,  9.5096,\n",
      "        -8.5501, -6.3347,  4.7491,  8.6593,  6.5831,  7.3573, -9.5378,  9.2949,\n",
      "        -9.2390,  4.0807,  8.4970, -9.6937,  4.3056,  9.3115, -9.7392, -9.6726,\n",
      "         0.8192, -3.1519, -9.6070, -4.4603, -6.7111, -2.3968, -9.4782,  4.6723,\n",
      "         7.6705, -7.0532,  0.7700, -7.6230,  9.1113, -5.7974,  3.5504, -9.1881,\n",
      "        -8.0859, -0.9813, -7.4114,  4.5963,  9.5158,  9.4707,  6.1397, -5.6021,\n",
      "         2.8130,  4.5557,  3.7070, -9.2212, -9.7915, -6.3336, -2.7982,  5.0566,\n",
      "         8.0146,  9.4317, -9.4126,  4.6535, -4.7500, -1.1246,  3.0935,  7.2148,\n",
      "        -8.0052,  3.7218, -9.7868,  4.2246,  4.5565,  9.2795,  6.6416,  7.2972,\n",
      "        -9.2036,  8.1584,  6.1222, -2.6796, -7.7046, -8.1984,  2.9288, -1.5494,\n",
      "        -0.4270,  6.9902, -6.9291, -7.8027,  8.8702, -9.3247,  0.4068, -9.7579,\n",
      "        -6.2286,  7.7278,  3.2705,  3.7515], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9999989800126423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/33000.0 [02:25<46:05:04,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 1.0000000000000004e-05\n",
      "\n",
      "Inner iteration 1000\n",
      "\th(W(model)): 7.653993747691601e-06\n",
      "\tscore(model): 6.597865357418968e-05\n",
      "\t mle: 5.816328343418215\n",
      "\t mse: 2.908207120473776\n",
      "\tW1: tensor([[1.0000e-04, 4.8400e+00],\n",
      "        [5.7086e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 7.653993747691601e-06\n",
      "\tW2: tensor([[1.0000e+00, 1.3126e-05],\n",
      "        [1.3126e-05, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0000e+00, 1.1112e-05],\n",
      "        [1.1112e-05, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[1.8868e-05, 0.0000e+00],\n",
      "        [2.7688e-05, 6.3071e-05]])\n",
      "Check y:  tensor([ 2.8202,  7.4708,  5.0392,  2.6358, -3.3242,  6.3175, -2.6899,  5.8867,\n",
      "         4.0126, -4.9810,  7.5338,  1.8628,  3.6829,  5.0417, -5.0428, -5.5453,\n",
      "        -3.4517,  7.0604,  7.6156,  6.3729,  3.6006,  7.4725, -1.5423,  7.6042,\n",
      "        -6.4611,  6.1674, -7.1043,  4.5324,  1.5127, -3.7180, -8.0066,  7.6319,\n",
      "        -1.8040,  3.6996, -3.4087,  5.5316,  5.3546,  5.5096,  4.5574,  7.0468,\n",
      "        -5.8327, -2.7157,  7.2775, -4.7006,  6.7766,  6.8509, -8.1331, -6.7471,\n",
      "        -7.1076, -5.6908,  3.7749, -2.6426,  3.3333, -5.9961, -8.1237, -7.4910,\n",
      "         6.4875, -8.1074, -1.3028, -8.1596, -7.4447, -6.2387,  6.5595, -6.9807,\n",
      "        -8.0210, -5.5172,  7.2277, -5.8488,  6.9759, -5.8186,  3.6600, -1.1860,\n",
      "         3.6517,  5.1115,  7.6282, -4.0360, -7.7642, -6.5140, -7.5287, -6.4737,\n",
      "        -7.0451, -3.7351, -4.8250,  7.2081,  3.6206, -7.9976,  1.5826, -5.7534,\n",
      "         4.0159,  4.9443, -7.0306,  6.7892, -6.8212,  7.4810, -7.6536, -7.8591,\n",
      "         4.4394, -3.4484,  7.1160, -2.9937,  6.9798, -7.9442,  7.6104,  4.0531,\n",
      "        -8.1372,  4.0245,  4.6506,  3.8618, -8.1852,  4.3123, -2.2400,  6.8318,\n",
      "         7.3009, -7.5033,  7.3187, -4.4727,  6.1318,  4.2325,  6.1176,  7.2089,\n",
      "         7.5518,  0.4731,  4.2209,  6.2706, -3.3153,  5.1644, -3.4208, -7.4193,\n",
      "         6.6423, -7.6416,  5.5434, -3.0947, -6.9139, -7.4865,  3.7650,  4.6065,\n",
      "         3.9486,  6.4896,  6.4645, -2.9742,  5.7733, -5.5579, -2.7698,  5.8832,\n",
      "         7.4039,  7.3539, -5.9422,  5.2008,  7.4620,  3.0495, -7.2433,  6.4124,\n",
      "        -7.5140,  5.4661, -6.6122,  6.8032,  7.3920,  3.7282, -4.0355, -4.9838,\n",
      "         7.2748, -1.9309,  7.5284,  6.4485,  3.6858,  6.6587, -3.1980, -5.8170,\n",
      "         7.5824, -7.6799,  1.4721, -4.5139, -8.0540, -3.4006,  7.5186, -8.1868,\n",
      "        -6.2858,  4.9764,  7.3600, -3.8072, -7.5558,  5.6499,  4.0686, -8.1825,\n",
      "         4.8137,  5.4152,  2.1926,  4.5700,  7.5831, -7.1903, -4.4038, -8.1298,\n",
      "        -7.8998,  4.5404,  7.6293, -0.0819, -8.1915, -8.0995, -4.6310, -2.8367,\n",
      "        -7.1938,  7.2607, -5.1929, -7.8073, -3.5871, -4.9232,  7.0066, -1.9234,\n",
      "         2.2385,  5.7703,  3.2797, -8.1660,  6.7027, -8.0195, -3.4648,  7.6634,\n",
      "        -6.9943, -4.9802,  4.5091,  7.0845,  5.8704,  6.3169, -7.8991,  7.4824,\n",
      "        -7.8924,  4.3111,  7.1357, -8.1601,  4.4590,  7.5874, -8.1026, -8.1495,\n",
      "         1.3297, -3.6171, -8.1142, -3.2783, -5.3234, -1.4387, -7.8426,  4.4499,\n",
      "         6.5001, -6.4406,  1.2884, -6.8281,  7.4857, -4.4906,  3.5694, -7.8604,\n",
      "        -7.1391, -0.2045, -5.9613,  4.6470,  7.6564,  7.6555,  5.5989, -5.4307,\n",
      "         2.9767,  4.3597,  4.0601, -7.6042, -8.1739, -5.9442, -3.3379,  4.9382,\n",
      "         6.8373,  7.5784, -7.7811,  4.4354, -4.8189, -0.3283,  3.6315,  6.2335,\n",
      "        -6.5007,  4.0702, -8.1920,  4.4060,  4.6214,  7.4721,  5.9119,  6.2817,\n",
      "        -7.5880,  6.7864,  5.5391, -3.2430, -6.2278, -7.2142,  3.5124, -0.6969,\n",
      "         0.2722,  6.1558, -5.5221, -6.9492,  7.2126, -7.9459,  0.9820, -8.1876,\n",
      "        -5.8711,  6.5336,  3.7575,  4.0904], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  1.0000057768202097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 31/33000.0 [02:32<50:00:23,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 1.0000000000000004e-05\n",
      "\n",
      "Inner iteration 2000\n",
      "\th(W(model)): 8.111231192042823e-06\n",
      "\tscore(model): 4.925321532462378e-05\n",
      "\t mle: 4.112862650434228\n",
      "\t mse: 2.0564415342447533\n",
      "\tW1: tensor([[1.0000e-04, 6.0922e+00],\n",
      "        [4.6691e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 8.111231192042823e-06\n",
      "\tW2: tensor([[ 1.0000e+00, -2.4489e-07],\n",
      "        [-2.4489e-07,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0000e+00, -2.1881e-07],\n",
      "        [-2.1881e-07,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-3.5703e-07,  0.0000e+00],\n",
      "        [-1.6762e-07, -5.0537e-07]])\n",
      "Check y:  tensor([ 2.7181,  9.1287,  5.6012,  2.4870, -4.6528,  7.3925, -3.9130,  6.6456,\n",
      "         4.0859, -6.5603,  9.1930,  1.5285,  3.8139,  5.4461, -5.3218, -5.9446,\n",
      "        -3.4351,  8.4306,  9.3301,  7.3685,  3.5723,  9.0920, -2.5646,  9.3106,\n",
      "        -7.1187,  7.1753, -7.9826,  4.7591,  1.0990, -5.1098, -9.7168,  9.3580,\n",
      "        -2.8731,  3.8354, -3.3858,  6.2763,  6.0316,  6.2458,  4.7921,  8.4778,\n",
      "        -7.5181, -3.9432,  8.8308, -4.9053,  8.0699,  8.1813, -9.5594, -7.4978,\n",
      "        -8.8885, -7.3601,  3.9324, -3.8577,  3.2484, -6.5158, -9.5394, -8.5271,\n",
      "         7.6410, -9.7751, -2.2815, -9.7874, -8.4604, -6.8284,  7.7471, -7.8132,\n",
      "        -9.3469, -7.1658,  8.6963, -6.3277,  8.2974, -6.2894,  3.6453, -2.1433,\n",
      "         3.6351,  5.6992,  9.3690, -4.1132, -9.5228, -7.1883, -9.3064, -7.1352,\n",
      "        -8.8244, -5.1297, -5.0559,  8.7242,  3.7339, -9.7106,  1.1845, -6.2068,\n",
      "         4.2443,  5.3127, -8.8094,  8.0887, -7.5972,  9.1445, -9.4234, -9.0797,\n",
      "         4.7991, -3.4313,  8.5185, -2.9158,  8.3760, -9.6716,  9.3424,  4.1375,\n",
      "        -9.7851,  4.2556,  5.0792,  4.0446, -9.6949,  4.4706, -3.3859,  8.0721,\n",
      "         8.8668, -9.2821,  8.8423, -5.9799,  7.0071,  4.5271,  6.9860,  8.7255,\n",
      "         9.2533, -0.1625,  4.3523,  7.3243, -4.6425,  5.7713, -3.3997, -9.2009,\n",
      "         7.8698, -9.4124,  6.2928, -4.3857, -7.7224, -9.2660,  3.9196,  5.0206,\n",
      "         4.1571,  7.6441,  7.6073, -4.2452,  6.4804, -7.2114, -4.0065,  6.6405,\n",
      "         8.9802,  8.9485, -6.4468,  5.6663,  9.1152,  2.9124, -8.1755,  7.4282,\n",
      "        -8.5604,  6.1856, -7.3181,  8.0278,  8.9609,  3.8721, -5.4770, -5.2495,\n",
      "         8.8267, -3.0226,  9.2174,  7.4830,  3.6771,  7.8043, -3.1461, -7.5006,\n",
      "         9.3000, -8.8044,  1.0493, -4.6805, -9.4056, -3.3766,  9.1680, -9.7018,\n",
      "        -8.0166,  5.3565,  8.9578, -3.8456, -8.6212,  6.4411,  4.3130, -9.7774,\n",
      "         5.1352,  6.1152,  1.9357,  4.9721,  9.3012, -8.9728, -5.9008, -9.5523,\n",
      "        -9.1445,  4.7697,  9.3707, -0.8291, -9.7276, -9.7717, -4.8212, -4.0847,\n",
      "        -8.9763,  8.8050, -6.8006, -8.9985, -3.5906, -5.1755,  8.4167, -3.0138,\n",
      "         1.9925,  6.4761,  3.1843, -9.6362,  7.9595, -9.7255, -3.4501,  9.4163,\n",
      "        -8.7718, -6.5593,  4.8913,  8.4685,  6.7513,  7.2840, -9.6364,  9.1082,\n",
      "        -9.1327,  4.4691,  8.6133, -9.6211,  4.6624,  9.3077, -9.7731, -9.5958,\n",
      "         0.8755, -3.6253, -9.5200, -4.5994, -6.9479, -2.4422, -9.5901,  4.8130,\n",
      "         7.5615, -7.0917,  0.8251, -7.6065,  9.1517, -6.0004,  3.6682, -9.0816,\n",
      "        -8.0306, -0.9757, -7.6605,  4.9113,  9.4017,  9.4084,  6.2288, -5.8013,\n",
      "         2.9150,  4.6941,  4.1463, -9.3776, -9.7839, -6.4493, -3.3051,  5.3042,\n",
      "         8.1609,  9.2672, -9.5376,  4.7939, -5.0485, -1.1236,  3.6103,  7.1589,\n",
      "        -8.2495,  4.1591, -9.7529,  4.5927,  4.8773,  9.0914,  6.8101,  7.2311,\n",
      "        -9.3625,  8.0016,  6.2867, -3.1971, -7.9534, -8.1348,  3.4646, -1.5628,\n",
      "        -0.4043,  7.1586, -7.1714, -7.7704,  8.6722, -9.2197,  0.4527, -9.7049,\n",
      "        -6.3561,  7.6126,  3.7659,  4.1849], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  1.0000003201269227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 32/33000.0 [02:39<53:14:44,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 1.0000000000000004e-05\n",
      "\n",
      "Inner iteration 3000\n",
      "\th(W(model)): 5.7543761555756134e-06\n",
      "\tscore(model): 4.627015002419347e-05\n",
      "\t mle: 4.050258202388336\n",
      "\t mse: 2.0251393464403336\n",
      "\tW1: tensor([[1.0000e-04, 6.2691e+00],\n",
      "        [3.8198e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 5.7543761555756134e-06\n",
      "\tW2: tensor([[ 1.0000e+00, -1.0679e-07],\n",
      "        [-1.0679e-07,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0000e+00, -1.0652e-07],\n",
      "        [-1.0652e-07,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[ 4.0429e-09,  0.0000e+00],\n",
      "        [ 6.3249e-10, -2.3940e-09]])\n",
      "Check y:  tensor([ 2.6770,  9.2904,  5.5573,  2.4484, -4.6098,  7.4002, -3.8723,  6.6351,\n",
      "         3.8533, -6.5314,  9.4367,  1.5017,  3.7645,  5.3163, -5.1925, -5.8565,\n",
      "        -3.2122,  8.6123,  9.5767,  7.4367,  3.3134,  9.3304, -2.5349,  9.5573,\n",
      "        -7.1154,  7.1729, -8.0437,  4.5720,  1.0781, -5.0673, -9.8502,  9.6038,\n",
      "        -2.8403,  3.7859, -3.1613,  6.2444,  5.9946,  6.2132,  4.6075,  8.5611,\n",
      "        -7.5124, -3.9023,  8.9517, -4.7508,  8.1190,  8.2390, -9.7180, -7.5229,\n",
      "        -8.9464, -7.3496,  3.8825, -3.8173,  2.9771, -6.4681, -9.6974, -8.6273,\n",
      "         7.6621, -9.9204, -2.2550, -9.9399, -8.5559, -6.8036,  7.7745, -7.8618,\n",
      "        -9.4971, -7.1500,  8.9035, -6.2665,  8.4656, -6.2254,  3.3897, -2.1185,\n",
      "         3.3790,  5.6566,  9.5785, -3.9173, -9.6320, -7.1902, -9.3952, -7.1331,\n",
      "        -8.8781, -5.0872, -4.9104,  8.8328,  3.6849, -9.8430,  1.1625, -6.1369,\n",
      "         4.1936,  5.1709, -8.8622,  8.1393, -7.6297,  9.3087, -9.5227, -9.2156,\n",
      "         4.7489, -3.2082,  8.7089, -2.6788,  8.4500, -9.7983,  9.5448,  3.9079,\n",
      "        -9.9343,  4.2049,  5.0304,  3.9944, -9.8555,  4.2625, -3.3485,  8.2168,\n",
      "         8.9921, -9.3689,  9.0623, -5.9430,  7.0356,  4.4763,  7.0123,  8.8343,\n",
      "         9.4366, -0.1649,  4.1363,  7.3288, -4.5995,  5.7298, -3.1756, -9.2811,\n",
      "         7.9049, -9.5107,  6.2613, -4.3431, -7.7643, -9.3514,  3.8698,  4.9714,\n",
      "         4.1065,  7.6654,  7.6265, -4.2030,  6.4524, -7.1968, -3.9653,  6.6294,\n",
      "         9.2110,  9.0842, -6.3941,  5.5568,  9.2748,  2.6319, -8.2507,  7.5030,\n",
      "        -8.6628,  6.1517, -7.3297,  8.1678,  9.1903,  3.8225, -5.4359, -5.1158,\n",
      "         8.9472, -2.9884,  9.3940,  7.5637,  3.4230,  7.9202, -2.9146, -7.4944,\n",
      "         9.4927, -8.9232,  1.0291, -4.5134, -9.5585, -3.1518,  9.4105, -9.8624,\n",
      "        -8.0291,  5.2186,  9.0948, -3.6379, -8.7278,  6.4134,  4.2622, -9.9338,\n",
      "         4.9783,  6.0797,  1.9035,  4.9226,  9.4942, -9.0363, -5.8631, -9.7107,\n",
      "        -9.2842,  4.5834,  9.5807, -0.8218, -9.8877, -9.9159, -4.6620, -4.0431,\n",
      "        -9.0400,  8.9228, -6.7763, -9.1295, -3.3731, -5.0372,  8.4943, -2.9796,\n",
      "         1.9597,  6.4476,  2.9110, -9.7966,  8.0008, -9.8603, -3.2276,  9.6517,\n",
      "        -8.8223, -6.5305,  4.8415,  8.6540,  6.7328,  7.3429, -9.7585,  9.3476,\n",
      "        -9.2717,  4.2609,  8.7101, -9.7812,  4.4680,  9.5021, -9.9177, -9.7554,\n",
      "         0.8578, -3.4090, -9.6775, -4.5564, -6.9268, -2.4139, -9.7066,  4.7629,\n",
      "         7.6508, -7.0864,  0.8082, -7.6397,  9.3171, -5.9637,  3.6196, -9.2176,\n",
      "        -8.0953, -0.9663, -7.6595,  4.7359,  9.6429,  9.6322,  6.1747, -5.7035,\n",
      "         2.8720,  4.6436,  3.9173, -9.4727, -9.9387, -6.3968, -3.0780,  5.1618,\n",
      "         8.2170,  9.5134, -9.6483,  4.7436, -4.9025, -1.1121,  3.3530,  7.2040,\n",
      "        -8.2721,  3.9309, -9.9119,  4.3933,  4.6993,  9.3297,  6.7935,  7.2842,\n",
      "        -9.4562,  8.1388,  6.2551, -2.9669, -7.9633, -8.2070,  3.2012, -1.5454,\n",
      "        -0.4031,  7.1555, -7.1557, -7.8158,  8.8772, -9.3635,  0.4411, -9.8655,\n",
      "        -6.2969,  7.7075,  3.5159,  3.9583], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  1.0000001301979546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 33/33000.0 [02:46<55:42:04,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 1.0000000000000004e-05\n",
      "\n",
      "Inner iteration 4000\n",
      "\th(W(model)): 3.621799102848655e-06\n",
      "\tscore(model): 4.3988895294544494e-05\n",
      "\t mle: 4.035293553061711\n",
      "\t mse: 2.01765703619747\n",
      "\tW1: tensor([[1.0000e-04, 6.3236e+00],\n",
      "        [3.0012e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 3.621799102848655e-06\n",
      "\tW2: tensor([[ 1.0000e+00, -1.1574e-08],\n",
      "        [-1.1574e-08,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 1.0000e+00, -1.4288e-08],\n",
      "        [-1.4288e-08,  1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-2.0351e-11,  0.0000e+00],\n",
      "        [-7.9113e-10, -2.0251e-10]])\n",
      "Check y:  tensor([ 2.6897,  9.2890,  5.5569,  2.4613, -4.6022,  7.3860, -3.8668,  6.6527,\n",
      "         3.7786, -6.5121,  9.4895,  1.5144,  3.7745,  5.2900, -5.1499, -5.8403,\n",
      "        -3.0913,  8.6728,  9.6213,  7.4768,  3.2234,  9.3866, -2.5301,  9.6036,\n",
      "        -7.1432,  7.1601, -8.0944,  4.5203,  1.0903, -5.0576, -9.8489,  9.6458,\n",
      "        -2.8357,  3.7958, -3.0386,  6.2387,  5.9908,  6.2077,  4.5571,  8.5462,\n",
      "        -7.4856, -3.8968,  8.9415, -4.6902,  8.1027,  8.2228, -9.7626, -7.5620,\n",
      "        -8.9175, -7.3240,  3.8920, -3.8119,  2.8786, -6.4745, -9.7431, -8.6858,\n",
      "         7.6467, -9.9287, -2.2499, -9.9560, -8.6138, -6.8215,  7.7587, -7.9088,\n",
      "        -9.5500, -7.1259,  8.9648, -6.2657,  8.5249, -6.2232,  3.3016, -2.1132,\n",
      "         3.2906,  5.6555,  9.5937, -3.8229, -9.6173, -7.2201, -9.3731, -7.1614,\n",
      "        -8.8487, -5.0774, -4.8562,  8.8208,  3.6952, -9.8410,  1.1748, -6.1314,\n",
      "         4.2018,  5.1397, -8.8327,  8.1229, -7.6715,  9.3080, -9.5040, -9.2736,\n",
      "         4.7541, -3.0872,  8.7699, -2.5404,  8.4345, -9.7927,  9.5570,  3.8349,\n",
      "        -9.9466,  4.2131,  5.0338,  4.0035, -9.8904,  4.2007, -3.3438,  8.2729,\n",
      "         8.9827, -9.3461,  9.1228, -5.9280,  7.0651,  4.4831,  7.0411,  8.8222,\n",
      "         9.4416, -0.1553,  4.0705,  7.3150, -4.5919,  5.7281, -3.0534, -9.2565,\n",
      "         7.8887, -9.4916,  6.2554, -4.3364, -7.8092, -9.3282,  3.8794,  4.9752,\n",
      "         4.1151,  7.6499,  7.6112, -4.1968,  6.4642, -7.1723, -3.9596,  6.6468,\n",
      "         9.2698,  9.0767, -6.3980,  5.5388,  9.2728,  2.5260, -8.3049,  7.5448,\n",
      "        -8.7215,  6.1466, -7.3636,  8.2231,  9.2493,  3.8323, -5.4242, -5.0700,\n",
      "         8.9369, -2.9837,  9.3969,  7.6070,  3.3358,  7.9712, -2.7836, -7.4677,\n",
      "         9.5010, -8.9828,  1.0413, -4.4430, -9.6096, -3.0288,  9.4643, -9.8965,\n",
      "        -7.9994,  5.1890,  9.0875, -3.5327, -8.7869,  6.4063,  4.2700, -9.9558,\n",
      "         4.9404,  6.0753,  1.9165,  4.9267,  9.5026, -9.0082, -5.8487, -9.7557,\n",
      "        -9.3414,  4.5322,  9.5961, -0.8138, -9.9189, -9.9232, -4.5977, -4.0372,\n",
      "        -9.0120,  8.9121, -6.7550, -9.1884, -3.2580, -4.9882,  8.4790, -2.9750,\n",
      "         1.9727,  6.4593,  2.8110, -9.8364,  7.9844, -9.8600, -3.1073,  9.6819,\n",
      "        -8.7926, -6.5111,  4.8461,  8.7148,  6.7231,  7.3807, -9.7502,  9.4033,\n",
      "        -9.3290,  4.1991,  8.6965, -9.8221,  4.4129,  9.5110, -9.9254, -9.7979,\n",
      "         0.8697, -3.2952, -9.7240, -4.5490, -6.9043, -2.4089, -9.6954,  4.7680,\n",
      "         7.6961, -7.1133,  0.8199, -7.6817,  9.3167, -5.9486,  3.6301, -9.2756,\n",
      "        -8.1469, -0.9587, -7.6318,  4.6898,  9.6784,  9.6548,  6.1776, -5.6813,\n",
      "         2.8844,  4.6494,  3.8446, -9.4525, -9.9580, -6.4008, -2.9525,  5.1302,\n",
      "         8.2007,  9.5625, -9.6343,  4.7488, -4.8481, -1.1048,  3.2640,  7.2382,\n",
      "        -8.2417,  3.8586, -9.9394,  4.3358,  4.6519,  9.3859,  6.7834,  7.3205,\n",
      "        -9.4356,  8.1937,  6.2493, -2.8376, -7.9339, -8.2605,  3.1082, -1.5390,\n",
      "        -0.3941,  7.1428, -7.1315, -7.8618,  8.9385, -9.4194,  0.4522, -9.8993,\n",
      "        -6.2972,  7.7541,  3.4314,  3.8868], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  1.000000048046034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 34/33000.0 [02:53<57:30:31,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 1.0000000000000004e-05\n",
      "\n",
      "Inner iteration 4999\n",
      "\th(W(model)): 7.411139753443763e-06\n",
      "\tscore(model): 4.765870392524156e-05\n",
      "\t mle: 4.0234143139708545\n",
      "\t mse: 2.011717432209268\n",
      "\tW1: tensor([[1.0000e-04, 6.3777e+00],\n",
      "        [4.2628e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 7.411139753443763e-06\n",
      "\tW2: tensor([[1.0000e+00, 7.1050e-09],\n",
      "        [7.1050e-09, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0000e+00, 8.2602e-09],\n",
      "        [8.2602e-09, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-8.0235e-10,  0.0000e+00],\n",
      "        [ 3.2662e-10,  1.0073e-10]])\n",
      "Check y:  tensor([ 2.7034,  9.2916,  5.5829,  2.4725, -4.6717,  7.3987, -3.9354,  6.6737,\n",
      "         3.7269, -6.5646,  9.5280,  1.5135,  3.7975,  5.2774, -5.1263, -5.8379,\n",
      "        -2.9978,  8.7216,  9.6529,  7.5140,  3.1587,  9.4284, -2.5889,  9.6364,\n",
      "        -7.1722,  7.1751, -8.1358,  4.4874,  1.0833, -5.1256, -9.8388,  9.6752,\n",
      "        -2.8975,  3.8190, -2.9434,  6.2613,  6.0150,  6.2306,  4.5251,  8.5481,\n",
      "        -7.5187, -3.9654,  8.9421, -4.6514,  8.1081,  8.2271, -9.7821, -7.5978,\n",
      "        -8.9161, -7.3607,  3.9157, -3.8803,  2.8068, -6.4891, -9.7636, -8.7281,\n",
      "         7.6566, -9.9224, -2.3056, -9.9540, -8.6563, -6.8441,  7.7675, -7.9487,\n",
      "        -9.5785, -7.1669,  9.0129, -6.2750,  8.5734, -6.2313,  3.2387, -2.1672,\n",
      "         3.2275,  5.6811,  9.6046, -3.7543, -9.6052, -7.2505, -9.3632, -7.1907,\n",
      "        -8.8488, -5.1454, -4.8230,  8.8215,  3.7177, -9.8307,  1.1691, -6.1371,\n",
      "         4.2270,  5.1231, -8.8332,  8.1281, -7.7087,  9.3109, -9.4926, -9.3093,\n",
      "         4.7808, -2.9936,  8.8188, -2.4296,  8.4371, -9.7814,  9.5660,  3.7845,\n",
      "        -9.9424,  4.2383,  5.0606,  4.0278, -9.9014,  4.1595, -3.4096,  8.3200,\n",
      "         8.9834, -9.3366,  9.1695, -5.9888,  7.0947,  4.5092,  7.0702,  8.8230,\n",
      "         9.4469, -0.1814,  4.0260,  7.3284, -4.6614,  5.7535, -2.9588, -9.2484,\n",
      "         7.8962, -9.4804,  6.2780, -4.4059, -7.8480, -9.3190,  3.9030,  5.0020,\n",
      "         4.1400,  7.6598,  7.6215, -4.2662,  6.4810, -7.2124, -4.0285,  6.6677,\n",
      "         9.3142,  9.0777, -6.4106,  5.5327,  9.2752,  2.4479, -8.3473,  7.5830,\n",
      "        -8.7637,  6.1699, -7.3964,  8.2698,  9.2941,  3.8556, -5.4900, -5.0438,\n",
      "         8.9376, -3.0468,  9.4013,  7.6462,  3.2737,  8.0153, -2.6802, -7.5013,\n",
      "         9.5080, -9.0230,  1.0336, -4.3958, -9.6360, -2.9333,  9.5037, -9.9069,\n",
      "        -8.0202,  5.1737,  9.0886, -3.4541, -8.8287,  6.4278,  4.2955, -9.9574,\n",
      "         4.9185,  6.0990,  1.9211,  4.9536,  9.5096, -9.0049, -5.9104, -9.7756,\n",
      "        -9.3756,  4.4995,  9.6071, -0.8499, -9.9270, -9.9165, -4.5557, -4.1063,\n",
      "        -9.0086,  8.9128, -6.8033, -9.2256, -3.1701, -4.9593,  8.4814, -3.0380,\n",
      "         1.9779,  6.4759,  2.7380, -9.8515,  7.9909, -9.8502, -3.0144,  9.7024,\n",
      "        -8.7940, -6.5636,  4.8729,  8.7637,  6.7421,  7.4162, -9.7385,  9.4447,\n",
      "        -9.3635,  4.1578,  8.6976, -9.8382,  4.3772,  9.5183, -9.9189, -9.8155,\n",
      "         0.8594, -3.2086, -9.7455, -4.6185, -6.9498, -2.4664, -9.6833,  4.7947,\n",
      "         7.7367, -7.1418,  0.8089, -7.7191,  9.3197, -6.0091,  3.6521, -9.3113,\n",
      "        -8.1885, -0.9970, -7.6615,  4.6613,  9.7028,  9.6701,  6.1875, -5.6742,\n",
      "         2.9002,  4.6760,  3.7944, -9.4417, -9.9579, -6.4135, -2.8545,  5.1134,\n",
      "         8.2052,  9.5977, -9.6222,  4.7755, -4.8146, -1.1453,  3.2003,  7.2711,\n",
      "        -8.2565,  3.8088, -9.9448,  4.2980,  4.6224,  9.4277,  6.8019,  7.3549,\n",
      "        -9.4250,  8.2401,  6.2719, -2.7360, -7.9563, -8.3027,  3.0412, -1.5857,\n",
      "        -0.4239,  7.1579, -7.1724, -7.9012,  8.9868, -9.4517,  0.4355, -9.9094,\n",
      "        -6.3073,  7.7955,  3.3714,  3.8377], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.999999980341377\n",
      "\n",
      "Dagma iter t=6 -- mu: 1.0000000000000004e-06 ------------------------------\n",
      "success:  False\n",
      "\n",
      "Minimize s=1.0 -- lr=0.001875\n",
      "\n",
      "mu 1.0000000000000004e-06\n",
      "\n",
      "Inner iteration 0\n",
      "\th(W(model)): 6.217842316580402e-06\n",
      "\tscore(model): 1.024265217229614e-05\n",
      "\t mle: 4.124686215142499\n",
      "\t mse: 2.0583510558907285\n",
      "\tW1: tensor([[1.0000e-04, 6.3775e+00],\n",
      "        [3.9036e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 6.217842316580402e-06\n",
      "\tW2: tensor([[1.0000e+00, 8.2602e-09],\n",
      "        [8.2602e-09, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[ 0.9963, -0.0014],\n",
      "        [-0.0014,  1.0033]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[ 3.6492e-05,  0.0000e+00],\n",
      "        [ 2.9821e-08, -7.0366e-08]])\n",
      "Check y:  tensor([ 2.6493,  8.9737,  5.4166,  2.4265, -4.4927,  7.1528, -3.7790,  6.5795,\n",
      "         3.7605, -6.3265,  9.2476,  1.5004,  3.7031,  5.2499, -5.1262, -5.8110,\n",
      "        -3.0600,  8.5068,  9.3568,  7.3742,  3.2107,  9.1580, -2.4736,  9.3428,\n",
      "        -7.0873,  6.9391, -8.0011,  4.4930,  1.0844, -4.9325, -9.5344,  9.3753,\n",
      "        -2.7728,  3.7237, -3.0069,  6.0658,  5.8301,  6.0364,  4.5292,  8.2538,\n",
      "        -7.2515, -3.8082,  8.6338, -4.6675,  7.8315,  7.9456, -9.5290, -7.4919,\n",
      "        -8.6133, -7.0982,  3.8168, -3.7256,  2.8687, -6.4353, -9.5126, -8.5583,\n",
      "         7.3994, -9.6243, -2.1989, -9.6624, -8.4911, -6.7745,  7.5055, -7.8243,\n",
      "        -9.3461, -6.9102,  8.7771, -6.2303,  8.3687, -6.1885,  3.2882, -2.0647,\n",
      "         3.2773,  5.5106,  9.2846, -3.7976, -9.2959, -7.1618, -9.0542, -7.1049,\n",
      "        -8.5473, -4.9517, -4.8334,  8.5172,  3.6263, -9.5260,  1.1673, -6.0982,\n",
      "         4.1160,  5.1024, -8.5319,  7.8507, -7.5971,  8.9926, -9.1830, -9.0992,\n",
      "         4.6478, -3.0559,  8.5971, -2.5033,  8.1471, -9.4749,  9.2455,  3.8162,\n",
      "        -9.6475,  4.1269,  4.9162,  3.9245, -9.6316,  4.1776, -3.2694,  8.1318,\n",
      "         8.6738, -9.0278,  8.9215, -5.7687,  6.9783,  4.3871,  6.9551,  8.5186,\n",
      "         9.1266, -0.1398,  4.0490,  7.0857, -4.4827,  5.5799, -3.0218, -8.9405,\n",
      "         7.6287, -9.1708,  6.0817, -4.2352, -7.7291, -9.0104,  3.8046,  4.8600,\n",
      "         4.0323,  7.4025,  7.3658, -4.0997,  6.3966, -6.9543, -3.8693,  6.5738,\n",
      "         9.0542,  8.7652, -6.3602,  5.4938,  8.9577,  2.5188, -8.2006,  7.4393,\n",
      "        -8.5916,  5.9783, -7.3006,  8.0848,  9.0359,  3.7590, -5.2855, -5.0466,\n",
      "         8.6294, -2.9176,  9.0815,  7.4989,  3.3221,  7.8461, -2.7491, -7.2346,\n",
      "         9.1874, -8.8337,  1.0363, -4.4202, -9.3982, -2.9969,  9.2259, -9.6362,\n",
      "        -7.7387,  5.1508,  8.7757, -3.5054, -8.6525,  6.2249,  4.1818, -9.6716,\n",
      "         4.9065,  5.9105,  1.8942,  4.8135,  9.1889, -8.7004, -5.6928, -9.5232,\n",
      "        -9.1604,  4.5046,  9.2872, -0.7876, -9.6522, -9.6177, -4.5750, -3.9448,\n",
      "        -8.7041,  8.6054, -6.5578, -9.0219, -3.2283, -4.9651,  8.1896, -2.9091,\n",
      "         1.9491,  6.3918,  2.8016, -9.5895,  7.7193, -9.5464, -3.0762,  9.3901,\n",
      "        -8.4936, -6.3256,  4.7361,  8.5459,  6.5254,  7.2820, -9.4308,  9.1728,\n",
      "        -9.1493,  4.1760,  8.3977, -9.5780,  4.3870,  9.1977, -9.6203, -9.5583,\n",
      "         0.8678, -3.2659, -9.4965, -4.4412, -6.6998, -2.3548, -9.3748,  4.6611,\n",
      "         7.5841, -7.0583,  0.8189, -7.6069,  9.0013, -5.7884,  3.5632, -9.1011,\n",
      "        -8.0510, -0.9302, -7.3901,  4.6600,  9.3953,  9.3529,  6.1177, -5.6538,\n",
      "         2.8389,  4.5472,  3.8257, -9.1322, -9.6695, -6.3629, -2.9199,  5.0931,\n",
      "         7.9246,  9.3093, -9.3130,  4.6427, -4.8253, -1.0739,  3.2509,  7.1450,\n",
      "        -7.9687,  3.8396, -9.6653,  4.3109,  4.6226,  9.1574,  6.5825,  7.2241,\n",
      "        -9.1156,  8.0570,  6.0759, -2.8038, -7.6766, -8.1587,  3.0965, -1.5008,\n",
      "        -0.3747,  6.9227, -6.9156, -7.7795,  8.7529, -9.2303,  0.4576, -9.6382,\n",
      "        -6.2613,  7.6394,  3.4168,  3.8675], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9999999804439957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 36/33000.0 [03:00<47:49:40,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 1.0000000000000004e-06\n",
      "\n",
      "Inner iteration 1000\n",
      "\th(W(model)): 1.6984532264171497e-07\n",
      "\tscore(model): 5.3607999896998767e-05\n",
      "\t mle: 53.43347806372588\n",
      "\t mse: 26.717088165947356\n",
      "\tW1: tensor([[1.0000e-04, 1.2966e-01],\n",
      "        [2.9855e-03, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 1.6984532264171497e-07\n",
      "\tW2: tensor([[9.9999e-01, 2.8735e-06],\n",
      "        [2.8735e-06, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0000e+00, 5.1726e-06],\n",
      "        [5.1726e-06, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-3.5532e-05,  0.0000e+00],\n",
      "        [-8.3806e-06, -3.5975e-05]])\n",
      "Check y:  tensor([-0.1852, -0.2035, -0.2276, -0.1837, -0.2042, -0.2593, -0.2004, -0.1371,\n",
      "        -0.1451, -0.2227, -0.0931, -0.1805, -0.1961, -0.1486, -0.4061, -0.4054,\n",
      "        -0.3956, -0.0946, -0.1037, -0.1219, -0.1421, -0.0897, -0.1940, -0.1014,\n",
      "        -0.4048, -0.2572, -0.4075, -0.1483, -0.1803, -0.2071, -0.3772, -0.1078,\n",
      "        -0.1955, -0.1964, -0.3948, -0.2417, -0.2367, -0.2411, -0.1484, -0.2487,\n",
      "        -0.2437, -0.2005, -0.2307, -0.4060, -0.2584, -0.2566, -0.4140, -0.4056,\n",
      "        -0.3035, -0.2394, -0.1977, -0.2001, -0.1404, -0.4047, -0.4143, -0.4108,\n",
      "        -0.2606, -0.3894, -0.1927, -0.3973, -0.4103, -0.4046, -0.2606, -0.4067,\n",
      "        -0.4153, -0.2345, -0.0896, -0.4049, -0.0977, -0.4049, -0.1425, -0.1920,\n",
      "        -0.1424, -0.2297, -0.1605, -0.4031, -0.3533, -0.4049, -0.3335, -0.4049,\n",
      "        -0.2995, -0.2072, -0.4061, -0.2373, -0.1950, -0.3762, -0.1803, -0.4050,\n",
      "        -0.2023, -0.1489, -0.2986, -0.2581, -0.4059, -0.2015, -0.3437, -0.4145,\n",
      "        -0.2117, -0.3956, -0.0927, -0.3851, -0.2520, -0.3706, -0.1678, -0.1454,\n",
      "        -0.3936, -0.2024, -0.2170, -0.1993, -0.4102, -0.1472, -0.1979, -0.1034,\n",
      "        -0.2281, -0.3315, -0.0882, -0.2148, -0.1302, -0.2069, -0.1307, -0.2373,\n",
      "        -0.1858, -0.1830, -0.1466, -0.2588, -0.2041, -0.2312, -0.3951, -0.3251,\n",
      "        -0.2602, -0.3427, -0.2421, -0.2027, -0.4063, -0.3302, -0.1975, -0.2159,\n",
      "        -0.2009, -0.2606, -0.2605, -0.2020, -0.1397, -0.2356, -0.2008, -0.1372,\n",
      "        -0.0882, -0.2217, -0.4048, -0.1478, -0.2051, -0.1391, -0.4085, -0.1204,\n",
      "        -0.4110, -0.2399, -0.4052, -0.1046, -0.0881, -0.1969, -0.2099, -0.4061,\n",
      "        -0.2310, -0.1962, -0.1915, -0.1191, -0.1427, -0.1106, -0.3904, -0.2432,\n",
      "        -0.1772, -0.4127, -0.1803, -0.4056, -0.4152, -0.3947, -0.0920, -0.4099,\n",
      "        -0.2604, -0.1488, -0.2209, -0.4009, -0.4115, -0.2450, -0.2033, -0.4022,\n",
      "        -0.1490, -0.2384, -0.1813, -0.2149, -0.1770, -0.3089, -0.2139, -0.4141,\n",
      "        -0.4148, -0.1484, -0.1600, -0.1858, -0.4083, -0.3883, -0.4059, -0.2012,\n",
      "        -0.3091, -0.2324, -0.2269, -0.4140, -0.3979, -0.4061, -0.2507, -0.1961,\n",
      "        -0.1815, -0.1398, -0.1401, -0.4124, -0.2596, -0.3787, -0.3959, -0.1287,\n",
      "        -0.2964, -0.2227, -0.2134, -0.0937, -0.2508, -0.1240, -0.3660, -0.0901,\n",
      "        -0.4147, -0.1472, -0.2431, -0.4128, -0.1480, -0.1757, -0.3888, -0.4134,\n",
      "        -0.1805, -0.3984, -0.4145, -0.2039, -0.2297, -0.1934, -0.3605, -0.2119,\n",
      "        -0.1171, -0.4048, -0.1805, -0.4059, -0.2006, -0.2150, -0.1942, -0.4145,\n",
      "        -0.4077, -0.1864, -0.2480, -0.1487, -0.1187, -0.1442, -0.1431, -0.4056,\n",
      "        -0.1866, -0.2098, -0.1455, -0.3396, -0.4001, -0.4048, -0.3934, -0.1489,\n",
      "        -0.2570, -0.0975, -0.3548, -0.2116, -0.4061, -0.1871, -0.1423, -0.1269,\n",
      "        -0.2699, -0.1456, -0.4061, -0.1477, -0.1487, -0.0897, -0.2518, -0.1252,\n",
      "        -0.3382, -0.1053, -0.2420, -0.3914, -0.2580, -0.4083, -0.1415, -0.1892,\n",
      "        -0.1840, -0.2570, -0.2347, -0.4065, -0.0900, -0.4151, -0.1812, -0.4097,\n",
      "        -0.4049, -0.1157, -0.1432, -0.1457], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9999917853001663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 37/33000.0 [03:08<53:17:13,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 1.0000000000000004e-06\n",
      "\n",
      "Inner iteration 2000\n",
      "\th(W(model)): 2.9101028486244193e-08\n",
      "\tscore(model): 4.7695083368457737e-05\n",
      "\t mle: 47.6580590623519\n",
      "\t mse: 23.829550396835206\n",
      "\tW1: tensor([[1.0000e-04, 4.0949e-01],\n",
      "        [2.3297e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 2.9101028486244193e-08\n",
      "\tW2: tensor([[1.0000e+00, 4.6268e-06],\n",
      "        [4.6268e-06, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0000e+00, 4.6491e-06],\n",
      "        [4.6491e-06, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-1.6531e-07,  0.0000e+00],\n",
      "        [-1.3668e-07,  3.1236e-07]])\n",
      "Check y:  tensor([ 0.1368,  0.3847,  0.2490,  0.1249, -0.3619,  0.2937, -0.3053,  0.2621,\n",
      "         0.1044, -0.5203,  0.4479,  0.0712,  0.1877,  0.1835, -0.7225, -0.7622,\n",
      "        -0.5859,  0.3988,  0.4500,  0.3156,  0.0749,  0.4436, -0.2053,  0.4502,\n",
      "        -0.8347,  0.2880, -0.8876,  0.1429,  0.0453, -0.3978, -0.9228,  0.4493,\n",
      "        -0.2279,  0.1886, -0.5818,  0.2663,  0.2603,  0.2656,  0.1448,  0.3347,\n",
      "        -0.6133, -0.3075,  0.3575, -0.6949,  0.3158,  0.3204, -0.9708, -0.8579,\n",
      "        -0.7780, -0.5970,  0.1926, -0.3011,  0.0557, -0.7976, -0.9704, -0.9204,\n",
      "         0.3009, -0.9428, -0.1848, -0.9550, -0.9165, -0.8169,  0.3042, -0.8772,\n",
      "        -0.9641, -0.5775,  0.4187, -0.7860,  0.3885, -0.7836,  0.0791, -0.1748,\n",
      "         0.0785,  0.2517,  0.4200, -0.6391, -0.8799, -0.8389, -0.8416, -0.8357,\n",
      "        -0.7691, -0.3994, -0.7050,  0.3498,  0.1844, -0.9211,  0.0505, -0.7785,\n",
      "         0.2050,  0.1754, -0.7670,  0.3165, -0.8640,  0.3865, -0.8616, -0.9516,\n",
      "         0.2248, -0.5856,  0.4055, -0.5404,  0.3294, -0.9113,  0.4146,  0.1074,\n",
      "        -0.9495,  0.2054,  0.2338,  0.1972, -0.9705,  0.1264, -0.2658,  0.3708,\n",
      "         0.3603, -0.8376,  0.4288, -0.4693,  0.2883,  0.2154,  0.2868,  0.3499,\n",
      "         0.4002, -0.0361,  0.1196,  0.2919, -0.3610,  0.2536, -0.5829, -0.8246,\n",
      "         0.3083, -0.8597,  0.2667, -0.3412, -0.8717, -0.8350,  0.1921,  0.2320,\n",
      "         0.2016,  0.3010,  0.2998, -0.3305,  0.2506, -0.5820, -0.3123,  0.2618,\n",
      "         0.4375,  0.3671, -0.7934,  0.1971,  0.3832,  0.0351, -0.8993,  0.3202,\n",
      "        -0.9224,  0.2641, -0.8469,  0.3673,  0.4363,  0.1902, -0.4274, -0.7178,\n",
      "         0.3572, -0.2389,  0.3953,  0.3244,  0.0810,  0.3496, -0.5611, -0.6114,\n",
      "         0.4072, -0.9365,  0.0422, -0.6796, -0.9664, -0.5810,  0.4470, -0.9702,\n",
      "        -0.6677,  0.1780,  0.3679, -0.6188, -0.9260,  0.2702,  0.2076, -0.9617,\n",
      "         0.1648,  0.2624,  0.0948,  0.2304,  0.4074, -0.7901, -0.4626, -0.9706,\n",
      "        -0.9548,  0.1435,  0.4204, -0.0817, -0.9689, -0.9412, -0.6892, -0.3182,\n",
      "        -0.7906,  0.3556, -0.5424, -0.9473, -0.5986, -0.7129,  0.3315, -0.2383,\n",
      "         0.0980,  0.2503,  0.0518, -0.9714,  0.3115, -0.9252, -0.5871,  0.4406,\n",
      "        -0.7618, -0.5202,  0.2278,  0.4018,  0.2776,  0.3091, -0.9032,  0.4444,\n",
      "        -0.9543,  0.1263,  0.3426, -0.9714,  0.1373,  0.4085, -0.9418, -0.9713,\n",
      "         0.0314, -0.6014, -0.9699, -0.3577, -0.5564, -0.1964, -0.8933,  0.2253,\n",
      "         0.3305, -0.8330,  0.0282, -0.8646,  0.3873, -0.4711,  0.1816, -0.9517,\n",
      "        -0.8905, -0.0918, -0.6283,  0.1517,  0.4455,  0.4313,  0.2334, -0.7531,\n",
      "         0.1467,  0.2212,  0.1079, -0.8536, -0.9589, -0.7935, -0.5749,  0.1749,\n",
      "         0.3195,  0.4499, -0.8828,  0.2246, -0.7045, -0.1022,  0.0771,  0.2996,\n",
      "        -0.6951,  0.1086, -0.9665,  0.1333,  0.1497,  0.4436,  0.2790,  0.3051,\n",
      "        -0.8510,  0.3652,  0.2666, -0.5656, -0.6605, -0.8968,  0.0685, -0.1332,\n",
      "        -0.0525,  0.2875, -0.5781, -0.8746,  0.4169, -0.9585,  0.0045, -0.9701,\n",
      "        -0.7878,  0.3345,  0.0861,  0.1101], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.999999993988105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 38/33000.0 [03:16<57:52:04,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 1.0000000000000004e-06\n",
      "\n",
      "Inner iteration 3000\n",
      "\th(W(model)): 6.91805852291727e-08\n",
      "\tscore(model): 3.899092514830054e-05\n",
      "\t mle: 38.911132142811745\n",
      "\t mse: 19.45590588682378\n",
      "\tW1: tensor([[1.0000e-04, 1.0128e+00],\n",
      "        [2.1896e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 6.91805852291727e-08\n",
      "\tW2: tensor([[1.0000e+00, 4.1574e-06],\n",
      "        [4.1574e-06, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0000e+00, 4.1569e-06],\n",
      "        [4.1569e-06, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-3.6636e-09,  0.0000e+00],\n",
      "        [ 1.1933e-09, -3.8521e-11]])\n",
      "Check y:  tensor([ 0.6328,  1.3540,  0.9961,  0.5993, -0.6416,  1.1742, -0.4984,  0.9345,\n",
      "         0.5111, -1.0309,  1.3679,  0.4546,  0.7831,  0.7349, -1.2405, -1.3468,\n",
      "        -0.8974,  1.2409,  1.3883,  1.0576,  0.4256,  1.3519, -0.2457,  1.3855,\n",
      "        -1.5406,  1.1537, -1.6781,  0.6220,  0.3869, -0.7319, -1.8370,  1.3921,\n",
      "        -0.3027,  0.7859, -0.8879,  1.0665,  1.0416,  1.0634,  0.6274,  1.2794,\n",
      "        -1.2427, -0.5042,  1.3177, -1.1679,  1.2385,  1.2495, -1.8959, -1.6016,\n",
      "        -1.5797, -1.2067,  0.7984, -0.4878,  0.3709, -1.4421, -1.8942, -1.7614,\n",
      "         1.1976, -1.8687, -0.1939, -1.8864, -1.7514, -1.4934,  1.2076, -1.6515,\n",
      "        -1.8742, -1.1631,  1.2863, -1.4109,  1.2180, -1.4045,  0.4378, -0.1688,\n",
      "         0.4361,  1.0067,  1.3884, -1.0253, -1.7649, -1.5519, -1.6973, -1.5433,\n",
      "        -1.5625, -0.7358, -1.1943,  1.3058,  0.7726, -1.8342,  0.4006, -1.3908,\n",
      "         0.8381,  0.7129, -1.5585,  1.2404, -1.6174,  1.3560, -1.7330, -1.8404,\n",
      "         0.9055, -0.8967,  1.2560, -0.7950,  1.2689, -1.8181,  1.3841,  0.5196,\n",
      "        -1.8786,  0.8395,  0.9381,  0.8129, -1.9032,  0.5746, -0.3984,  1.1790,\n",
      "         1.3219, -1.6901,  1.3109, -0.9086,  0.9958,  0.8730,  0.9922,  1.3059,\n",
      "         1.3709,  0.1792,  0.5551,  1.1678, -0.6395,  1.0143, -0.8906, -1.6664,\n",
      "         1.2193, -1.7295,  1.0681, -0.5895, -1.6372, -1.6853,  0.7968,  0.9314,\n",
      "         0.8271,  1.1979,  1.1944, -0.5623,  0.9067, -1.1733, -0.5163,  0.9336,\n",
      "         1.3338,  1.3315, -1.4307,  0.7712,  1.3522,  0.3136, -1.7080,  1.0679,\n",
      "        -1.7663,  1.0573, -1.5728,  1.1714,  1.3306,  0.7906, -0.8056, -1.2280,\n",
      "         1.3173, -0.3304,  1.3659,  1.0773,  0.4431,  1.1327, -0.8410, -1.2387,\n",
      "         1.3777, -1.8020,  0.3790, -1.1280, -1.8808, -0.8861,  1.3640, -1.9032,\n",
      "        -1.3594,  0.7201,  1.3326, -0.9755, -1.7753,  1.0829,  0.8467, -1.8955,\n",
      "         0.6838,  1.0501,  0.5172,  0.9258,  1.3778, -1.6025, -0.8923, -1.8953,\n",
      "        -1.8490,  0.6238,  1.3887,  0.0648, -1.9027, -1.8661, -1.1530, -0.5313,\n",
      "        -1.6035,  1.3148, -1.0827, -1.8294, -0.9273, -1.2152,  1.2731, -0.3288,\n",
      "         0.5258,  0.9060,  0.3601, -1.9012,  1.2279, -1.8409, -0.9003,  1.3985,\n",
      "        -1.5486, -1.0306,  0.9164,  1.2474,  1.1133,  1.0431, -1.8046,  1.3545,\n",
      "        -1.8474,  0.5743,  1.2937, -1.9003,  0.6061,  1.3788, -1.8671, -1.8987,\n",
      "         0.3511, -0.9339, -1.8925, -0.6311, -1.1149, -0.2233, -1.7879,  0.9072,\n",
      "         1.0908, -1.5363,  0.3429, -1.6189,  1.3570, -0.9129,  0.7639, -1.8407,\n",
      "        -1.6856,  0.0393, -1.2755,  0.6470,  1.3974,  1.3956,  0.8646, -1.3226,\n",
      "         0.6608,  0.8931,  0.5211, -1.7188, -1.8918, -1.4311, -0.8722,  0.7115,\n",
      "         1.2474,  1.3792, -1.7699,  0.9049, -1.1930,  0.0134,  0.4319,  1.0217,\n",
      "        -1.4159,  0.5232, -1.9008,  0.5947,  0.6414,  1.3518,  1.1189,  1.0340,\n",
      "        -1.7142,  1.1668,  1.0675, -0.8510, -1.3443, -1.7017,  0.4075, -0.0644,\n",
      "         0.1381,  1.1522, -1.1643, -1.6448,  1.2822, -1.8587,  0.2821, -1.9032,\n",
      "        -1.4156,  1.0996,  0.4579,  0.5275], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  1.0000000206358293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 39/33000.0 [03:24<61:26:37,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 1.0000000000000004e-06\n",
      "\n",
      "Inner iteration 4000\n",
      "\th(W(model)): 1.9012639440596502e-07\n",
      "\tscore(model): 2.8158942561097485e-05\n",
      "\t mle: 27.956780960282767\n",
      "\t mse: 13.978558030140128\n",
      "\tW1: tensor([[1.0000e-04, 1.9011e+00],\n",
      "        [2.1696e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 1.9012639440596502e-07\n",
      "\tW2: tensor([[1.0000e+00, 3.4190e-06],\n",
      "        [3.4190e-06, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0000e+00, 3.4182e-06],\n",
      "        [3.4182e-06, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-2.1426e-11,  0.0000e+00],\n",
      "        [ 5.7647e-11,  3.7292e-10]])\n",
      "Check y:  tensor([ 1.2743,  2.7464,  2.0126,  1.2094, -1.1092,  2.4014, -0.8441,  1.9364,\n",
      "         1.1178, -1.8219,  2.7217,  0.9322,  1.5710,  1.5572, -1.9918, -2.1949,\n",
      "        -1.3487,  2.4895,  2.7644,  2.1620,  0.9488,  2.6909, -0.3752,  2.7582,\n",
      "        -2.5656,  2.3568, -2.8270,  1.3367,  0.8040, -1.2759, -3.1816,  2.7735,\n",
      "        -0.4809,  1.5766, -1.3313,  2.1651,  2.1107,  2.1583,  1.3473,  2.6181,\n",
      "        -2.1991, -0.8548,  2.6877, -1.8535,  2.5375,  2.5596, -3.2468, -2.6817,\n",
      "        -2.7734, -2.1358,  1.6020, -0.8245,  0.8413, -2.3773, -3.2430, -2.9847,\n",
      "         2.4518, -3.2278, -0.2791, -3.2521, -2.9658, -2.4755,  2.4731, -2.7766,\n",
      "        -3.2014, -2.0586,  2.5706, -2.3176,  2.4487, -2.3054,  0.9729, -0.2325,\n",
      "         0.9695,  2.0352,  2.7921, -1.5849, -3.0714, -2.5871, -2.9645, -2.5707,\n",
      "        -2.7451, -1.2833, -1.9037,  2.6666,  1.5500, -3.1775,  0.8297, -2.2790,\n",
      "         1.6823,  1.5146, -2.7385,  2.5412, -2.7118,  2.7496, -3.0212, -3.1352,\n",
      "         1.8212, -1.3473,  2.5163, -1.1636,  2.5980, -3.1532,  2.7874,  1.1346,\n",
      "        -3.2416,  1.6852,  1.8893,  1.6311, -3.2669,  1.2432, -0.6586,  2.3795,\n",
      "         2.6948, -2.9530,  2.6150, -1.6002,  2.0495,  1.7538,  2.0429,  2.6669,\n",
      "         2.7707,  0.4144,  1.2047,  2.3875, -1.1054,  2.0518, -1.3362, -2.9149,\n",
      "         2.4977, -3.0158,  2.1687, -1.0128, -2.7495, -2.9453,  1.5987,  1.8752,\n",
      "         1.6600,  2.4524,  2.4450, -0.9624,  1.8846, -2.0766, -0.8772,  1.9348,\n",
      "         2.6569,  2.7109, -2.3554,  1.6273,  2.7438,  0.7293, -2.8836,  2.1806,\n",
      "        -2.9941,  2.1450, -2.6269,  2.3659,  2.6510,  1.5863, -1.4116, -1.9679,\n",
      "         2.6869, -0.5324,  2.7638,  2.1976,  0.9834,  2.2970, -1.2461, -2.1920,\n",
      "         2.7796, -3.0619,  0.7890, -1.7780, -3.2148, -1.3280,  2.7140, -3.2675,\n",
      "        -2.4021,  1.5286,  2.7127, -1.4924, -3.0112,  2.2012,  1.6998, -3.2632,\n",
      "         1.4577,  2.1294,  1.0515,  1.8634,  2.7799, -2.8109, -1.5703, -3.2454,\n",
      "        -3.1519,  1.3401,  2.7924,  0.2013, -3.2689, -3.2242, -1.8253, -0.9050,\n",
      "        -2.8125,  2.6826, -1.9151, -3.1140, -1.4034, -1.9434,  2.6060, -0.5294,\n",
      "         1.0679,  1.8832,  0.8200, -3.2597,  2.5156, -3.1875, -1.3540,  2.7954,\n",
      "        -2.7221, -1.8216,  1.8438,  2.5011,  2.2679,  2.1358, -3.1327,  2.6958,\n",
      "        -3.1489,  1.2427,  2.6448, -3.2574,  1.3054,  2.7811, -3.2256, -3.2533,\n",
      "         0.7364, -1.4155, -3.2392, -1.0898, -1.9727, -0.3336, -3.1070,  1.8246,\n",
      "         2.2219, -2.5573,  0.7210, -2.7146,  2.7510, -1.6079,  1.5327, -3.1357,\n",
      "        -2.8411,  0.1538, -2.2565,  1.3857,  2.7886,  2.7976,  1.8054, -2.1485,\n",
      "         1.3290,  1.7953,  1.1375, -2.9987, -3.2590, -2.3562, -1.3027,  1.5119,\n",
      "         2.5555,  2.7446, -3.0791,  1.8199, -1.9013,  0.1057,  0.9613,  2.0968,\n",
      "        -2.4989,  1.1417, -3.2684,  1.2828,  1.3748,  2.6907,  2.2803,  2.1193,\n",
      "        -2.9914,  2.3578,  2.1674, -1.2643, -2.3760, -2.8717,  0.9131, -0.0387,\n",
      "         0.3377,  2.3533, -2.0608, -2.7638,  2.5632, -3.1707,  0.6067, -3.2677,\n",
      "        -2.3266,  2.2377,  1.0127,  1.1501], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  1.0000000342596327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 40/33000.0 [03:31<64:06:07,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 1.0000000000000004e-06\n",
      "\n",
      "Inner iteration 5000\n",
      "\th(W(model)): 4.4236755414317486e-07\n",
      "\tscore(model): 1.7344147557556182e-05\n",
      "\t mle: 16.89101454386793\n",
      "\t mse: 8.445561779404246\n",
      "\tW1: tensor([[1.0000e-04, 3.0494e+00],\n",
      "        [2.1312e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 4.4236755414317486e-07\n",
      "\tW2: tensor([[1.0000e+00, 2.4620e-06],\n",
      "        [2.4620e-06, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0000e+00, 2.4609e-06],\n",
      "        [2.4609e-06, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-9.4366e-14,  0.0000e+00],\n",
      "        [ 3.8560e-11,  2.0594e-10]])\n",
      "Check y:  tensor([ 1.9516,  4.5098,  3.1928,  1.8457, -1.8283,  3.8850, -1.4133,  3.2689,\n",
      "         1.9253, -2.9346,  4.4942,  1.3969,  2.4413,  2.6516, -2.9547, -3.2826,\n",
      "        -1.9262,  4.1401,  4.5580,  3.6289,  1.6453,  4.4477, -0.6771,  4.5488,\n",
      "        -3.8821,  3.8042, -4.3047,  2.2879,  1.1910, -2.0886, -4.9428,  4.5713,\n",
      "        -0.8432,  2.4507, -1.8987,  3.4607,  3.3646,  3.4488,  2.3055,  4.2791,\n",
      "        -3.5105, -1.4301,  4.4047, -2.7320,  4.1327,  4.1729, -4.9967, -4.0698,\n",
      "        -4.3652, -3.4145,  2.4930, -1.3826,  1.4676, -3.5774, -4.9898, -4.5604,\n",
      "         3.9766, -5.0030, -0.5258, -5.0322, -4.5297, -3.7363,  4.0155, -4.2233,\n",
      "        -4.9173, -3.2970,  4.2646, -3.4810,  4.0772, -3.4613,  1.6852, -0.4524,\n",
      "         1.6796,  3.2322,  4.5920, -2.3015, -4.7916, -3.9167, -4.6407, -3.8903,\n",
      "        -4.3239, -2.1000, -2.8129,  4.3669,  2.4063, -4.9373,  1.2322, -3.4186,\n",
      "         2.6278,  2.5815, -4.3143,  4.1395, -4.1184,  4.5153, -4.7211, -4.8067,\n",
      "         2.8631, -1.9240,  4.1814, -1.6350,  4.2428, -4.9045,  4.5834,  1.9532,\n",
      "        -5.0199,  2.6327,  2.9797,  2.5417, -5.0372,  2.1331, -1.1224,  3.9700,\n",
      "         4.4175, -4.6242,  4.3324, -2.5925,  3.4501,  2.7485,  3.4396,  4.3674,\n",
      "         4.5532,  0.5700,  2.0694,  3.8597, -1.8224,  3.2611, -1.9064, -4.5697,\n",
      "         4.0602, -4.7134,  3.4671, -1.6775, -4.1794, -4.6134,  2.4875,  2.9554,\n",
      "         2.5903,  3.9778,  3.9643, -1.5987,  3.1853, -3.3246, -1.4653,  3.2663,\n",
      "         4.3961,  4.4464, -3.5421,  2.7667,  4.5051,  1.2828, -4.3964,  3.6582,\n",
      "        -4.5757,  3.4252, -3.9812,  3.9488,  4.3872,  2.4668, -2.2998, -2.9163,\n",
      "         4.4033, -0.9242,  4.5408,  3.6850,  1.7026,  3.8413, -1.7645, -3.4999,\n",
      "         4.5692, -4.6862,  1.1670, -2.6108, -4.9403, -1.8936,  4.4826, -5.0387,\n",
      "        -3.8163,  2.6046,  4.4496, -2.1541, -4.6035,  3.5248,  2.6572, -5.0436,\n",
      "         2.4879,  3.3976,  1.5893,  2.9352,  4.5696, -4.4198, -2.5462, -4.9943,\n",
      "        -4.8343,  2.2936,  4.5925,  0.2323, -5.0436, -4.9984, -2.6868, -1.5089,\n",
      "        -4.4221,  4.3956, -3.0778, -4.7717, -2.0128, -2.8768,  4.2573, -0.9194,\n",
      "         1.6160,  3.1831,  1.4324, -5.0215,  4.0928, -4.9506, -1.9345,  4.6023,\n",
      "        -4.2903, -2.9341,  2.9016,  4.1579,  3.6440,  3.5873, -4.8765,  4.4551,\n",
      "        -4.8293,  2.1323,  4.3275, -5.0169,  2.2361,  4.5718, -5.0002, -5.0089,\n",
      "         1.0827, -2.0321, -4.9830, -1.7981, -3.1660, -0.6115, -4.8411,  2.8689,\n",
      "         3.7234, -3.8686,  1.0582, -4.1229,  4.5179, -2.6044,  2.3775, -4.8075,\n",
      "        -4.3277,  0.1571, -3.5974,  2.3690,  4.5932,  4.6034,  3.0572, -3.2077,\n",
      "         2.0412,  2.8190,  1.9580, -4.6894, -5.0396, -3.5434, -1.8536,  2.5771,\n",
      "         4.1655,  4.5285, -4.8023,  2.8609, -2.8089,  0.0810,  1.6660,  3.5255,\n",
      "        -3.9608,  1.9649, -5.0463,  2.1988,  2.3509,  4.4474,  3.6664,  3.5612,\n",
      "        -4.6790,  3.9362,  3.4648, -1.7931, -3.7772, -4.3772,  1.5863, -0.1469,\n",
      "         0.4482,  3.7979, -3.3004, -4.2026,  4.2533, -4.8657,  0.8758, -5.0394,\n",
      "        -3.4956,  3.7483,  1.7511,  1.9789], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  1.0000000628125316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 41/33000.0 [03:39<65:57:48,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 1.0000000000000004e-06\n",
      "\n",
      "Inner iteration 6000\n",
      "\th(W(model)): 7.687474923301352e-07\n",
      "\tscore(model): 9.512657715746095e-06\n",
      "\t mle: 8.737111259286134\n",
      "\t mse: 4.368566218530666\n",
      "\tW1: tensor([[1.0000e-04, 4.3066e+00],\n",
      "        [2.0093e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 7.687474923301352e-07\n",
      "\tW2: tensor([[1.0000e+00, 1.4181e-06],\n",
      "        [1.4181e-06, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0000e+00, 1.4171e-06],\n",
      "        [1.4171e-06, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[6.2593e-15, 0.0000e+00],\n",
      "        [2.2006e-11, 6.9060e-11]])\n",
      "Check y:  tensor([ 2.4784,  6.3853,  4.2986,  2.3268, -2.7807,  5.3668, -2.2130,  4.7602,\n",
      "         2.8268, -4.2816,  6.4521,  1.6889,  3.1858,  3.8756, -3.9884, -4.4513,\n",
      "        -2.5441,  5.9803,  6.5301,  5.2699,  2.4225,  6.3925, -1.2010,  6.5193,\n",
      "        -5.3000,  5.2393, -5.9004,  3.3508,  1.3983, -3.1356, -6.8952,  6.5452,\n",
      "        -1.4299,  3.1995, -2.5058,  4.7062,  4.5593,  4.6879,  3.3763,  6.0001,\n",
      "        -5.0521, -2.2360,  6.2073, -3.6745,  5.7622,  5.8271, -6.9068, -5.5663,\n",
      "        -6.1729, -4.9243,  3.2611, -2.1709,  2.1663, -4.8684, -6.8959, -6.2656,\n",
      "         5.5121, -6.9633, -0.9924, -6.9925, -6.2215, -5.0934,  5.5741, -5.7845,\n",
      "        -6.7850, -4.7676,  6.1495, -4.7319,  5.8940, -4.7040,  2.4801, -0.8910,\n",
      "         2.4721,  4.3582,  6.5355, -3.0693, -6.7127, -5.3491, -6.5242, -5.3116,\n",
      "        -6.1196, -3.1512, -3.7884,  6.1445,  3.1348, -6.8888,  1.4564, -4.6437,\n",
      "         3.4584,  3.7746, -6.1072,  5.7732, -5.6354,  6.3948, -6.6251, -6.6215,\n",
      "         3.8055, -2.5411,  6.0367, -2.1388,  5.9407, -6.8500,  6.5180,  2.8672,\n",
      "        -6.9809,  3.4655,  3.9788,  3.3323, -6.9752,  3.1273, -1.8138,  5.7462,\n",
      "         6.2287, -6.5034,  6.2406, -3.8197,  5.0174,  3.6359,  5.0026,  6.1453,\n",
      "         6.4616,  0.5278,  3.0352,  5.3268, -2.7727,  4.4020, -2.5166, -6.4344,\n",
      "         5.6456, -6.6155,  4.7160, -2.5747, -5.7220, -6.4897,  3.2530,  3.9426,\n",
      "         3.4034,  5.5140,  5.4924, -2.4668,  4.6410, -4.8044, -2.2842,  4.7565,\n",
      "         6.3251,  6.2771, -4.8185,  4.0413,  6.3771,  1.9002, -6.0311,  5.3111,\n",
      "        -6.2875,  4.6518, -5.4405,  5.7168,  6.3134,  3.2228, -3.4230, -3.9341,\n",
      "         6.2050, -1.5414,  6.4394,  5.3488,  2.5053,  5.5674, -2.3188, -5.0380,\n",
      "         6.4909, -6.4466,  1.3645, -3.5038, -6.8196, -2.4986,  6.4374, -6.9782,\n",
      "        -5.4569,  3.8078,  6.2827, -2.8627, -6.3274,  4.8047,  3.5016, -7.0004,\n",
      "         3.6396,  4.6095,  1.9616,  3.9127,  6.4916, -6.2430, -3.7571, -6.9030,\n",
      "        -6.6619,  3.3590,  6.5366,  0.0575, -6.9887, -6.9583, -3.6107, -2.3439,\n",
      "        -6.2459,  6.1921, -4.4739, -6.5705, -2.6650, -3.8785,  5.9644, -1.5348,\n",
      "         1.9995,  4.6379,  2.1156, -6.9472,  5.6979, -6.9044, -2.5558,  6.5726,\n",
      "        -6.0761, -4.2808,  3.8627,  6.0047,  4.9891,  5.2113, -6.8164,  6.4021,\n",
      "        -6.6546,  3.1261,  6.0794, -6.9396,  3.2760,  6.4957, -6.9603, -6.9264,\n",
      "         1.2459, -2.6920, -6.8852, -2.7394, -4.5922, -1.1106, -6.7734,  3.8141,\n",
      "         5.4025, -5.2809,  1.2114, -5.6418,  6.3992, -3.8360,  3.0929, -6.6227,\n",
      "        -5.9331, -0.0469, -5.1674,  3.4680,  6.5672,  6.5631,  4.4579, -4.3456,\n",
      "         2.6069,  3.7402,  2.8742, -6.5854, -6.9983, -4.8203, -2.4428,  3.7682,\n",
      "         5.8152,  6.4948, -6.7259,  3.8022, -3.7828, -0.1526,  2.4525,  5.1241,\n",
      "        -5.6469,  2.8842, -6.9971,  3.2221,  3.4419,  6.3921,  5.0239,  5.1745,\n",
      "        -6.5724,  5.6994,  4.7124, -2.3586, -5.4054, -6.0036,  2.3374, -0.4686,\n",
      "         0.3580,  5.2295, -4.7720, -5.7550,  6.1343, -6.7082,  0.9554, -6.9796,\n",
      "        -4.7526,  5.4374,  2.5752,  2.9044], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  1.000000116527844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 42/33000.0 [03:47<67:51:27,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 1.0000000000000004e-06\n",
      "\n",
      "Inner iteration 7000\n",
      "\th(W(model)): 1.3671212499843932e-06\n",
      "\tscore(model): 6.724229604051813e-06\n",
      "\t mle: 5.354106484958918\n",
      "\t mse: 2.6770555026463403\n",
      "\tW1: tensor([[1.0000e-04, 5.1923e+00],\n",
      "        [2.2353e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 1.3671212499843932e-06\n",
      "\tW2: tensor([[1.0000e+00, 6.3006e-07],\n",
      "        [6.3006e-07, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0000e+00, 6.2936e-07],\n",
      "        [6.2936e-07, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[-3.3455e-11,  0.0000e+00],\n",
      "        [ 4.3359e-11, -1.9894e-11]])\n",
      "Check y:  tensor([ 2.6710,  7.6785,  4.9299,  2.4859, -3.6052,  6.3028, -2.9386,  5.9282,\n",
      "         3.5874, -5.3542,  7.8859,  1.7110,  3.5398,  4.8631, -4.8251, -5.3800,\n",
      "        -3.0856,  7.3639,  7.9609,  6.5346,  3.0930,  7.8237, -1.7444,  7.9514,\n",
      "        -6.3933,  6.1364, -7.1075,  4.2261,  1.3598, -4.0206, -8.3236,  7.9734,\n",
      "        -2.0152,  3.5568, -3.0392,  5.4483,  5.2607,  5.4249,  4.2571,  7.1449,\n",
      "        -6.2430, -2.9657,  7.4283, -4.4480,  6.8252,  6.9120, -8.3076, -6.7103,\n",
      "        -7.5200, -6.0962,  3.6330, -2.8891,  2.7790, -5.8786, -8.2943, -7.5413,\n",
      "         6.4938, -8.3956, -1.4973, -8.4243, -7.4889, -6.1471,  6.5755, -6.9698,\n",
      "        -8.1601, -5.9157,  7.5562, -5.7156,  7.2648, -5.6823,  3.1635, -1.3771,\n",
      "         3.1537,  5.0053,  7.9046, -3.7194, -8.1240, -6.4519, -7.9145, -6.4072,\n",
      "        -7.4599, -4.0388, -4.5849,  7.3418,  3.4769, -8.3167,  1.4299, -5.6101,\n",
      "         3.8775,  4.7408, -7.4459,  6.8399, -6.7925,  7.6923, -8.0269, -7.9646,\n",
      "         4.3098, -3.0820,  7.4284, -2.5954,  7.0645, -8.2747,  7.8763,  3.6367,\n",
      "        -8.4134,  3.8863,  4.5270,  3.7211, -8.3930,  3.9539, -2.4685,  7.0936,\n",
      "         7.4579, -7.8913,  7.6581, -4.8183,  6.2351,  4.0982,  6.2174,  7.3428,\n",
      "         7.7899,  0.3134,  3.8417,  6.2506, -3.5958,  5.0608, -3.0523, -7.8141,\n",
      "         6.6701, -8.0163,  5.4609, -3.3636, -6.8955, -7.8760,  3.6230,  4.4816,\n",
      "         3.8092,  6.4962,  6.4678, -3.2369,  5.7855, -5.9581, -3.0224,  5.9237,\n",
      "         7.7512,  7.5254, -5.8190,  5.0635,  7.6668,  2.4525, -7.2628,  6.5833,\n",
      "        -7.5673,  5.3788, -6.5607,  7.0594,  7.7384,  3.5857, -4.3562, -4.7600,\n",
      "         7.4251, -2.1469,  7.7571,  6.6278,  3.1943,  6.8849, -2.8132, -6.2268,\n",
      "         7.8341, -7.7563,  1.3190, -4.2428, -8.2018, -3.0305,  7.8708, -8.3969,\n",
      "        -6.7068,  4.7810,  7.5332, -3.4702, -7.6147,  5.5745,  3.9311, -8.4298,\n",
      "         4.5770,  5.3248,  2.0416,  4.4440,  7.8352, -7.5990, -4.7455, -8.3029,\n",
      "        -8.0128,  4.2361,  7.9065, -0.2488, -8.4108, -8.3905, -4.3714, -3.0925,\n",
      "        -7.6023,  7.4073, -5.5768, -7.9037, -3.2317, -4.6932,  7.0966, -2.1392,\n",
      "         2.0876,  5.7818,  2.7169, -8.3575,  6.7396, -8.3334, -3.0996,  7.9818,\n",
      "        -7.4108, -5.3533,  4.3814,  7.3918,  5.8119,  6.4653, -8.2381,  7.8339,\n",
      "        -8.0040,  3.9525,  7.2527, -8.3480,  4.1351,  7.8415, -8.3925, -8.3317,\n",
      "         1.1761, -3.2642, -8.2812, -3.5568, -5.7134, -1.6374, -8.1909,  4.3206,\n",
      "         6.6912, -6.3706,  1.1345, -6.8002,  7.6986, -4.8372,  3.4251, -7.9660,\n",
      "        -7.1463, -0.3734, -6.3754,  4.3687,  7.9863,  7.9543,  5.5657, -5.2534,\n",
      "         2.8282,  4.2282,  3.6452, -7.9827, -8.4290, -5.8212, -2.9632,  4.7330,\n",
      "         6.8961,  7.9284, -8.1386,  4.3057, -4.5782, -0.4993,  3.1297,  6.3618,\n",
      "        -6.9235,  3.6574, -8.4227,  4.0695,  4.3369,  7.8233,  5.8569,  6.4217,\n",
      "        -7.9682,  7.0392,  5.4563, -2.8613, -6.6479, -7.2301,  2.9888, -0.8755,\n",
      "         0.1103,  6.1236, -5.9208, -6.9348,  7.5391, -8.0681,  0.8265, -8.3986,\n",
      "        -5.7403,  6.7323,  3.2799,  3.6821], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  1.0000001850678462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 43/33000.0 [03:55<50:06:25,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mu 1.0000000000000004e-06\n",
      "\n",
      "Inner iteration 7999\n",
      "\th(W(model)): 3.455139514496608e-06\n",
      "\tscore(model): 7.997723051381018e-06\n",
      "\t mle: 4.540921511519699\n",
      "\t mse: 2.2704618140805124\n",
      "\tW1: tensor([[1.0000e-04, 5.5778e+00],\n",
      "        [3.3228e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "\tcycle loss: 3.455139514496608e-06\n",
      "\tW2: tensor([[1.0000e+00, 6.6972e-06],\n",
      "        [6.6972e-06, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "\tstructure loss: 0.0\n",
      "\tSigma: tensor([[1.0000e+00, 5.7337e-07],\n",
      "        [5.7337e-07, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "Check M:  tensor([[5.6999e-10, 0.0000e+00],\n",
      "        [2.5811e-05, 3.7596e-06]])\n",
      "Check y:  tensor([ 2.7209,  8.2649,  5.2109,  2.5180, -4.0649,  6.7354, -3.3540,  6.4736,\n",
      "         4.0024, -5.9155,  8.5161,  1.6704,  3.6756,  5.3532, -5.2889, -5.8768,\n",
      "        -3.4307,  7.9753,  8.5917,  7.1091,  3.4757,  8.4524, -2.0740,  8.5823,\n",
      "        -6.9448,  6.5503, -7.6937,  4.6800,  1.2872, -4.5065, -8.9834,  8.6037,\n",
      "        -2.3649,  3.6942, -3.3808,  5.7858,  5.5777,  5.7599,  4.7128,  7.6718,\n",
      "        -6.8459, -3.3829,  7.9868, -4.8882,  7.3164,  7.4129, -8.9510, -7.2776,\n",
      "        -8.1675, -6.6928,  3.7782, -3.3011,  3.1402, -6.4032, -8.9369, -8.1475,\n",
      "         6.9478, -9.0540, -1.8081, -9.0809, -8.0928, -6.6859,  7.0387, -7.5495,\n",
      "        -8.7954, -6.5042,  8.1754, -6.2313,  7.8720, -6.1961,  3.5510, -1.6787,\n",
      "         3.5405,  5.2945,  8.5178, -4.1107, -8.7830, -7.0063, -8.5706, -6.9594,\n",
      "        -8.1058, -4.5257, -5.0338,  7.8907,  3.6063, -8.9765,  1.3637, -6.1200,\n",
      "         4.0476,  5.2240, -8.0913,  7.3327, -7.3638,  8.2803, -8.6848, -8.5903,\n",
      "         4.5248, -3.4268,  8.0425, -2.9023,  7.5825, -8.9346,  8.4859,  4.0548,\n",
      "        -9.0709,  4.0574,  4.7649,  3.8752, -9.0424,  4.3915, -2.8510,  7.6934,\n",
      "         8.0197, -8.5470,  8.2812, -5.3509,  6.7955,  4.2912,  6.7770,  7.8918,\n",
      "         8.3892,  0.1491,  4.2724,  6.6773, -4.0549,  5.3560, -3.3949, -8.4683,\n",
      "         7.1439, -8.6740,  5.7998, -3.8075, -7.4717, -8.5314,  3.7672,  4.7147,\n",
      "         3.9723,  6.9504,  6.9189, -3.6725,  6.3239, -6.5485, -3.4435,  6.4689,\n",
      "         8.3776,  8.0947, -6.3403,  5.5644,  8.2519,  2.7903, -7.8562,  7.1601,\n",
      "        -8.1747,  5.7087, -7.1206,  7.6578,  8.3644,  3.7260, -4.8623, -5.2198,\n",
      "         7.9832, -2.5063,  8.3525,  7.2067,  3.5838,  7.4755, -3.1374, -6.8290,\n",
      "         8.4385, -8.3723,  1.2427, -4.6696, -8.8393, -3.3715,  8.5007, -9.0467,\n",
      "        -7.3282,  5.2665,  8.1034, -3.8438, -8.2243,  5.9260,  4.1068, -9.0846,\n",
      "         5.0511,  5.6487,  2.0317,  4.6731,  8.4398, -8.2485, -5.2740, -8.9460,\n",
      "        -8.6408,  4.6906,  8.5199, -0.4603, -9.0620, -9.0491, -4.8067, -3.5184,\n",
      "        -8.2519,  7.9634, -6.1492, -8.5266, -3.5877, -5.1489,  7.6181, -2.4979,\n",
      "         2.0820,  6.3199,  3.0737, -9.0042,  7.2212, -8.9931, -3.4458,  8.6073,\n",
      "        -8.0553, -5.9145,  4.6039,  8.0044,  6.1896,  7.0366, -8.8979,  8.4629,\n",
      "        -8.6316,  4.3900,  7.7916, -8.9940,  4.5836,  8.4469, -9.0510, -8.9766,\n",
      "         1.0870, -3.6226, -8.9230, -4.0134, -6.2924, -1.9588, -8.8506,  4.5368,\n",
      "         7.2730, -6.9209,  1.0418, -7.3718,  8.2874, -5.3708,  3.5493, -8.5918,\n",
      "        -7.7344, -0.5951, -6.9839,  4.8308,  8.6145,  8.5745,  6.0930, -5.7428,\n",
      "         2.8933,  4.4347,  4.0638, -8.6400, -9.0847, -6.3426, -3.2990,  5.2158,\n",
      "         7.3952,  8.5593, -8.7978,  4.5203, -5.0267, -0.7314,  3.5148,  6.9283,\n",
      "        -7.5528,  4.0768, -9.0755,  4.5141,  4.7972,  8.4519,  6.2396,  6.9909,\n",
      "        -8.6252,  7.6366,  5.7947, -3.1893, -7.2672, -7.8221,  3.3644, -1.1378,\n",
      "        -0.0713,  6.5361, -6.5096, -7.5129,  8.1576, -8.6987,  0.7065, -9.0486,\n",
      "        -6.2573,  7.3160,  3.6750,  4.1030], grad_fn=<SelectBackward0>)\n",
      "Check eigenvalues:  0.9999944074891853\n",
      "final_W1:  tensor([[1.0000e-04, 5.5781e+00],\n",
      "        [2.9522e-04, 1.0000e-04]], grad_fn=<SqrtBackward0>)\n",
      "final_W2:  tensor([[1.0000e+00, 5.7337e-07],\n",
      "        [5.7337e-07, 1.0000e+00]], grad_fn=<AddBackward0>)\n",
      "W1:  [[1.00000000e-04 5.57813569e+00]\n",
      " [2.95223390e-04 1.00000000e-04]]\n",
      "W2:  [[1.00000101e+00 5.73365197e-07]\n",
      " [5.73365197e-07 9.99999023e-01]]\n",
      "logdet:  tensor(3.7255e-08)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The programm is closed\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "#z = np.random.uniform(low=0, high=3, size=100)\n",
    "x = np.random.uniform(low=-3, high=3, size=300)\n",
    "epsilon = np.random.normal(0, 1, 300) \n",
    "y = np.array([np.sin(x)*10 + epsilon for x, epsilon in zip(x, epsilon)])\n",
    "X = np.column_stack((x, y))\n",
    "data = pd.DataFrame(X, columns=['x', 'y'])\n",
    "eq_model2 = admg_rkhs_discovery.ADMG_RKHSDagma(data, gamma = 1)\n",
    "model2 = admg_rkhs_discovery.RKHS_discovery(eq_model2, admg_class = \"none\", verbose=True)\n",
    "W1, W2, output = model2.fit(data, lambda1=1e-3, tau=1e-4, T = 6, mu_init = 0.1, lr=0.03, w_threshold=0.0)\n",
    "print(\"W1: \", W1)\n",
    "print(\"W2: \", W2)\n",
    "sign, logdet = torch.linalg.slogdet(torch.tensor(W2))\n",
    "print(\"logdet: \", logdet)\n",
    "y_hat = output[:, 1].detach().numpy()\n",
    "plt.figure(figsize=(10, 6))  # Optional: specifies the figure size\n",
    "plt.scatter(x, y, label='y', color='blue', marker='o')  # Plot x vs. y1\n",
    "plt.scatter(x, y_hat, label='y_est', color='red', marker='s') \n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"The programm is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The programm is closed\n"
     ]
    }
   ],
   "source": [
    "x_hat = output[:, 0].detach().numpy()\n",
    "plt.figure(figsize=(10, 6))  # Optional: specifies the figure size\n",
    "plt.scatter(y, x, label='y', color='blue', marker='o')  # Plot x vs. y1\n",
    "plt.scatter(y, x_hat, label='y_est', color='red', marker='s') \n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"The programm is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.43751465  84.42928251]\n",
      " [ 84.42928251 904.85609546]]\n"
     ]
    }
   ],
   "source": [
    "cov_matrix = np.cov(X, rowvar=False)\n",
    "print(cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different Hyperparameter tuning for the four simulations\n",
    "large datapoints\n",
    "exponential simulations\n",
    "Check if gradient of the kernel is in RKHS\n",
    "do other non-linear simulations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "admg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
